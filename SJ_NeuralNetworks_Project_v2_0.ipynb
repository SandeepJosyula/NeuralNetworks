{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SJ_NeuralNetworks Project v2.0",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "12R6n1Vq6W_LhFWfP0KBNwEAnZu93kBZK",
      "authorship_tag": "ABX9TyNwonY1/mEk4hu/xw0OZKFb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SandeepJosyula/NeuralNetworks/blob/master/SJ_NeuralNetworks_Project_v2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gmcyq2O7Ttb",
        "colab_type": "text"
      },
      "source": [
        "# **Neural Networks Project**\n",
        "## The Problem \n",
        "\n",
        "**Description:** Recognizing multi-digit numbers in photographs captured at street level is an importantcomponent of modern-day map making. A classic example of a corpus of such streetlevel photographs is Googleâ€™s StreetView imagery comprised of hundreds of millions ofgeo-located 360 degree panoramic images. The ability to automatically transcribe anaddress number from a geo-located patch of pixels and associate the transcribednumber with a known street address helps pinpoint, with a high degree of accuracy, thelocation of the building it represents.\n",
        "\n",
        "More broadly, recognizing numbers in photographs is a problem of interest to the opticalcharacter recognition community. While OCR on constrained domains like documentprocessing is well studied, arbitrary multi-character text recognition in photographs isstill highly challenging. This difficulty arises due to the wide variability in the visualappearance of text in the wild on account of a large range of fonts, colours, styles,orientations, and character arrangements. The recognition problem is furthercomplicated by environmental factors such as lighting, shadows, secularities, andocclusions as well as by image acquisition factors such as resolution, motion, and focus blurs.\n",
        "\n",
        "In this project we will use dataset with images centred around a single digit (many of theimages do contain some distractors at the sides). Although we are taking a sample ofthe data which is simpler, it is more complex than MNIST because of the distractors.\n",
        "\n",
        "**Data Description:** \n",
        "The Street View House Numbers (SVHN) DatasetSVHN is a real-world image dataset for developing machine learning and objectrecognition algorithms with minimal requirement on data formatting but comes from asignificantly harder, unsolved, real world problem (recognizing digits and numbers innatural scene images). SVHN is obtained from house numbers in Google Street Viewimages.\n",
        "\n",
        "**Link to the dataset:** https://drive.google.com/file/d/1L2-WXzguhUsCArrFUc8EEkXcj33pahoS/view?usp=sharing\n",
        "\n",
        "Acknowledgement for the datasets.Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. NgReading Digits in Natural Images with Unsupervised Feature Learning NIPS Workshopon Deep Learning and Unsupervised Feature Learning 2011. PDFhttp://ufldl.stanford.edu/housenumbers as the URL for this site when necessary\n",
        "\n",
        "##Objective:\n",
        "The objective of the project is to learn how to implement a simple image classification pipeline based on a deep neural network. The goals of this project are as follows: \n",
        "\n",
        "**Steps and tasks**\n",
        "\n",
        "1.Load Dataset\n",
        "\n",
        "2.Understand the basic Image Classification pipeline and the data-driven approach (train/predict stages)\n",
        "\n",
        "3.Data fetching and understand the train/val/test splits. (15points)\n",
        "\n",
        "4.Implement and apply a deep neural network classifier including (feedforward neuralnetwork, RELU, activations) (25points) \n",
        "\n",
        "5.Implement batch normalization for training the neural network(10points) \n",
        "\n",
        "6.Print the classification accuracy metrics (10points) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcapkOq57mJ2",
        "colab_type": "text"
      },
      "source": [
        "# **Implementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_8NvO-ODHRn",
        "colab_type": "text"
      },
      "source": [
        "## 1. Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R53GW0us5W5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0d4bf1ad-7c2a-44dc-b25f-6a1ee4e1f1eb"
      },
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense\n",
        "from keras import regularizers,optimizers\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import BatchNormalization, Dropout\n",
        "\n",
        "# Initialize the random number generator\n",
        "import random\n",
        "random.seed(0)\n",
        "import math\n",
        "# Ignore the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, auc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Bqbf0GODPLA",
        "colab_type": "text"
      },
      "source": [
        "## 2. Read data and extract required datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxxyFbmu0I00",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f5c58c07-a08c-47a4-c308-fa575c3f6806"
      },
      "source": [
        "# Open the file as read only\n",
        "h5f = h5py.File( '/content/drive/My Drive/Study/ML & AI - Study/Colab Notebooks/Neural Networks/SVHN_single_grey1.h5', mode='r')\n",
        "list(h5f.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzXQRTshuIjh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "63009b80-b038-40bf-9167-eab7faa6754a"
      },
      "source": [
        "X_train = h5f['X_train'][:]\n",
        "X_test = h5f['X_test'][:]\n",
        "X_val = h5f['X_val'][:]\n",
        "y_train = h5f['y_train'][:]\n",
        "y_test = h5f['y_test'][:]\n",
        "y_val = h5f['y_val'][:]\n",
        "print('X_train shape: ',X_train.shape)\n",
        "print('X_test shape: ',X_test.shape)\n",
        "print('y_train shape: ',y_train.shape)\n",
        "print('y_test shape: ',y_test.shape)\n",
        "print('X_val shape: ',X_val.shape)\n",
        "print('y_val shape: ',y_val.shape)\n",
        "h5f.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape:  (42000, 32, 32)\n",
            "X_test shape:  (18000, 32, 32)\n",
            "y_train shape:  (42000,)\n",
            "y_test shape:  (18000,)\n",
            "X_val shape:  (60000, 32, 32)\n",
            "y_val shape:  (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxAVWmXfYfny",
        "colab_type": "text"
      },
      "source": [
        "## 3. Data Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAkusu6TDaqX",
        "colab_type": "text"
      },
      "source": [
        "### 3.1. Flatten the images for Keras\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJqPhdnGE5CW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c2b8ff3c-5ead-435e-8846-f3a4da679549"
      },
      "source": [
        "# reshaping X data: (n, 32, 32) => (n, 1024)\n",
        "X_train = X_train.reshape( (X_train.shape[0], -1))\n",
        "X_test = X_test.reshape((X_test.shape[0], -1))\n",
        "X_val = X_val.reshape((X_val.shape[0], -1))\n",
        "\n",
        "print(X_train.shape, X_test.shape, X_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 1024) (18000, 1024) (60000, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_TP9cBFDbsQ",
        "colab_type": "text"
      },
      "source": [
        "### 3.2. Normalize the inputs for X_train, X_test and X_val\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agQ5HNHHE6g7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c3352643-792c-4548-8c91-64aa98e2cc75"
      },
      "source": [
        "print(X_train.max())\n",
        "print(X_train.min())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "254.9745\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6_V1nSZcGOP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "92d6f5e8-278d-4371-88e3-52ddcbb793dc"
      },
      "source": [
        "X_train = X_train / 254.9745\n",
        "X_val = X_val / 254.9745\n",
        "\n",
        "print(X_train.max())\n",
        "print(X_train.min())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dalBsG7oDccN",
        "colab_type": "text"
      },
      "source": [
        "### 3.3. Visualize the first 10 images in X_train and the corresponding Y_train labels\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSvaZ77TXPGK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        },
        "outputId": "f22cc1b1-518a-496d-c798-e495b5eb1b1b"
      },
      "source": [
        "plt.figure(figsize=(10, 1))\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.imshow(X_train[i].reshape(32, 32))  # For gray scale, use the argument cmap=\"gray\"\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "print('label for each of the above image: %s' % (y_train[0:10]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "label for each of the above image: [2 6 7 4 4 0 3 0 7 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r3mAlf8DcGX",
        "colab_type": "text"
      },
      "source": [
        "### 3.4. Convert the class matrices y_train, y_test and y_val into one hot vectors\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXXi2PGNE8Gj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "93bb80da-27da-493d-a8f4-d763eda94392"
      },
      "source": [
        "# converting y data into categorical (one-hot encoding)\n",
        "print(y_train[10]) # Check the value before one-hot encoding\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "y_val = to_categorical(y_val)\n",
        "\n",
        "print(y_train.shape, y_test.shape, y_val.shape)\n",
        "\n",
        "print(y_train[10]) # Check the value after one-hot encoding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "(42000, 10) (18000, 10) (60000, 10)\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cwa9BZXDxWP",
        "colab_type": "text"
      },
      "source": [
        "### 3.5. Print the train, test and val shapes\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo-tzJXpE9Xc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "728eb818-7483-41dd-cfdf-f08a563d9afd"
      },
      "source": [
        "print(X_train.shape, X_test.shape, X_val.shape, y_train.shape, y_test.shape, y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 1024) (18000, 1024) (60000, 1024) (42000, 10) (18000, 10) (60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s18qS17MDxP7",
        "colab_type": "text"
      },
      "source": [
        "## 4. Model Building - Definition\n",
        "\n",
        " - In the train and test loop, define the hyperparameters for the model\t\n",
        " - Create a Sequential model in Keras with input layer with the correct input shape, Hidden Layers, Output Layers and the activation functions\t\n",
        " - Define the optimizer to be used\n",
        " - Compile the model with the corresonding loss & metrics to monitor\n",
        " - Fit the model and use model.evaluate() to return the score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghNipG3xX9ap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_and_test_loop(X, y, hidden_nodes, output_nodes, iter_epochs, btc_size, lr, Lambda, verb=True, addbatchnormalization=False, setdropout=False):\n",
        "\n",
        "    ## hyperparameters\n",
        "    eps = iter_epochs\n",
        "    learning_rate = lr\n",
        "    hidden_nodes = hidden_nodes \n",
        "    output_nodes = output_nodes \n",
        "    btc_size = btc_size \n",
        "    dropout_val = 0.2\n",
        "    # pick a sequential model    \n",
        "    model = Sequential()\n",
        "\n",
        "    # define the input size to 1024 - which is 32*32 size of the image\n",
        "    if addbatchnormalization ==True:\n",
        "      print('Added Batch Normalization after input layer') \n",
        "      model.add(Dense(hidden_nodes, input_shape=(1024,)))    #use activation function RELU for input layer\n",
        "      model.add(BatchNormalization())      \n",
        "      model.add(Activation('relu'))  \n",
        "      if setdropout ==True:\n",
        "        model.add(Dropout(dropout_val)) \n",
        "      model.add(Dense(hidden_nodes))    \n",
        "      model.add(BatchNormalization())      \n",
        "      model.add(Activation('relu'))  \n",
        "      if setdropout ==True:\n",
        "        model.add(Dropout(dropout_val))\n",
        "      model.add(Dense(hidden_nodes))    \n",
        "      model.add(BatchNormalization())      \n",
        "      model.add(Activation('relu'))  \n",
        "      if setdropout ==True:\n",
        "        model.add(Dropout(dropout_val))\n",
        "      model.add(Dense(hidden_nodes))    \n",
        "      model.add(BatchNormalization())      \n",
        "      model.add(Activation('relu'))  \n",
        "      if setdropout ==True:\n",
        "        model.add(Dropout(dropout_val))\n",
        "      model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
        "    else:\n",
        "      model.add(Dense(hidden_nodes, input_shape=(1024,), activation='relu'))    #use activation function RELU for input layer\n",
        "      model.add(Dense(hidden_nodes, activation='relu'))\n",
        "      model.add(Dense(hidden_nodes, activation='relu'))\n",
        "      model.add(Dense(hidden_nodes, activation='relu'))\n",
        "      model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
        "    \n",
        "    # Define the optimizer - SGD \n",
        "    print('Optimizer SGD is used')\n",
        "    sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n",
        "    \n",
        "    # Compile model with appropriate loss and metrics\n",
        "    print('Compiling the model')\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "    \n",
        "    # print model summary\n",
        "    print(model.summary())\n",
        "\n",
        "    # Fit the model\n",
        "    print('Fit the model')\n",
        "    model.fit(X, y, epochs=eps, batch_size=btc_size, verbose= 1)  \n",
        "  \n",
        "    return model\n",
        "    \n",
        "    # return the score\n",
        "    #print('Score:')\n",
        "    #score = model.evaluate(X, y, verbose=0)\n",
        "    #return score\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3rhYgi3Dw5r",
        "colab_type": "text"
      },
      "source": [
        "**Disable Regularization by setting appropriate value for Lambda and check the loss of the NN**\n",
        " - Disabling regularization means lambda value set to 0\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO6h77xBFEMv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "55e9b37d-ae71-45e5-b876-d5af92eaf15c"
      },
      "source": [
        "m1 = train_and_test_loop(X_train, y_train, hidden_nodes=128, output_nodes=10, btc_size=100, iter_epochs=10, lr=0.01, Lambda=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 182,026\n",
            "Trainable params: 182,026\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/10\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 2.2299 - accuracy: 0.1715\n",
            "Epoch 2/10\n",
            "42000/42000 [==============================] - 2s 43us/step - loss: 1.5704 - accuracy: 0.4596\n",
            "Epoch 3/10\n",
            "42000/42000 [==============================] - 2s 44us/step - loss: 1.2745 - accuracy: 0.5842\n",
            "Epoch 4/10\n",
            "42000/42000 [==============================] - 2s 44us/step - loss: 1.1043 - accuracy: 0.6464\n",
            "Epoch 5/10\n",
            "42000/42000 [==============================] - 2s 43us/step - loss: 0.9995 - accuracy: 0.6815\n",
            "Epoch 6/10\n",
            "42000/42000 [==============================] - 2s 45us/step - loss: 0.9580 - accuracy: 0.6955\n",
            "Epoch 7/10\n",
            "42000/42000 [==============================] - 2s 46us/step - loss: 0.8915 - accuracy: 0.7161\n",
            "Epoch 8/10\n",
            "42000/42000 [==============================] - 2s 44us/step - loss: 0.8382 - accuracy: 0.7362\n",
            "Epoch 9/10\n",
            "42000/42000 [==============================] - 2s 44us/step - loss: 0.8039 - accuracy: 0.7449\n",
            "Epoch 10/10\n",
            "42000/42000 [==============================] - 2s 44us/step - loss: 0.7738 - accuracy: 0.7536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U73mUc08Xh9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score_m1 = m1.evaluate(X_test,y_test,verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1mFrD6wXhwM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "762b0bbb-587d-4b99-c69a-6bf1d2342fcc"
      },
      "source": [
        "print(score_m1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[81.83378453826904, 0.7534444332122803]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGC9u73rhouq",
        "colab_type": "text"
      },
      "source": [
        "**Observations:**\n",
        " - Accuracy is 0.75. Not bad for a basic hyperparameter values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nMcQSo7AqaK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "b6d0298a-f81b-4bca-c650-63d43240e967"
      },
      "source": [
        "# vary the parameters and try again\n",
        "model_m2 = train_and_test_loop(X_train, y_train, hidden_nodes=256, output_nodes=10, btc_size=100, iter_epochs=10, lr=0.01, Lambda=0.001)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/10\n",
            "42000/42000 [==============================] - 4s 91us/step - loss: 2.1305 - accuracy: 0.2423\n",
            "Epoch 2/10\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 1.3985 - accuracy: 0.5486\n",
            "Epoch 3/10\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 1.1633 - accuracy: 0.6390\n",
            "Epoch 4/10\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 1.0247 - accuracy: 0.6850\n",
            "Epoch 5/10\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.9327 - accuracy: 0.7148\n",
            "Epoch 6/10\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.8813 - accuracy: 0.7279\n",
            "Epoch 7/10\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.8494 - accuracy: 0.7408\n",
            "Epoch 8/10\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.7908 - accuracy: 0.7576\n",
            "Epoch 9/10\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.7593 - accuracy: 0.7675\n",
            "Epoch 10/10\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.7314 - accuracy: 0.7764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOuwqxb0XCxO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9dc40e49-541e-422b-8945-b58dc0b17793"
      },
      "source": [
        "score_m2 = model_m2.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18000/18000 [==============================] - 1s 47us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp7YoUQ3XIKE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "545bce83-f2a0-4f93-99e5-bbba809df353"
      },
      "source": [
        "print('Accuracy: ', score_m2[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7644444704055786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcfwyGIxh0S9",
        "colab_type": "text"
      },
      "source": [
        "**Observations:**\n",
        " - Accuracy is almost the same for the test set as it is for train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZOvCSt4BLHf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "f1ee9271-5a50-4247-cc59-14affe07201e"
      },
      "source": [
        "# vary the parameters and try again\n",
        "model_m3 = train_and_test_loop(X_train, y_train, hidden_nodes=256, output_nodes=10, btc_size=100, iter_epochs=10, lr=0.00001, Lambda=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_11 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/10\n",
            "42000/42000 [==============================] - 4s 91us/step - loss: 2.3182 - accuracy: 0.0976\n",
            "Epoch 2/10\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 2.3136 - accuracy: 0.0980\n",
            "Epoch 3/10\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 2.3104 - accuracy: 0.0983\n",
            "Epoch 4/10\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 2.3081 - accuracy: 0.0992\n",
            "Epoch 5/10\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 2.3063 - accuracy: 0.1004\n",
            "Epoch 6/10\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 2.3050 - accuracy: 0.1005\n",
            "Epoch 7/10\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 2.3039 - accuracy: 0.1012\n",
            "Epoch 8/10\n",
            "42000/42000 [==============================] - 4s 84us/step - loss: 2.3031 - accuracy: 0.1022\n",
            "Epoch 9/10\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 2.3024 - accuracy: 0.1033\n",
            "Epoch 10/10\n",
            "42000/42000 [==============================] - 4s 85us/step - loss: 2.3018 - accuracy: 0.1049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXnsVeANXrzF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e185e5bd-6a68-4ec5-9e5a-e6ac9a99d0b4"
      },
      "source": [
        "score_m3 = model_m3.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18000/18000 [==============================] - 1s 44us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8Yk4rCjXroW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3ff8f873-c350-41d6-a4a3-6132ecc31a8c"
      },
      "source": [
        "print('Accuracy: ', score_m3[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.1059444472193718\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjpJ0aDIiCPZ",
        "colab_type": "text"
      },
      "source": [
        "**Observations:**\n",
        " - considering the epoch count is too small, may be for higher count the accuracy of the mode may be better"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kc3c1sRvEWba",
        "colab_type": "text"
      },
      "source": [
        "**Increase the Regularization parameter (Lambda) and check how the loss is for the NN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62rCSzJ5FHyd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "1fc5bbdc-8238-48de-a908-a32372b79db4"
      },
      "source": [
        "model_m4 = train_and_test_loop(X_train, y_train, hidden_nodes=50, output_nodes=10, btc_size=1000, iter_epochs=10, lr=0.001, Lambda=1e3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 50)                51250     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 59,410\n",
            "Trainable params: 59,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/10\n",
            "42000/42000 [==============================] - 1s 14us/step - loss: 3947.8606 - accuracy: 0.0991\n",
            "Epoch 2/10\n",
            "42000/42000 [==============================] - 1s 13us/step - loss: 51.8459 - accuracy: 0.0980\n",
            "Epoch 3/10\n",
            "42000/42000 [==============================] - 1s 13us/step - loss: 2.8498 - accuracy: 0.1012\n",
            "Epoch 4/10\n",
            "42000/42000 [==============================] - 1s 12us/step - loss: 2.3091 - accuracy: 0.1019\n",
            "Epoch 5/10\n",
            "42000/42000 [==============================] - 1s 13us/step - loss: 2.3027 - accuracy: 0.1019\n",
            "Epoch 6/10\n",
            "42000/42000 [==============================] - 1s 13us/step - loss: 2.3026 - accuracy: 0.1019\n",
            "Epoch 7/10\n",
            "42000/42000 [==============================] - 1s 13us/step - loss: 2.3026 - accuracy: 0.1019\n",
            "Epoch 8/10\n",
            "42000/42000 [==============================] - 1s 12us/step - loss: 2.3026 - accuracy: 0.1019\n",
            "Epoch 9/10\n",
            "42000/42000 [==============================] - 1s 12us/step - loss: 2.3026 - accuracy: 0.1019\n",
            "Epoch 10/10\n",
            "42000/42000 [==============================] - 1s 12us/step - loss: 2.3026 - accuracy: 0.1019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAZON0oiYEzv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e2039ffb-66a1-4c3e-98be-a98b4bb10319"
      },
      "source": [
        "score_m4 = model_m4.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18000/18000 [==============================] - 0s 24us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnaK-lnMYEou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eed1527c-75cd-4c3d-e930-a634892d7c21"
      },
      "source": [
        "print('Accuracy: ', score_m4[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.09549999982118607\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzxhvfM3iL6P",
        "colab_type": "text"
      },
      "source": [
        "**Observations:**\n",
        " - Accuracy is not that better, but the loss has quickly reduced within the 10 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMKxajp9EX9S",
        "colab_type": "text"
      },
      "source": [
        "## 5. Overfit a small subset of dataset\n",
        " - Network overfit with a small subset of the dataset\n",
        " - Check if the network will overfit when you use no regularization and the loss is very small and accuracy is 100%.\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRUwW2pMFJAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_subset = X_train[0:20]\n",
        "y_train_subset = y_train[0:20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCtvZOQ5B41d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "78148761-191b-40d6-ff51-6fc2eac729af"
      },
      "source": [
        "X_train_subset.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 1024)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCOB-9MYB-U5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a076e23d-895e-4b96-ee2d-a6b5b531fa2e"
      },
      "source": [
        "model_m5 = train_and_test_loop(X_train_subset, y_train_subset, hidden_nodes=128, output_nodes=10, btc_size=100, iter_epochs=500, lr=0.001, Lambda=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_21 (Dense)             (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 182,026\n",
            "Trainable params: 182,026\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/500\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 2.2989 - accuracy: 0.1000\n",
            "Epoch 2/500\n",
            "20/20 [==============================] - 0s 262us/step - loss: 2.2964 - accuracy: 0.1000\n",
            "Epoch 3/500\n",
            "20/20 [==============================] - 0s 238us/step - loss: 2.2918 - accuracy: 0.1000\n",
            "Epoch 4/500\n",
            "20/20 [==============================] - 0s 231us/step - loss: 2.2854 - accuracy: 0.1000\n",
            "Epoch 5/500\n",
            "20/20 [==============================] - 0s 201us/step - loss: 2.2776 - accuracy: 0.1000\n",
            "Epoch 6/500\n",
            "20/20 [==============================] - 0s 135us/step - loss: 2.2689 - accuracy: 0.1000\n",
            "Epoch 7/500\n",
            "20/20 [==============================] - 0s 124us/step - loss: 2.2594 - accuracy: 0.1000\n",
            "Epoch 8/500\n",
            "20/20 [==============================] - 0s 161us/step - loss: 2.2492 - accuracy: 0.1000\n",
            "Epoch 9/500\n",
            "20/20 [==============================] - 0s 205us/step - loss: 2.2383 - accuracy: 0.1500\n",
            "Epoch 10/500\n",
            "20/20 [==============================] - 0s 189us/step - loss: 2.2267 - accuracy: 0.2000\n",
            "Epoch 11/500\n",
            "20/20 [==============================] - 0s 157us/step - loss: 2.2149 - accuracy: 0.3000\n",
            "Epoch 12/500\n",
            "20/20 [==============================] - 0s 192us/step - loss: 2.2030 - accuracy: 0.3500\n",
            "Epoch 13/500\n",
            "20/20 [==============================] - 0s 123us/step - loss: 2.1913 - accuracy: 0.3000\n",
            "Epoch 14/500\n",
            "20/20 [==============================] - 0s 140us/step - loss: 2.1797 - accuracy: 0.2500\n",
            "Epoch 15/500\n",
            "20/20 [==============================] - 0s 173us/step - loss: 2.1682 - accuracy: 0.2000\n",
            "Epoch 16/500\n",
            "20/20 [==============================] - 0s 146us/step - loss: 2.1569 - accuracy: 0.2500\n",
            "Epoch 17/500\n",
            "20/20 [==============================] - 0s 167us/step - loss: 2.1460 - accuracy: 0.2000\n",
            "Epoch 18/500\n",
            "20/20 [==============================] - 0s 142us/step - loss: 2.1348 - accuracy: 0.2000\n",
            "Epoch 19/500\n",
            "20/20 [==============================] - 0s 141us/step - loss: 2.1239 - accuracy: 0.2000\n",
            "Epoch 20/500\n",
            "20/20 [==============================] - 0s 157us/step - loss: 2.1130 - accuracy: 0.2000\n",
            "Epoch 21/500\n",
            "20/20 [==============================] - 0s 235us/step - loss: 2.1020 - accuracy: 0.2000\n",
            "Epoch 22/500\n",
            "20/20 [==============================] - 0s 172us/step - loss: 2.0909 - accuracy: 0.2000\n",
            "Epoch 23/500\n",
            "20/20 [==============================] - 0s 157us/step - loss: 2.0794 - accuracy: 0.2000\n",
            "Epoch 24/500\n",
            "20/20 [==============================] - 0s 151us/step - loss: 2.0684 - accuracy: 0.2000\n",
            "Epoch 25/500\n",
            "20/20 [==============================] - 0s 177us/step - loss: 2.0575 - accuracy: 0.2500\n",
            "Epoch 26/500\n",
            "20/20 [==============================] - 0s 175us/step - loss: 2.0469 - accuracy: 0.2500\n",
            "Epoch 27/500\n",
            "20/20 [==============================] - 0s 170us/step - loss: 2.0364 - accuracy: 0.2500\n",
            "Epoch 28/500\n",
            "20/20 [==============================] - 0s 143us/step - loss: 2.0261 - accuracy: 0.2500\n",
            "Epoch 29/500\n",
            "20/20 [==============================] - 0s 144us/step - loss: 2.0158 - accuracy: 0.2500\n",
            "Epoch 30/500\n",
            "20/20 [==============================] - 0s 331us/step - loss: 2.0055 - accuracy: 0.2500\n",
            "Epoch 31/500\n",
            "20/20 [==============================] - 0s 171us/step - loss: 1.9955 - accuracy: 0.2500\n",
            "Epoch 32/500\n",
            "20/20 [==============================] - 0s 173us/step - loss: 1.9860 - accuracy: 0.2500\n",
            "Epoch 33/500\n",
            "20/20 [==============================] - 0s 175us/step - loss: 1.9768 - accuracy: 0.2500\n",
            "Epoch 34/500\n",
            "20/20 [==============================] - 0s 150us/step - loss: 1.9681 - accuracy: 0.2500\n",
            "Epoch 35/500\n",
            "20/20 [==============================] - 0s 129us/step - loss: 1.9598 - accuracy: 0.2000\n",
            "Epoch 36/500\n",
            "20/20 [==============================] - 0s 151us/step - loss: 1.9522 - accuracy: 0.2500\n",
            "Epoch 37/500\n",
            "20/20 [==============================] - 0s 160us/step - loss: 1.9452 - accuracy: 0.2500\n",
            "Epoch 38/500\n",
            "20/20 [==============================] - 0s 130us/step - loss: 1.9385 - accuracy: 0.2500\n",
            "Epoch 39/500\n",
            "20/20 [==============================] - 0s 149us/step - loss: 1.9320 - accuracy: 0.2500\n",
            "Epoch 40/500\n",
            "20/20 [==============================] - 0s 142us/step - loss: 1.9259 - accuracy: 0.2500\n",
            "Epoch 41/500\n",
            "20/20 [==============================] - 0s 186us/step - loss: 1.9202 - accuracy: 0.2500\n",
            "Epoch 42/500\n",
            "20/20 [==============================] - 0s 225us/step - loss: 1.9148 - accuracy: 0.3000\n",
            "Epoch 43/500\n",
            "20/20 [==============================] - 0s 224us/step - loss: 1.9097 - accuracy: 0.3000\n",
            "Epoch 44/500\n",
            "20/20 [==============================] - 0s 246us/step - loss: 1.9048 - accuracy: 0.3000\n",
            "Epoch 45/500\n",
            "20/20 [==============================] - 0s 239us/step - loss: 1.9001 - accuracy: 0.3000\n",
            "Epoch 46/500\n",
            "20/20 [==============================] - 0s 247us/step - loss: 1.8954 - accuracy: 0.3000\n",
            "Epoch 47/500\n",
            "20/20 [==============================] - 0s 215us/step - loss: 1.8908 - accuracy: 0.3000\n",
            "Epoch 48/500\n",
            "20/20 [==============================] - 0s 242us/step - loss: 1.8864 - accuracy: 0.3000\n",
            "Epoch 49/500\n",
            "20/20 [==============================] - 0s 109us/step - loss: 1.8821 - accuracy: 0.3000\n",
            "Epoch 50/500\n",
            "20/20 [==============================] - 0s 147us/step - loss: 1.8779 - accuracy: 0.3000\n",
            "Epoch 51/500\n",
            "20/20 [==============================] - 0s 193us/step - loss: 1.8739 - accuracy: 0.3000\n",
            "Epoch 52/500\n",
            "20/20 [==============================] - 0s 151us/step - loss: 1.8698 - accuracy: 0.3000\n",
            "Epoch 53/500\n",
            "20/20 [==============================] - 0s 193us/step - loss: 1.8659 - accuracy: 0.3000\n",
            "Epoch 54/500\n",
            "20/20 [==============================] - 0s 265us/step - loss: 1.8620 - accuracy: 0.3000\n",
            "Epoch 55/500\n",
            "20/20 [==============================] - 0s 145us/step - loss: 1.8581 - accuracy: 0.3000\n",
            "Epoch 56/500\n",
            "20/20 [==============================] - 0s 168us/step - loss: 1.8543 - accuracy: 0.3000\n",
            "Epoch 57/500\n",
            "20/20 [==============================] - 0s 160us/step - loss: 1.8504 - accuracy: 0.3000\n",
            "Epoch 58/500\n",
            "20/20 [==============================] - 0s 173us/step - loss: 1.8468 - accuracy: 0.3000\n",
            "Epoch 59/500\n",
            "20/20 [==============================] - 0s 227us/step - loss: 1.8432 - accuracy: 0.3000\n",
            "Epoch 60/500\n",
            "20/20 [==============================] - 0s 196us/step - loss: 1.8396 - accuracy: 0.3000\n",
            "Epoch 61/500\n",
            "20/20 [==============================] - 0s 247us/step - loss: 1.8360 - accuracy: 0.3000\n",
            "Epoch 62/500\n",
            "20/20 [==============================] - 0s 202us/step - loss: 1.8325 - accuracy: 0.3000\n",
            "Epoch 63/500\n",
            "20/20 [==============================] - 0s 201us/step - loss: 1.8290 - accuracy: 0.3500\n",
            "Epoch 64/500\n",
            "20/20 [==============================] - 0s 171us/step - loss: 1.8257 - accuracy: 0.3500\n",
            "Epoch 65/500\n",
            "20/20 [==============================] - 0s 167us/step - loss: 1.8225 - accuracy: 0.3500\n",
            "Epoch 66/500\n",
            "20/20 [==============================] - 0s 128us/step - loss: 1.8194 - accuracy: 0.4000\n",
            "Epoch 67/500\n",
            "20/20 [==============================] - 0s 136us/step - loss: 1.8163 - accuracy: 0.4000\n",
            "Epoch 68/500\n",
            "20/20 [==============================] - 0s 156us/step - loss: 1.8133 - accuracy: 0.4500\n",
            "Epoch 69/500\n",
            "20/20 [==============================] - 0s 208us/step - loss: 1.8102 - accuracy: 0.4500\n",
            "Epoch 70/500\n",
            "20/20 [==============================] - 0s 295us/step - loss: 1.8072 - accuracy: 0.4500\n",
            "Epoch 71/500\n",
            "20/20 [==============================] - 0s 159us/step - loss: 1.8042 - accuracy: 0.4500\n",
            "Epoch 72/500\n",
            "20/20 [==============================] - 0s 136us/step - loss: 1.8012 - accuracy: 0.4500\n",
            "Epoch 73/500\n",
            "20/20 [==============================] - 0s 238us/step - loss: 1.7982 - accuracy: 0.4500\n",
            "Epoch 74/500\n",
            "20/20 [==============================] - 0s 180us/step - loss: 1.7953 - accuracy: 0.4500\n",
            "Epoch 75/500\n",
            "20/20 [==============================] - 0s 346us/step - loss: 1.7925 - accuracy: 0.4500\n",
            "Epoch 76/500\n",
            "20/20 [==============================] - 0s 263us/step - loss: 1.7898 - accuracy: 0.4500\n",
            "Epoch 77/500\n",
            "20/20 [==============================] - 0s 292us/step - loss: 1.7870 - accuracy: 0.4500\n",
            "Epoch 78/500\n",
            "20/20 [==============================] - 0s 672us/step - loss: 1.7843 - accuracy: 0.4000\n",
            "Epoch 79/500\n",
            "20/20 [==============================] - 0s 245us/step - loss: 1.7815 - accuracy: 0.4000\n",
            "Epoch 80/500\n",
            "20/20 [==============================] - 0s 290us/step - loss: 1.7787 - accuracy: 0.4000\n",
            "Epoch 81/500\n",
            "20/20 [==============================] - 0s 196us/step - loss: 1.7758 - accuracy: 0.4000\n",
            "Epoch 82/500\n",
            "20/20 [==============================] - 0s 179us/step - loss: 1.7729 - accuracy: 0.4000\n",
            "Epoch 83/500\n",
            "20/20 [==============================] - 0s 205us/step - loss: 1.7701 - accuracy: 0.4000\n",
            "Epoch 84/500\n",
            "20/20 [==============================] - 0s 232us/step - loss: 1.7672 - accuracy: 0.4000\n",
            "Epoch 85/500\n",
            "20/20 [==============================] - 0s 246us/step - loss: 1.7644 - accuracy: 0.4000\n",
            "Epoch 86/500\n",
            "20/20 [==============================] - 0s 337us/step - loss: 1.7615 - accuracy: 0.4000\n",
            "Epoch 87/500\n",
            "20/20 [==============================] - 0s 333us/step - loss: 1.7586 - accuracy: 0.4000\n",
            "Epoch 88/500\n",
            "20/20 [==============================] - 0s 322us/step - loss: 1.7557 - accuracy: 0.4000\n",
            "Epoch 89/500\n",
            "20/20 [==============================] - 0s 189us/step - loss: 1.7528 - accuracy: 0.4000\n",
            "Epoch 90/500\n",
            "20/20 [==============================] - 0s 254us/step - loss: 1.7500 - accuracy: 0.4000\n",
            "Epoch 91/500\n",
            "20/20 [==============================] - 0s 281us/step - loss: 1.7471 - accuracy: 0.4000\n",
            "Epoch 92/500\n",
            "20/20 [==============================] - 0s 247us/step - loss: 1.7442 - accuracy: 0.4000\n",
            "Epoch 93/500\n",
            "20/20 [==============================] - 0s 143us/step - loss: 1.7413 - accuracy: 0.4000\n",
            "Epoch 94/500\n",
            "20/20 [==============================] - 0s 164us/step - loss: 1.7384 - accuracy: 0.4000\n",
            "Epoch 95/500\n",
            "20/20 [==============================] - 0s 233us/step - loss: 1.7355 - accuracy: 0.4500\n",
            "Epoch 96/500\n",
            "20/20 [==============================] - 0s 142us/step - loss: 1.7325 - accuracy: 0.4500\n",
            "Epoch 97/500\n",
            "20/20 [==============================] - 0s 248us/step - loss: 1.7295 - accuracy: 0.4500\n",
            "Epoch 98/500\n",
            "20/20 [==============================] - 0s 307us/step - loss: 1.7265 - accuracy: 0.4500\n",
            "Epoch 99/500\n",
            "20/20 [==============================] - 0s 254us/step - loss: 1.7236 - accuracy: 0.4500\n",
            "Epoch 100/500\n",
            "20/20 [==============================] - 0s 264us/step - loss: 1.7206 - accuracy: 0.4500\n",
            "Epoch 101/500\n",
            "20/20 [==============================] - 0s 236us/step - loss: 1.7176 - accuracy: 0.4500\n",
            "Epoch 102/500\n",
            "20/20 [==============================] - 0s 211us/step - loss: 1.7145 - accuracy: 0.4500\n",
            "Epoch 103/500\n",
            "20/20 [==============================] - 0s 177us/step - loss: 1.7114 - accuracy: 0.4500\n",
            "Epoch 104/500\n",
            "20/20 [==============================] - 0s 228us/step - loss: 1.7084 - accuracy: 0.4500\n",
            "Epoch 105/500\n",
            "20/20 [==============================] - 0s 134us/step - loss: 1.7053 - accuracy: 0.4500\n",
            "Epoch 106/500\n",
            "20/20 [==============================] - 0s 396us/step - loss: 1.7022 - accuracy: 0.4500\n",
            "Epoch 107/500\n",
            "20/20 [==============================] - 0s 285us/step - loss: 1.6990 - accuracy: 0.4500\n",
            "Epoch 108/500\n",
            "20/20 [==============================] - 0s 131us/step - loss: 1.6960 - accuracy: 0.4500\n",
            "Epoch 109/500\n",
            "20/20 [==============================] - 0s 215us/step - loss: 1.6931 - accuracy: 0.4500\n",
            "Epoch 110/500\n",
            "20/20 [==============================] - 0s 160us/step - loss: 1.6902 - accuracy: 0.4500\n",
            "Epoch 111/500\n",
            "20/20 [==============================] - 0s 306us/step - loss: 1.6874 - accuracy: 0.4500\n",
            "Epoch 112/500\n",
            "20/20 [==============================] - 0s 166us/step - loss: 1.6845 - accuracy: 0.4500\n",
            "Epoch 113/500\n",
            "20/20 [==============================] - 0s 161us/step - loss: 1.6815 - accuracy: 0.4500\n",
            "Epoch 114/500\n",
            "20/20 [==============================] - 0s 222us/step - loss: 1.6786 - accuracy: 0.4500\n",
            "Epoch 115/500\n",
            "20/20 [==============================] - 0s 223us/step - loss: 1.6757 - accuracy: 0.4500\n",
            "Epoch 116/500\n",
            "20/20 [==============================] - 0s 290us/step - loss: 1.6728 - accuracy: 0.4500\n",
            "Epoch 117/500\n",
            "20/20 [==============================] - 0s 195us/step - loss: 1.6698 - accuracy: 0.4500\n",
            "Epoch 118/500\n",
            "20/20 [==============================] - 0s 205us/step - loss: 1.6668 - accuracy: 0.4500\n",
            "Epoch 119/500\n",
            "20/20 [==============================] - 0s 212us/step - loss: 1.6639 - accuracy: 0.4500\n",
            "Epoch 120/500\n",
            "20/20 [==============================] - 0s 218us/step - loss: 1.6610 - accuracy: 0.5000\n",
            "Epoch 121/500\n",
            "20/20 [==============================] - 0s 280us/step - loss: 1.6581 - accuracy: 0.5000\n",
            "Epoch 122/500\n",
            "20/20 [==============================] - 0s 181us/step - loss: 1.6551 - accuracy: 0.5000\n",
            "Epoch 123/500\n",
            "20/20 [==============================] - 0s 177us/step - loss: 1.6521 - accuracy: 0.5000\n",
            "Epoch 124/500\n",
            "20/20 [==============================] - 0s 181us/step - loss: 1.6491 - accuracy: 0.5000\n",
            "Epoch 125/500\n",
            "20/20 [==============================] - 0s 250us/step - loss: 1.6461 - accuracy: 0.5000\n",
            "Epoch 126/500\n",
            "20/20 [==============================] - 0s 232us/step - loss: 1.6430 - accuracy: 0.5000\n",
            "Epoch 127/500\n",
            "20/20 [==============================] - 0s 239us/step - loss: 1.6400 - accuracy: 0.5000\n",
            "Epoch 128/500\n",
            "20/20 [==============================] - 0s 234us/step - loss: 1.6369 - accuracy: 0.5000\n",
            "Epoch 129/500\n",
            "20/20 [==============================] - 0s 234us/step - loss: 1.6338 - accuracy: 0.5000\n",
            "Epoch 130/500\n",
            "20/20 [==============================] - 0s 244us/step - loss: 1.6307 - accuracy: 0.5000\n",
            "Epoch 131/500\n",
            "20/20 [==============================] - 0s 243us/step - loss: 1.6275 - accuracy: 0.5000\n",
            "Epoch 132/500\n",
            "20/20 [==============================] - 0s 214us/step - loss: 1.6244 - accuracy: 0.5000\n",
            "Epoch 133/500\n",
            "20/20 [==============================] - 0s 256us/step - loss: 1.6213 - accuracy: 0.5000\n",
            "Epoch 134/500\n",
            "20/20 [==============================] - 0s 229us/step - loss: 1.6182 - accuracy: 0.5000\n",
            "Epoch 135/500\n",
            "20/20 [==============================] - 0s 208us/step - loss: 1.6150 - accuracy: 0.5000\n",
            "Epoch 136/500\n",
            "20/20 [==============================] - 0s 237us/step - loss: 1.6118 - accuracy: 0.5000\n",
            "Epoch 137/500\n",
            "20/20 [==============================] - 0s 236us/step - loss: 1.6085 - accuracy: 0.5000\n",
            "Epoch 138/500\n",
            "20/20 [==============================] - 0s 230us/step - loss: 1.6053 - accuracy: 0.5500\n",
            "Epoch 139/500\n",
            "20/20 [==============================] - 0s 224us/step - loss: 1.6020 - accuracy: 0.5500\n",
            "Epoch 140/500\n",
            "20/20 [==============================] - 0s 219us/step - loss: 1.5987 - accuracy: 0.5500\n",
            "Epoch 141/500\n",
            "20/20 [==============================] - 0s 308us/step - loss: 1.5955 - accuracy: 0.5500\n",
            "Epoch 142/500\n",
            "20/20 [==============================] - 0s 202us/step - loss: 1.5922 - accuracy: 0.5500\n",
            "Epoch 143/500\n",
            "20/20 [==============================] - 0s 203us/step - loss: 1.5889 - accuracy: 0.5500\n",
            "Epoch 144/500\n",
            "20/20 [==============================] - 0s 188us/step - loss: 1.5856 - accuracy: 0.5500\n",
            "Epoch 145/500\n",
            "20/20 [==============================] - 0s 160us/step - loss: 1.5823 - accuracy: 0.5500\n",
            "Epoch 146/500\n",
            "20/20 [==============================] - 0s 185us/step - loss: 1.5789 - accuracy: 0.5500\n",
            "Epoch 147/500\n",
            "20/20 [==============================] - 0s 160us/step - loss: 1.5756 - accuracy: 0.5500\n",
            "Epoch 148/500\n",
            "20/20 [==============================] - 0s 194us/step - loss: 1.5723 - accuracy: 0.5500\n",
            "Epoch 149/500\n",
            "20/20 [==============================] - 0s 211us/step - loss: 1.5688 - accuracy: 0.5500\n",
            "Epoch 150/500\n",
            "20/20 [==============================] - 0s 208us/step - loss: 1.5653 - accuracy: 0.5500\n",
            "Epoch 151/500\n",
            "20/20 [==============================] - 0s 182us/step - loss: 1.5618 - accuracy: 0.5500\n",
            "Epoch 152/500\n",
            "20/20 [==============================] - 0s 207us/step - loss: 1.5584 - accuracy: 0.5500\n",
            "Epoch 153/500\n",
            "20/20 [==============================] - 0s 202us/step - loss: 1.5548 - accuracy: 0.5500\n",
            "Epoch 154/500\n",
            "20/20 [==============================] - 0s 218us/step - loss: 1.5513 - accuracy: 0.5500\n",
            "Epoch 155/500\n",
            "20/20 [==============================] - 0s 194us/step - loss: 1.5478 - accuracy: 0.5500\n",
            "Epoch 156/500\n",
            "20/20 [==============================] - 0s 195us/step - loss: 1.5443 - accuracy: 0.5500\n",
            "Epoch 157/500\n",
            "20/20 [==============================] - 0s 187us/step - loss: 1.5407 - accuracy: 0.5500\n",
            "Epoch 158/500\n",
            "20/20 [==============================] - 0s 182us/step - loss: 1.5372 - accuracy: 0.5500\n",
            "Epoch 159/500\n",
            "20/20 [==============================] - 0s 167us/step - loss: 1.5336 - accuracy: 0.5500\n",
            "Epoch 160/500\n",
            "20/20 [==============================] - 0s 189us/step - loss: 1.5300 - accuracy: 0.5500\n",
            "Epoch 161/500\n",
            "20/20 [==============================] - 0s 186us/step - loss: 1.5264 - accuracy: 0.5500\n",
            "Epoch 162/500\n",
            "20/20 [==============================] - 0s 196us/step - loss: 1.5228 - accuracy: 0.5500\n",
            "Epoch 163/500\n",
            "20/20 [==============================] - 0s 205us/step - loss: 1.5192 - accuracy: 0.5500\n",
            "Epoch 164/500\n",
            "20/20 [==============================] - 0s 152us/step - loss: 1.5155 - accuracy: 0.5500\n",
            "Epoch 165/500\n",
            "20/20 [==============================] - 0s 199us/step - loss: 1.5119 - accuracy: 0.5500\n",
            "Epoch 166/500\n",
            "20/20 [==============================] - 0s 193us/step - loss: 1.5082 - accuracy: 0.5500\n",
            "Epoch 167/500\n",
            "20/20 [==============================] - 0s 178us/step - loss: 1.5046 - accuracy: 0.5500\n",
            "Epoch 168/500\n",
            "20/20 [==============================] - 0s 199us/step - loss: 1.5009 - accuracy: 0.5500\n",
            "Epoch 169/500\n",
            "20/20 [==============================] - 0s 157us/step - loss: 1.4971 - accuracy: 0.5500\n",
            "Epoch 170/500\n",
            "20/20 [==============================] - 0s 213us/step - loss: 1.4933 - accuracy: 0.5500\n",
            "Epoch 171/500\n",
            "20/20 [==============================] - 0s 221us/step - loss: 1.4895 - accuracy: 0.5500\n",
            "Epoch 172/500\n",
            "20/20 [==============================] - 0s 226us/step - loss: 1.4857 - accuracy: 0.5500\n",
            "Epoch 173/500\n",
            "20/20 [==============================] - 0s 230us/step - loss: 1.4818 - accuracy: 0.5500\n",
            "Epoch 174/500\n",
            "20/20 [==============================] - 0s 229us/step - loss: 1.4778 - accuracy: 0.5500\n",
            "Epoch 175/500\n",
            "20/20 [==============================] - 0s 236us/step - loss: 1.4738 - accuracy: 0.5500\n",
            "Epoch 176/500\n",
            "20/20 [==============================] - 0s 224us/step - loss: 1.4698 - accuracy: 0.5500\n",
            "Epoch 177/500\n",
            "20/20 [==============================] - 0s 231us/step - loss: 1.4657 - accuracy: 0.5500\n",
            "Epoch 178/500\n",
            "20/20 [==============================] - 0s 223us/step - loss: 1.4616 - accuracy: 0.5500\n",
            "Epoch 179/500\n",
            "20/20 [==============================] - 0s 230us/step - loss: 1.4575 - accuracy: 0.5500\n",
            "Epoch 180/500\n",
            "20/20 [==============================] - 0s 224us/step - loss: 1.4533 - accuracy: 0.5500\n",
            "Epoch 181/500\n",
            "20/20 [==============================] - 0s 217us/step - loss: 1.4490 - accuracy: 0.5500\n",
            "Epoch 182/500\n",
            "20/20 [==============================] - 0s 243us/step - loss: 1.4447 - accuracy: 0.6000\n",
            "Epoch 183/500\n",
            "20/20 [==============================] - 0s 285us/step - loss: 1.4402 - accuracy: 0.6000\n",
            "Epoch 184/500\n",
            "20/20 [==============================] - 0s 193us/step - loss: 1.4357 - accuracy: 0.6000\n",
            "Epoch 185/500\n",
            "20/20 [==============================] - 0s 248us/step - loss: 1.4313 - accuracy: 0.6000\n",
            "Epoch 186/500\n",
            "20/20 [==============================] - 0s 353us/step - loss: 1.4269 - accuracy: 0.6000\n",
            "Epoch 187/500\n",
            "20/20 [==============================] - 0s 303us/step - loss: 1.4225 - accuracy: 0.6000\n",
            "Epoch 188/500\n",
            "20/20 [==============================] - 0s 300us/step - loss: 1.4180 - accuracy: 0.6000\n",
            "Epoch 189/500\n",
            "20/20 [==============================] - 0s 329us/step - loss: 1.4136 - accuracy: 0.6000\n",
            "Epoch 190/500\n",
            "20/20 [==============================] - 0s 204us/step - loss: 1.4091 - accuracy: 0.6000\n",
            "Epoch 191/500\n",
            "20/20 [==============================] - 0s 311us/step - loss: 1.4048 - accuracy: 0.6000\n",
            "Epoch 192/500\n",
            "20/20 [==============================] - 0s 281us/step - loss: 1.4005 - accuracy: 0.6000\n",
            "Epoch 193/500\n",
            "20/20 [==============================] - 0s 194us/step - loss: 1.3961 - accuracy: 0.6000\n",
            "Epoch 194/500\n",
            "20/20 [==============================] - 0s 143us/step - loss: 1.3918 - accuracy: 0.6000\n",
            "Epoch 195/500\n",
            "20/20 [==============================] - 0s 145us/step - loss: 1.3874 - accuracy: 0.6000\n",
            "Epoch 196/500\n",
            "20/20 [==============================] - 0s 243us/step - loss: 1.3831 - accuracy: 0.6000\n",
            "Epoch 197/500\n",
            "20/20 [==============================] - 0s 171us/step - loss: 1.3787 - accuracy: 0.6000\n",
            "Epoch 198/500\n",
            "20/20 [==============================] - 0s 155us/step - loss: 1.3744 - accuracy: 0.6000\n",
            "Epoch 199/500\n",
            "20/20 [==============================] - 0s 201us/step - loss: 1.3700 - accuracy: 0.6000\n",
            "Epoch 200/500\n",
            "20/20 [==============================] - 0s 138us/step - loss: 1.3655 - accuracy: 0.6000\n",
            "Epoch 201/500\n",
            "20/20 [==============================] - 0s 208us/step - loss: 1.3611 - accuracy: 0.6000\n",
            "Epoch 202/500\n",
            "20/20 [==============================] - 0s 147us/step - loss: 1.3566 - accuracy: 0.6000\n",
            "Epoch 203/500\n",
            "20/20 [==============================] - 0s 190us/step - loss: 1.3522 - accuracy: 0.6000\n",
            "Epoch 204/500\n",
            "20/20 [==============================] - 0s 136us/step - loss: 1.3479 - accuracy: 0.6000\n",
            "Epoch 205/500\n",
            "20/20 [==============================] - 0s 159us/step - loss: 1.3435 - accuracy: 0.6000\n",
            "Epoch 206/500\n",
            "20/20 [==============================] - 0s 162us/step - loss: 1.3391 - accuracy: 0.6000\n",
            "Epoch 207/500\n",
            "20/20 [==============================] - 0s 194us/step - loss: 1.3346 - accuracy: 0.6000\n",
            "Epoch 208/500\n",
            "20/20 [==============================] - 0s 290us/step - loss: 1.3302 - accuracy: 0.6000\n",
            "Epoch 209/500\n",
            "20/20 [==============================] - 0s 262us/step - loss: 1.3257 - accuracy: 0.6000\n",
            "Epoch 210/500\n",
            "20/20 [==============================] - 0s 642us/step - loss: 1.3212 - accuracy: 0.6000\n",
            "Epoch 211/500\n",
            "20/20 [==============================] - 0s 337us/step - loss: 1.3167 - accuracy: 0.6000\n",
            "Epoch 212/500\n",
            "20/20 [==============================] - 0s 334us/step - loss: 1.3122 - accuracy: 0.6000\n",
            "Epoch 213/500\n",
            "20/20 [==============================] - 0s 354us/step - loss: 1.3077 - accuracy: 0.6000\n",
            "Epoch 214/500\n",
            "20/20 [==============================] - 0s 301us/step - loss: 1.3031 - accuracy: 0.6000\n",
            "Epoch 215/500\n",
            "20/20 [==============================] - 0s 696us/step - loss: 1.2986 - accuracy: 0.6000\n",
            "Epoch 216/500\n",
            "20/20 [==============================] - 0s 234us/step - loss: 1.2940 - accuracy: 0.6000\n",
            "Epoch 217/500\n",
            "20/20 [==============================] - 0s 151us/step - loss: 1.2894 - accuracy: 0.6000\n",
            "Epoch 218/500\n",
            "20/20 [==============================] - 0s 179us/step - loss: 1.2848 - accuracy: 0.6000\n",
            "Epoch 219/500\n",
            "20/20 [==============================] - 0s 148us/step - loss: 1.2802 - accuracy: 0.6000\n",
            "Epoch 220/500\n",
            "20/20 [==============================] - 0s 148us/step - loss: 1.2756 - accuracy: 0.6000\n",
            "Epoch 221/500\n",
            "20/20 [==============================] - 0s 237us/step - loss: 1.2710 - accuracy: 0.6000\n",
            "Epoch 222/500\n",
            "20/20 [==============================] - 0s 244us/step - loss: 1.2664 - accuracy: 0.6000\n",
            "Epoch 223/500\n",
            "20/20 [==============================] - 0s 250us/step - loss: 1.2618 - accuracy: 0.6000\n",
            "Epoch 224/500\n",
            "20/20 [==============================] - 0s 241us/step - loss: 1.2571 - accuracy: 0.6000\n",
            "Epoch 225/500\n",
            "20/20 [==============================] - 0s 233us/step - loss: 1.2524 - accuracy: 0.6000\n",
            "Epoch 226/500\n",
            "20/20 [==============================] - 0s 241us/step - loss: 1.2477 - accuracy: 0.6000\n",
            "Epoch 227/500\n",
            "20/20 [==============================] - 0s 231us/step - loss: 1.2430 - accuracy: 0.6000\n",
            "Epoch 228/500\n",
            "20/20 [==============================] - 0s 251us/step - loss: 1.2383 - accuracy: 0.6000\n",
            "Epoch 229/500\n",
            "20/20 [==============================] - 0s 246us/step - loss: 1.2337 - accuracy: 0.6000\n",
            "Epoch 230/500\n",
            "20/20 [==============================] - 0s 244us/step - loss: 1.2290 - accuracy: 0.6000\n",
            "Epoch 231/500\n",
            "20/20 [==============================] - 0s 240us/step - loss: 1.2244 - accuracy: 0.6000\n",
            "Epoch 232/500\n",
            "20/20 [==============================] - 0s 240us/step - loss: 1.2197 - accuracy: 0.6000\n",
            "Epoch 233/500\n",
            "20/20 [==============================] - 0s 255us/step - loss: 1.2149 - accuracy: 0.6000\n",
            "Epoch 234/500\n",
            "20/20 [==============================] - 0s 263us/step - loss: 1.2102 - accuracy: 0.6000\n",
            "Epoch 235/500\n",
            "20/20 [==============================] - 0s 203us/step - loss: 1.2055 - accuracy: 0.6000\n",
            "Epoch 236/500\n",
            "20/20 [==============================] - 0s 188us/step - loss: 1.2008 - accuracy: 0.6000\n",
            "Epoch 237/500\n",
            "20/20 [==============================] - 0s 219us/step - loss: 1.1960 - accuracy: 0.6000\n",
            "Epoch 238/500\n",
            "20/20 [==============================] - 0s 201us/step - loss: 1.1913 - accuracy: 0.6000\n",
            "Epoch 239/500\n",
            "20/20 [==============================] - 0s 232us/step - loss: 1.1865 - accuracy: 0.6000\n",
            "Epoch 240/500\n",
            "20/20 [==============================] - 0s 183us/step - loss: 1.1817 - accuracy: 0.6000\n",
            "Epoch 241/500\n",
            "20/20 [==============================] - 0s 170us/step - loss: 1.1769 - accuracy: 0.6000\n",
            "Epoch 242/500\n",
            "20/20 [==============================] - 0s 147us/step - loss: 1.1721 - accuracy: 0.6000\n",
            "Epoch 243/500\n",
            "20/20 [==============================] - 0s 134us/step - loss: 1.1673 - accuracy: 0.6000\n",
            "Epoch 244/500\n",
            "20/20 [==============================] - 0s 145us/step - loss: 1.1626 - accuracy: 0.6000\n",
            "Epoch 245/500\n",
            "20/20 [==============================] - 0s 245us/step - loss: 1.1577 - accuracy: 0.6000\n",
            "Epoch 246/500\n",
            "20/20 [==============================] - 0s 200us/step - loss: 1.1530 - accuracy: 0.6000\n",
            "Epoch 247/500\n",
            "20/20 [==============================] - 0s 220us/step - loss: 1.1482 - accuracy: 0.6000\n",
            "Epoch 248/500\n",
            "20/20 [==============================] - 0s 178us/step - loss: 1.1434 - accuracy: 0.6000\n",
            "Epoch 249/500\n",
            "20/20 [==============================] - 0s 205us/step - loss: 1.1386 - accuracy: 0.6000\n",
            "Epoch 250/500\n",
            "20/20 [==============================] - 0s 191us/step - loss: 1.1338 - accuracy: 0.6000\n",
            "Epoch 251/500\n",
            "20/20 [==============================] - 0s 212us/step - loss: 1.1290 - accuracy: 0.6000\n",
            "Epoch 252/500\n",
            "20/20 [==============================] - 0s 206us/step - loss: 1.1242 - accuracy: 0.6500\n",
            "Epoch 253/500\n",
            "20/20 [==============================] - 0s 187us/step - loss: 1.1194 - accuracy: 0.6500\n",
            "Epoch 254/500\n",
            "20/20 [==============================] - 0s 183us/step - loss: 1.1145 - accuracy: 0.6500\n",
            "Epoch 255/500\n",
            "20/20 [==============================] - 0s 211us/step - loss: 1.1097 - accuracy: 0.6500\n",
            "Epoch 256/500\n",
            "20/20 [==============================] - 0s 185us/step - loss: 1.1048 - accuracy: 0.6500\n",
            "Epoch 257/500\n",
            "20/20 [==============================] - 0s 203us/step - loss: 1.0999 - accuracy: 0.6500\n",
            "Epoch 258/500\n",
            "20/20 [==============================] - 0s 211us/step - loss: 1.0950 - accuracy: 0.6500\n",
            "Epoch 259/500\n",
            "20/20 [==============================] - 0s 208us/step - loss: 1.0902 - accuracy: 0.6500\n",
            "Epoch 260/500\n",
            "20/20 [==============================] - 0s 201us/step - loss: 1.0853 - accuracy: 0.6500\n",
            "Epoch 261/500\n",
            "20/20 [==============================] - 0s 174us/step - loss: 1.0804 - accuracy: 0.6500\n",
            "Epoch 262/500\n",
            "20/20 [==============================] - 0s 189us/step - loss: 1.0755 - accuracy: 0.6500\n",
            "Epoch 263/500\n",
            "20/20 [==============================] - 0s 171us/step - loss: 1.0706 - accuracy: 0.6500\n",
            "Epoch 264/500\n",
            "20/20 [==============================] - 0s 206us/step - loss: 1.0656 - accuracy: 0.6500\n",
            "Epoch 265/500\n",
            "20/20 [==============================] - 0s 207us/step - loss: 1.0608 - accuracy: 0.6500\n",
            "Epoch 266/500\n",
            "20/20 [==============================] - 0s 196us/step - loss: 1.0559 - accuracy: 0.6500\n",
            "Epoch 267/500\n",
            "20/20 [==============================] - 0s 169us/step - loss: 1.0510 - accuracy: 0.6500\n",
            "Epoch 268/500\n",
            "20/20 [==============================] - 0s 225us/step - loss: 1.0461 - accuracy: 0.6500\n",
            "Epoch 269/500\n",
            "20/20 [==============================] - 0s 206us/step - loss: 1.0412 - accuracy: 0.6500\n",
            "Epoch 270/500\n",
            "20/20 [==============================] - 0s 242us/step - loss: 1.0364 - accuracy: 0.6500\n",
            "Epoch 271/500\n",
            "20/20 [==============================] - 0s 217us/step - loss: 1.0315 - accuracy: 0.6500\n",
            "Epoch 272/500\n",
            "20/20 [==============================] - 0s 234us/step - loss: 1.0265 - accuracy: 0.6500\n",
            "Epoch 273/500\n",
            "20/20 [==============================] - 0s 252us/step - loss: 1.0216 - accuracy: 0.6500\n",
            "Epoch 274/500\n",
            "20/20 [==============================] - 0s 213us/step - loss: 1.0166 - accuracy: 0.6500\n",
            "Epoch 275/500\n",
            "20/20 [==============================] - 0s 206us/step - loss: 1.0117 - accuracy: 0.6500\n",
            "Epoch 276/500\n",
            "20/20 [==============================] - 0s 211us/step - loss: 1.0067 - accuracy: 0.6500\n",
            "Epoch 277/500\n",
            "20/20 [==============================] - 0s 194us/step - loss: 1.0016 - accuracy: 0.6500\n",
            "Epoch 278/500\n",
            "20/20 [==============================] - 0s 227us/step - loss: 0.9965 - accuracy: 0.6500\n",
            "Epoch 279/500\n",
            "20/20 [==============================] - 0s 223us/step - loss: 0.9915 - accuracy: 0.6500\n",
            "Epoch 280/500\n",
            "20/20 [==============================] - 0s 197us/step - loss: 0.9864 - accuracy: 0.6500\n",
            "Epoch 281/500\n",
            "20/20 [==============================] - 0s 347us/step - loss: 0.9813 - accuracy: 0.6500\n",
            "Epoch 282/500\n",
            "20/20 [==============================] - 0s 239us/step - loss: 0.9762 - accuracy: 0.6500\n",
            "Epoch 283/500\n",
            "20/20 [==============================] - 0s 224us/step - loss: 0.9711 - accuracy: 0.6500\n",
            "Epoch 284/500\n",
            "20/20 [==============================] - 0s 234us/step - loss: 0.9659 - accuracy: 0.7000\n",
            "Epoch 285/500\n",
            "20/20 [==============================] - 0s 223us/step - loss: 0.9606 - accuracy: 0.7000\n",
            "Epoch 286/500\n",
            "20/20 [==============================] - 0s 197us/step - loss: 0.9553 - accuracy: 0.7000\n",
            "Epoch 287/500\n",
            "20/20 [==============================] - 0s 191us/step - loss: 0.9498 - accuracy: 0.7000\n",
            "Epoch 288/500\n",
            "20/20 [==============================] - 0s 308us/step - loss: 0.9444 - accuracy: 0.7500\n",
            "Epoch 289/500\n",
            "20/20 [==============================] - 0s 270us/step - loss: 0.9390 - accuracy: 0.7500\n",
            "Epoch 290/500\n",
            "20/20 [==============================] - 0s 208us/step - loss: 0.9335 - accuracy: 0.7500\n",
            "Epoch 291/500\n",
            "20/20 [==============================] - 0s 217us/step - loss: 0.9283 - accuracy: 0.7500\n",
            "Epoch 292/500\n",
            "20/20 [==============================] - 0s 185us/step - loss: 0.9230 - accuracy: 0.7500\n",
            "Epoch 293/500\n",
            "20/20 [==============================] - 0s 214us/step - loss: 0.9179 - accuracy: 0.7500\n",
            "Epoch 294/500\n",
            "20/20 [==============================] - 0s 250us/step - loss: 0.9127 - accuracy: 0.7500\n",
            "Epoch 295/500\n",
            "20/20 [==============================] - 0s 238us/step - loss: 0.9077 - accuracy: 0.7500\n",
            "Epoch 296/500\n",
            "20/20 [==============================] - 0s 232us/step - loss: 0.9027 - accuracy: 0.7500\n",
            "Epoch 297/500\n",
            "20/20 [==============================] - 0s 217us/step - loss: 0.8977 - accuracy: 0.7500\n",
            "Epoch 298/500\n",
            "20/20 [==============================] - 0s 180us/step - loss: 0.8927 - accuracy: 0.7500\n",
            "Epoch 299/500\n",
            "20/20 [==============================] - 0s 151us/step - loss: 0.8877 - accuracy: 0.7500\n",
            "Epoch 300/500\n",
            "20/20 [==============================] - 0s 180us/step - loss: 0.8826 - accuracy: 0.7500\n",
            "Epoch 301/500\n",
            "20/20 [==============================] - 0s 193us/step - loss: 0.8776 - accuracy: 0.7500\n",
            "Epoch 302/500\n",
            "20/20 [==============================] - 0s 270us/step - loss: 0.8725 - accuracy: 0.7500\n",
            "Epoch 303/500\n",
            "20/20 [==============================] - 0s 251us/step - loss: 0.8675 - accuracy: 0.8000\n",
            "Epoch 304/500\n",
            "20/20 [==============================] - 0s 216us/step - loss: 0.8624 - accuracy: 0.8000\n",
            "Epoch 305/500\n",
            "20/20 [==============================] - 0s 225us/step - loss: 0.8573 - accuracy: 0.8000\n",
            "Epoch 306/500\n",
            "20/20 [==============================] - 0s 240us/step - loss: 0.8523 - accuracy: 0.8000\n",
            "Epoch 307/500\n",
            "20/20 [==============================] - 0s 241us/step - loss: 0.8472 - accuracy: 0.8000\n",
            "Epoch 308/500\n",
            "20/20 [==============================] - 0s 199us/step - loss: 0.8421 - accuracy: 0.8000\n",
            "Epoch 309/500\n",
            "20/20 [==============================] - 0s 203us/step - loss: 0.8371 - accuracy: 0.8000\n",
            "Epoch 310/500\n",
            "20/20 [==============================] - 0s 243us/step - loss: 0.8321 - accuracy: 0.8000\n",
            "Epoch 311/500\n",
            "20/20 [==============================] - 0s 219us/step - loss: 0.8270 - accuracy: 0.8000\n",
            "Epoch 312/500\n",
            "20/20 [==============================] - 0s 189us/step - loss: 0.8220 - accuracy: 0.8500\n",
            "Epoch 313/500\n",
            "20/20 [==============================] - 0s 145us/step - loss: 0.8170 - accuracy: 0.8500\n",
            "Epoch 314/500\n",
            "20/20 [==============================] - 0s 155us/step - loss: 0.8120 - accuracy: 0.8500\n",
            "Epoch 315/500\n",
            "20/20 [==============================] - 0s 170us/step - loss: 0.8070 - accuracy: 0.8500\n",
            "Epoch 316/500\n",
            "20/20 [==============================] - 0s 176us/step - loss: 0.8020 - accuracy: 0.8500\n",
            "Epoch 317/500\n",
            "20/20 [==============================] - 0s 165us/step - loss: 0.7970 - accuracy: 0.8500\n",
            "Epoch 318/500\n",
            "20/20 [==============================] - 0s 202us/step - loss: 0.7920 - accuracy: 0.8500\n",
            "Epoch 319/500\n",
            "20/20 [==============================] - 0s 162us/step - loss: 0.7871 - accuracy: 0.8500\n",
            "Epoch 320/500\n",
            "20/20 [==============================] - 0s 173us/step - loss: 0.7821 - accuracy: 0.9000\n",
            "Epoch 321/500\n",
            "20/20 [==============================] - 0s 229us/step - loss: 0.7771 - accuracy: 0.9000\n",
            "Epoch 322/500\n",
            "20/20 [==============================] - 0s 232us/step - loss: 0.7721 - accuracy: 0.9000\n",
            "Epoch 323/500\n",
            "20/20 [==============================] - 0s 256us/step - loss: 0.7671 - accuracy: 0.9000\n",
            "Epoch 324/500\n",
            "20/20 [==============================] - 0s 204us/step - loss: 0.7621 - accuracy: 0.9000\n",
            "Epoch 325/500\n",
            "20/20 [==============================] - 0s 175us/step - loss: 0.7571 - accuracy: 0.9000\n",
            "Epoch 326/500\n",
            "20/20 [==============================] - 0s 143us/step - loss: 0.7521 - accuracy: 0.9000\n",
            "Epoch 327/500\n",
            "20/20 [==============================] - 0s 179us/step - loss: 0.7472 - accuracy: 0.9000\n",
            "Epoch 328/500\n",
            "20/20 [==============================] - 0s 230us/step - loss: 0.7422 - accuracy: 0.9000\n",
            "Epoch 329/500\n",
            "20/20 [==============================] - 0s 200us/step - loss: 0.7373 - accuracy: 0.9000\n",
            "Epoch 330/500\n",
            "20/20 [==============================] - 0s 199us/step - loss: 0.7325 - accuracy: 0.9000\n",
            "Epoch 331/500\n",
            "20/20 [==============================] - 0s 190us/step - loss: 0.7276 - accuracy: 0.9000\n",
            "Epoch 332/500\n",
            "20/20 [==============================] - 0s 212us/step - loss: 0.7226 - accuracy: 0.9000\n",
            "Epoch 333/500\n",
            "20/20 [==============================] - 0s 208us/step - loss: 0.7178 - accuracy: 0.9000\n",
            "Epoch 334/500\n",
            "20/20 [==============================] - 0s 150us/step - loss: 0.7130 - accuracy: 0.9000\n",
            "Epoch 335/500\n",
            "20/20 [==============================] - 0s 160us/step - loss: 0.7081 - accuracy: 0.9000\n",
            "Epoch 336/500\n",
            "20/20 [==============================] - 0s 164us/step - loss: 0.7033 - accuracy: 0.9000\n",
            "Epoch 337/500\n",
            "20/20 [==============================] - 0s 169us/step - loss: 0.6985 - accuracy: 0.9000\n",
            "Epoch 338/500\n",
            "20/20 [==============================] - 0s 156us/step - loss: 0.6936 - accuracy: 0.9000\n",
            "Epoch 339/500\n",
            "20/20 [==============================] - 0s 162us/step - loss: 0.6888 - accuracy: 0.9000\n",
            "Epoch 340/500\n",
            "20/20 [==============================] - 0s 150us/step - loss: 0.6841 - accuracy: 0.9000\n",
            "Epoch 341/500\n",
            "20/20 [==============================] - 0s 208us/step - loss: 0.6793 - accuracy: 0.9000\n",
            "Epoch 342/500\n",
            "20/20 [==============================] - 0s 193us/step - loss: 0.6745 - accuracy: 0.9000\n",
            "Epoch 343/500\n",
            "20/20 [==============================] - 0s 152us/step - loss: 0.6698 - accuracy: 0.9000\n",
            "Epoch 344/500\n",
            "20/20 [==============================] - 0s 136us/step - loss: 0.6651 - accuracy: 0.9000\n",
            "Epoch 345/500\n",
            "20/20 [==============================] - 0s 198us/step - loss: 0.6604 - accuracy: 0.9000\n",
            "Epoch 346/500\n",
            "20/20 [==============================] - 0s 224us/step - loss: 0.6558 - accuracy: 0.9000\n",
            "Epoch 347/500\n",
            "20/20 [==============================] - 0s 163us/step - loss: 0.6512 - accuracy: 0.9000\n",
            "Epoch 348/500\n",
            "20/20 [==============================] - 0s 267us/step - loss: 0.6466 - accuracy: 0.9000\n",
            "Epoch 349/500\n",
            "20/20 [==============================] - 0s 214us/step - loss: 0.6420 - accuracy: 0.9000\n",
            "Epoch 350/500\n",
            "20/20 [==============================] - 0s 247us/step - loss: 0.6375 - accuracy: 0.9000\n",
            "Epoch 351/500\n",
            "20/20 [==============================] - 0s 186us/step - loss: 0.6329 - accuracy: 0.9000\n",
            "Epoch 352/500\n",
            "20/20 [==============================] - 0s 245us/step - loss: 0.6283 - accuracy: 0.9000\n",
            "Epoch 353/500\n",
            "20/20 [==============================] - 0s 196us/step - loss: 0.6238 - accuracy: 0.9000\n",
            "Epoch 354/500\n",
            "20/20 [==============================] - 0s 172us/step - loss: 0.6193 - accuracy: 0.9000\n",
            "Epoch 355/500\n",
            "20/20 [==============================] - 0s 221us/step - loss: 0.6148 - accuracy: 0.9000\n",
            "Epoch 356/500\n",
            "20/20 [==============================] - 0s 152us/step - loss: 0.6103 - accuracy: 0.9000\n",
            "Epoch 357/500\n",
            "20/20 [==============================] - 0s 185us/step - loss: 0.6059 - accuracy: 0.9000\n",
            "Epoch 358/500\n",
            "20/20 [==============================] - 0s 172us/step - loss: 0.6015 - accuracy: 0.9000\n",
            "Epoch 359/500\n",
            "20/20 [==============================] - 0s 128us/step - loss: 0.5972 - accuracy: 0.9000\n",
            "Epoch 360/500\n",
            "20/20 [==============================] - 0s 160us/step - loss: 0.5928 - accuracy: 0.9000\n",
            "Epoch 361/500\n",
            "20/20 [==============================] - 0s 197us/step - loss: 0.5885 - accuracy: 0.9000\n",
            "Epoch 362/500\n",
            "20/20 [==============================] - 0s 180us/step - loss: 0.5841 - accuracy: 0.9000\n",
            "Epoch 363/500\n",
            "20/20 [==============================] - 0s 215us/step - loss: 0.5798 - accuracy: 0.9000\n",
            "Epoch 364/500\n",
            "20/20 [==============================] - 0s 194us/step - loss: 0.5755 - accuracy: 0.9000\n",
            "Epoch 365/500\n",
            "20/20 [==============================] - 0s 266us/step - loss: 0.5712 - accuracy: 0.9000\n",
            "Epoch 366/500\n",
            "20/20 [==============================] - 0s 215us/step - loss: 0.5669 - accuracy: 0.9000\n",
            "Epoch 367/500\n",
            "20/20 [==============================] - 0s 218us/step - loss: 0.5626 - accuracy: 0.9000\n",
            "Epoch 368/500\n",
            "20/20 [==============================] - 0s 216us/step - loss: 0.5584 - accuracy: 0.9000\n",
            "Epoch 369/500\n",
            "20/20 [==============================] - 0s 213us/step - loss: 0.5542 - accuracy: 0.9000\n",
            "Epoch 370/500\n",
            "20/20 [==============================] - 0s 209us/step - loss: 0.5500 - accuracy: 0.9000\n",
            "Epoch 371/500\n",
            "20/20 [==============================] - 0s 237us/step - loss: 0.5458 - accuracy: 0.9000\n",
            "Epoch 372/500\n",
            "20/20 [==============================] - 0s 235us/step - loss: 0.5416 - accuracy: 0.9000\n",
            "Epoch 373/500\n",
            "20/20 [==============================] - 0s 326us/step - loss: 0.5375 - accuracy: 0.9000\n",
            "Epoch 374/500\n",
            "20/20 [==============================] - 0s 201us/step - loss: 0.5333 - accuracy: 0.9000\n",
            "Epoch 375/500\n",
            "20/20 [==============================] - 0s 207us/step - loss: 0.5292 - accuracy: 0.9000\n",
            "Epoch 376/500\n",
            "20/20 [==============================] - 0s 230us/step - loss: 0.5251 - accuracy: 0.9000\n",
            "Epoch 377/500\n",
            "20/20 [==============================] - 0s 243us/step - loss: 0.5210 - accuracy: 0.9000\n",
            "Epoch 378/500\n",
            "20/20 [==============================] - 0s 233us/step - loss: 0.5170 - accuracy: 0.9000\n",
            "Epoch 379/500\n",
            "20/20 [==============================] - 0s 230us/step - loss: 0.5129 - accuracy: 0.9000\n",
            "Epoch 380/500\n",
            "20/20 [==============================] - 0s 227us/step - loss: 0.5089 - accuracy: 0.9000\n",
            "Epoch 381/500\n",
            "20/20 [==============================] - 0s 224us/step - loss: 0.5049 - accuracy: 0.9000\n",
            "Epoch 382/500\n",
            "20/20 [==============================] - 0s 225us/step - loss: 0.5009 - accuracy: 0.9500\n",
            "Epoch 383/500\n",
            "20/20 [==============================] - 0s 217us/step - loss: 0.4969 - accuracy: 0.9500\n",
            "Epoch 384/500\n",
            "20/20 [==============================] - 0s 516us/step - loss: 0.4930 - accuracy: 0.9500\n",
            "Epoch 385/500\n",
            "20/20 [==============================] - 0s 239us/step - loss: 0.4891 - accuracy: 0.9500\n",
            "Epoch 386/500\n",
            "20/20 [==============================] - 0s 266us/step - loss: 0.4852 - accuracy: 0.9500\n",
            "Epoch 387/500\n",
            "20/20 [==============================] - 0s 228us/step - loss: 0.4813 - accuracy: 0.9500\n",
            "Epoch 388/500\n",
            "20/20 [==============================] - 0s 208us/step - loss: 0.4775 - accuracy: 0.9500\n",
            "Epoch 389/500\n",
            "20/20 [==============================] - 0s 240us/step - loss: 0.4737 - accuracy: 0.9500\n",
            "Epoch 390/500\n",
            "20/20 [==============================] - 0s 239us/step - loss: 0.4699 - accuracy: 0.9500\n",
            "Epoch 391/500\n",
            "20/20 [==============================] - 0s 248us/step - loss: 0.4661 - accuracy: 0.9500\n",
            "Epoch 392/500\n",
            "20/20 [==============================] - 0s 273us/step - loss: 0.4623 - accuracy: 0.9500\n",
            "Epoch 393/500\n",
            "20/20 [==============================] - 0s 253us/step - loss: 0.4586 - accuracy: 0.9500\n",
            "Epoch 394/500\n",
            "20/20 [==============================] - 0s 249us/step - loss: 0.4548 - accuracy: 0.9500\n",
            "Epoch 395/500\n",
            "20/20 [==============================] - 0s 210us/step - loss: 0.4511 - accuracy: 0.9500\n",
            "Epoch 396/500\n",
            "20/20 [==============================] - 0s 200us/step - loss: 0.4474 - accuracy: 0.9500\n",
            "Epoch 397/500\n",
            "20/20 [==============================] - 0s 196us/step - loss: 0.4437 - accuracy: 0.9500\n",
            "Epoch 398/500\n",
            "20/20 [==============================] - 0s 188us/step - loss: 0.4401 - accuracy: 0.9500\n",
            "Epoch 399/500\n",
            "20/20 [==============================] - 0s 235us/step - loss: 0.4365 - accuracy: 0.9500\n",
            "Epoch 400/500\n",
            "20/20 [==============================] - 0s 263us/step - loss: 0.4328 - accuracy: 0.9500\n",
            "Epoch 401/500\n",
            "20/20 [==============================] - 0s 267us/step - loss: 0.4292 - accuracy: 0.9500\n",
            "Epoch 402/500\n",
            "20/20 [==============================] - 0s 221us/step - loss: 0.4256 - accuracy: 0.9500\n",
            "Epoch 403/500\n",
            "20/20 [==============================] - 0s 190us/step - loss: 0.4221 - accuracy: 0.9500\n",
            "Epoch 404/500\n",
            "20/20 [==============================] - 0s 217us/step - loss: 0.4186 - accuracy: 0.9500\n",
            "Epoch 405/500\n",
            "20/20 [==============================] - 0s 217us/step - loss: 0.4151 - accuracy: 0.9500\n",
            "Epoch 406/500\n",
            "20/20 [==============================] - 0s 253us/step - loss: 0.4116 - accuracy: 0.9500\n",
            "Epoch 407/500\n",
            "20/20 [==============================] - 0s 167us/step - loss: 0.4081 - accuracy: 0.9500\n",
            "Epoch 408/500\n",
            "20/20 [==============================] - 0s 179us/step - loss: 0.4047 - accuracy: 0.9500\n",
            "Epoch 409/500\n",
            "20/20 [==============================] - 0s 217us/step - loss: 0.4013 - accuracy: 0.9500\n",
            "Epoch 410/500\n",
            "20/20 [==============================] - 0s 195us/step - loss: 0.3980 - accuracy: 0.9500\n",
            "Epoch 411/500\n",
            "20/20 [==============================] - 0s 238us/step - loss: 0.3947 - accuracy: 0.9500\n",
            "Epoch 412/500\n",
            "20/20 [==============================] - 0s 182us/step - loss: 0.3913 - accuracy: 0.9500\n",
            "Epoch 413/500\n",
            "20/20 [==============================] - 0s 220us/step - loss: 0.3880 - accuracy: 0.9500\n",
            "Epoch 414/500\n",
            "20/20 [==============================] - 0s 225us/step - loss: 0.3847 - accuracy: 0.9500\n",
            "Epoch 415/500\n",
            "20/20 [==============================] - 0s 164us/step - loss: 0.3814 - accuracy: 0.9500\n",
            "Epoch 416/500\n",
            "20/20 [==============================] - 0s 193us/step - loss: 0.3782 - accuracy: 0.9500\n",
            "Epoch 417/500\n",
            "20/20 [==============================] - 0s 249us/step - loss: 0.3749 - accuracy: 0.9500\n",
            "Epoch 418/500\n",
            "20/20 [==============================] - 0s 181us/step - loss: 0.3717 - accuracy: 0.9500\n",
            "Epoch 419/500\n",
            "20/20 [==============================] - 0s 201us/step - loss: 0.3686 - accuracy: 0.9500\n",
            "Epoch 420/500\n",
            "20/20 [==============================] - 0s 389us/step - loss: 0.3654 - accuracy: 0.9500\n",
            "Epoch 421/500\n",
            "20/20 [==============================] - 0s 354us/step - loss: 0.3623 - accuracy: 0.9500\n",
            "Epoch 422/500\n",
            "20/20 [==============================] - 0s 156us/step - loss: 0.3591 - accuracy: 0.9500\n",
            "Epoch 423/500\n",
            "20/20 [==============================] - 0s 132us/step - loss: 0.3561 - accuracy: 0.9500\n",
            "Epoch 424/500\n",
            "20/20 [==============================] - 0s 170us/step - loss: 0.3530 - accuracy: 0.9500\n",
            "Epoch 425/500\n",
            "20/20 [==============================] - 0s 171us/step - loss: 0.3500 - accuracy: 0.9500\n",
            "Epoch 426/500\n",
            "20/20 [==============================] - 0s 172us/step - loss: 0.3470 - accuracy: 0.9500\n",
            "Epoch 427/500\n",
            "20/20 [==============================] - 0s 189us/step - loss: 0.3440 - accuracy: 0.9500\n",
            "Epoch 428/500\n",
            "20/20 [==============================] - 0s 133us/step - loss: 0.3410 - accuracy: 1.0000\n",
            "Epoch 429/500\n",
            "20/20 [==============================] - 0s 230us/step - loss: 0.3380 - accuracy: 1.0000\n",
            "Epoch 430/500\n",
            "20/20 [==============================] - 0s 198us/step - loss: 0.3351 - accuracy: 1.0000\n",
            "Epoch 431/500\n",
            "20/20 [==============================] - 0s 191us/step - loss: 0.3322 - accuracy: 1.0000\n",
            "Epoch 432/500\n",
            "20/20 [==============================] - 0s 248us/step - loss: 0.3293 - accuracy: 1.0000\n",
            "Epoch 433/500\n",
            "20/20 [==============================] - 0s 207us/step - loss: 0.3265 - accuracy: 1.0000\n",
            "Epoch 434/500\n",
            "20/20 [==============================] - 0s 192us/step - loss: 0.3236 - accuracy: 1.0000\n",
            "Epoch 435/500\n",
            "20/20 [==============================] - 0s 203us/step - loss: 0.3208 - accuracy: 1.0000\n",
            "Epoch 436/500\n",
            "20/20 [==============================] - 0s 156us/step - loss: 0.3180 - accuracy: 1.0000\n",
            "Epoch 437/500\n",
            "20/20 [==============================] - 0s 190us/step - loss: 0.3152 - accuracy: 1.0000\n",
            "Epoch 438/500\n",
            "20/20 [==============================] - 0s 256us/step - loss: 0.3125 - accuracy: 1.0000\n",
            "Epoch 439/500\n",
            "20/20 [==============================] - 0s 223us/step - loss: 0.3098 - accuracy: 1.0000\n",
            "Epoch 440/500\n",
            "20/20 [==============================] - 0s 213us/step - loss: 0.3071 - accuracy: 1.0000\n",
            "Epoch 441/500\n",
            "20/20 [==============================] - 0s 194us/step - loss: 0.3044 - accuracy: 1.0000\n",
            "Epoch 442/500\n",
            "20/20 [==============================] - 0s 171us/step - loss: 0.3018 - accuracy: 1.0000\n",
            "Epoch 443/500\n",
            "20/20 [==============================] - 0s 145us/step - loss: 0.2991 - accuracy: 1.0000\n",
            "Epoch 444/500\n",
            "20/20 [==============================] - 0s 174us/step - loss: 0.2965 - accuracy: 1.0000\n",
            "Epoch 445/500\n",
            "20/20 [==============================] - 0s 242us/step - loss: 0.2939 - accuracy: 1.0000\n",
            "Epoch 446/500\n",
            "20/20 [==============================] - 0s 244us/step - loss: 0.2914 - accuracy: 1.0000\n",
            "Epoch 447/500\n",
            "20/20 [==============================] - 0s 233us/step - loss: 0.2889 - accuracy: 1.0000\n",
            "Epoch 448/500\n",
            "20/20 [==============================] - 0s 234us/step - loss: 0.2863 - accuracy: 1.0000\n",
            "Epoch 449/500\n",
            "20/20 [==============================] - 0s 145us/step - loss: 0.2838 - accuracy: 1.0000\n",
            "Epoch 450/500\n",
            "20/20 [==============================] - 0s 130us/step - loss: 0.2814 - accuracy: 1.0000\n",
            "Epoch 451/500\n",
            "20/20 [==============================] - 0s 164us/step - loss: 0.2789 - accuracy: 1.0000\n",
            "Epoch 452/500\n",
            "20/20 [==============================] - 0s 130us/step - loss: 0.2765 - accuracy: 1.0000\n",
            "Epoch 453/500\n",
            "20/20 [==============================] - 0s 187us/step - loss: 0.2740 - accuracy: 1.0000\n",
            "Epoch 454/500\n",
            "20/20 [==============================] - 0s 159us/step - loss: 0.2717 - accuracy: 1.0000\n",
            "Epoch 455/500\n",
            "20/20 [==============================] - 0s 158us/step - loss: 0.2693 - accuracy: 1.0000\n",
            "Epoch 456/500\n",
            "20/20 [==============================] - 0s 172us/step - loss: 0.2669 - accuracy: 1.0000\n",
            "Epoch 457/500\n",
            "20/20 [==============================] - 0s 161us/step - loss: 0.2646 - accuracy: 1.0000\n",
            "Epoch 458/500\n",
            "20/20 [==============================] - 0s 174us/step - loss: 0.2623 - accuracy: 1.0000\n",
            "Epoch 459/500\n",
            "20/20 [==============================] - 0s 153us/step - loss: 0.2600 - accuracy: 1.0000\n",
            "Epoch 460/500\n",
            "20/20 [==============================] - 0s 250us/step - loss: 0.2577 - accuracy: 1.0000\n",
            "Epoch 461/500\n",
            "20/20 [==============================] - 0s 177us/step - loss: 0.2554 - accuracy: 1.0000\n",
            "Epoch 462/500\n",
            "20/20 [==============================] - 0s 207us/step - loss: 0.2532 - accuracy: 1.0000\n",
            "Epoch 463/500\n",
            "20/20 [==============================] - 0s 248us/step - loss: 0.2510 - accuracy: 1.0000\n",
            "Epoch 464/500\n",
            "20/20 [==============================] - 0s 239us/step - loss: 0.2488 - accuracy: 1.0000\n",
            "Epoch 465/500\n",
            "20/20 [==============================] - 0s 243us/step - loss: 0.2467 - accuracy: 1.0000\n",
            "Epoch 466/500\n",
            "20/20 [==============================] - 0s 201us/step - loss: 0.2445 - accuracy: 1.0000\n",
            "Epoch 467/500\n",
            "20/20 [==============================] - 0s 244us/step - loss: 0.2424 - accuracy: 1.0000\n",
            "Epoch 468/500\n",
            "20/20 [==============================] - 0s 232us/step - loss: 0.2403 - accuracy: 1.0000\n",
            "Epoch 469/500\n",
            "20/20 [==============================] - 0s 223us/step - loss: 0.2382 - accuracy: 1.0000\n",
            "Epoch 470/500\n",
            "20/20 [==============================] - 0s 245us/step - loss: 0.2361 - accuracy: 1.0000\n",
            "Epoch 471/500\n",
            "20/20 [==============================] - 0s 254us/step - loss: 0.2341 - accuracy: 1.0000\n",
            "Epoch 472/500\n",
            "20/20 [==============================] - 0s 254us/step - loss: 0.2321 - accuracy: 1.0000\n",
            "Epoch 473/500\n",
            "20/20 [==============================] - 0s 252us/step - loss: 0.2300 - accuracy: 1.0000\n",
            "Epoch 474/500\n",
            "20/20 [==============================] - 0s 223us/step - loss: 0.2280 - accuracy: 1.0000\n",
            "Epoch 475/500\n",
            "20/20 [==============================] - 0s 248us/step - loss: 0.2260 - accuracy: 1.0000\n",
            "Epoch 476/500\n",
            "20/20 [==============================] - 0s 269us/step - loss: 0.2241 - accuracy: 1.0000\n",
            "Epoch 477/500\n",
            "20/20 [==============================] - 0s 256us/step - loss: 0.2221 - accuracy: 1.0000\n",
            "Epoch 478/500\n",
            "20/20 [==============================] - 0s 253us/step - loss: 0.2201 - accuracy: 1.0000\n",
            "Epoch 479/500\n",
            "20/20 [==============================] - 0s 229us/step - loss: 0.2182 - accuracy: 1.0000\n",
            "Epoch 480/500\n",
            "20/20 [==============================] - 0s 184us/step - loss: 0.2163 - accuracy: 1.0000\n",
            "Epoch 481/500\n",
            "20/20 [==============================] - 0s 214us/step - loss: 0.2144 - accuracy: 1.0000\n",
            "Epoch 482/500\n",
            "20/20 [==============================] - 0s 194us/step - loss: 0.2125 - accuracy: 1.0000\n",
            "Epoch 483/500\n",
            "20/20 [==============================] - 0s 243us/step - loss: 0.2107 - accuracy: 1.0000\n",
            "Epoch 484/500\n",
            "20/20 [==============================] - 0s 240us/step - loss: 0.2088 - accuracy: 1.0000\n",
            "Epoch 485/500\n",
            "20/20 [==============================] - 0s 207us/step - loss: 0.2070 - accuracy: 1.0000\n",
            "Epoch 486/500\n",
            "20/20 [==============================] - 0s 190us/step - loss: 0.2052 - accuracy: 1.0000\n",
            "Epoch 487/500\n",
            "20/20 [==============================] - 0s 188us/step - loss: 0.2034 - accuracy: 1.0000\n",
            "Epoch 488/500\n",
            "20/20 [==============================] - 0s 182us/step - loss: 0.2016 - accuracy: 1.0000\n",
            "Epoch 489/500\n",
            "20/20 [==============================] - 0s 204us/step - loss: 0.1998 - accuracy: 1.0000\n",
            "Epoch 490/500\n",
            "20/20 [==============================] - 0s 203us/step - loss: 0.1981 - accuracy: 1.0000\n",
            "Epoch 491/500\n",
            "20/20 [==============================] - 0s 217us/step - loss: 0.1964 - accuracy: 1.0000\n",
            "Epoch 492/500\n",
            "20/20 [==============================] - 0s 215us/step - loss: 0.1947 - accuracy: 1.0000\n",
            "Epoch 493/500\n",
            "20/20 [==============================] - 0s 214us/step - loss: 0.1931 - accuracy: 1.0000\n",
            "Epoch 494/500\n",
            "20/20 [==============================] - 0s 216us/step - loss: 0.1914 - accuracy: 1.0000\n",
            "Epoch 495/500\n",
            "20/20 [==============================] - 0s 208us/step - loss: 0.1898 - accuracy: 1.0000\n",
            "Epoch 496/500\n",
            "20/20 [==============================] - 0s 187us/step - loss: 0.1881 - accuracy: 1.0000\n",
            "Epoch 497/500\n",
            "20/20 [==============================] - 0s 193us/step - loss: 0.1865 - accuracy: 1.0000\n",
            "Epoch 498/500\n",
            "20/20 [==============================] - 0s 191us/step - loss: 0.1849 - accuracy: 1.0000\n",
            "Epoch 499/500\n",
            "20/20 [==============================] - 0s 207us/step - loss: 0.1833 - accuracy: 1.0000\n",
            "Epoch 500/500\n",
            "20/20 [==============================] - 0s 192us/step - loss: 0.1817 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDl5G_NxYeWw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85d9eed0-d981-4c3d-cb81-1cd184ff09fe"
      },
      "source": [
        "score_subset = model_m5.evaluate(X_train_subset, y_train_subset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r20/20 [==============================] - 0s 965us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHnRaAOTYeMN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0f134e89-d00e-4083-9e9e-372b2c49b342"
      },
      "source": [
        "print('Accuracy: ', score_subset[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaXliqihidMC",
        "colab_type": "text"
      },
      "source": [
        "**Observations:**\n",
        " - For a higher epoch count and for the small subset of data, we are able to overfit completely. The accuracy is 1 in the end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBdtQIISEYc3",
        "colab_type": "text"
      },
      "source": [
        "## 6. Load the original dataset with all the images and prepare the data for modelling\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs69w7XqFMZ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "c0b0b4b2-592f-4c2d-9bc9-4ae5194f6945"
      },
      "source": [
        "orig_model = train_and_test_loop(X_train, y_train, hidden_nodes=256, output_nodes=10, btc_size=100, iter_epochs=10, lr=0.01, Lambda=0.01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_26 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/10\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 2.3232 - accuracy: 0.1918\n",
            "Epoch 2/10\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 1.6634 - accuracy: 0.4481\n",
            "Epoch 3/10\n",
            "42000/42000 [==============================] - 4s 85us/step - loss: 1.3342 - accuracy: 0.5825\n",
            "Epoch 4/10\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 1.1831 - accuracy: 0.6398\n",
            "Epoch 5/10\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 1.0791 - accuracy: 0.6749\n",
            "Epoch 6/10\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.9961 - accuracy: 0.7023\n",
            "Epoch 7/10\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.9332 - accuracy: 0.7213\n",
            "Epoch 8/10\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.8961 - accuracy: 0.7333\n",
            "Epoch 9/10\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.8553 - accuracy: 0.7420\n",
            "Epoch 10/10\n",
            "42000/42000 [==============================] - 4s 91us/step - loss: 0.8267 - accuracy: 0.7524\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNRBAxaeUUFx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6d8fb6cb-fe0b-4c84-cef5-245264f9bc7e"
      },
      "source": [
        "score_orig = orig_model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18000/18000 [==============================] - 1s 45us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTgilyi0Uadq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d862e9f7-a39a-4fe8-d852-f08b2049ae99"
      },
      "source": [
        "print('Accuracy: ',score_orig[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7334444522857666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFZrMp98ir5n",
        "colab_type": "text"
      },
      "source": [
        "**Observation:**\n",
        " - consider the initial accuracy on train and test data. Not bad for start with around 0.73 and 0.75"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdP-K3RUEYWA",
        "colab_type": "text"
      },
      "source": [
        "## 7. Start with a small Regularization. Keep adjusting the learning rate to check the loss. Record findings\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXwBBEpQFQ4O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "01b1e677-48b3-402c-c16f-df4443b7e0ce"
      },
      "source": [
        "model_m6 = train_and_test_loop(X_train, y_train, hidden_nodes=256, output_nodes=10, btc_size=1000, iter_epochs=10, lr=1e7, Lambda=1e-7)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_31 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/10\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: nan - accuracy: 0.1011\n",
            "Epoch 2/10\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 3/10\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 4/10\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 5/10\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 6/10\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 7/10\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 8/10\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 9/10\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 10/10\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: nan - accuracy: 0.0997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRUyh5rTboT4",
        "colab_type": "text"
      },
      "source": [
        "**Observation**\n",
        " - Loss is very high and exploding. That infers the learning rate is very high**\n",
        " - Now reduce the learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfgR0d5AaICd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "ff824e0d-a92e-4835-c222-15fff19aaf11"
      },
      "source": [
        "model_m7 = train_and_test_loop(X_train, y_train, hidden_nodes=256, output_nodes=10, btc_size=1000, iter_epochs=10, lr=1e3, Lambda=1e-7)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_36 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/10\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: nan - accuracy: 0.1002\n",
            "Epoch 2/10\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 3/10\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 4/10\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 5/10\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 6/10\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 7/10\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 8/10\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 9/10\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 10/10\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: nan - accuracy: 0.0997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALvH18A6cgPC",
        "colab_type": "text"
      },
      "source": [
        "**Observation**\n",
        " - Loss is still very high. Reduce the learing rate\n",
        " - Lambda is chosen as very small 1e-7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdzhMzlZaH0f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "fa805b69-0db7-453e-fea0-f8a45389f854"
      },
      "source": [
        "model_m8 = train_and_test_loop(X_train, y_train, hidden_nodes=256, output_nodes=10, btc_size=1000, iter_epochs=10, lr=1e-3, Lambda=1e-7)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_41 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/10\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3095 - accuracy: 0.1035\n",
            "Epoch 2/10\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2992 - accuracy: 0.1100\n",
            "Epoch 3/10\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.2966 - accuracy: 0.1275\n",
            "Epoch 4/10\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2944 - accuracy: 0.1377\n",
            "Epoch 5/10\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2923 - accuracy: 0.1464\n",
            "Epoch 6/10\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.2904 - accuracy: 0.1561\n",
            "Epoch 7/10\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2885 - accuracy: 0.1651\n",
            "Epoch 8/10\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.2867 - accuracy: 0.1734\n",
            "Epoch 9/10\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2846 - accuracy: 0.1849\n",
            "Epoch 10/10\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2825 - accuracy: 0.1949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8XbZI67cqKZ",
        "colab_type": "text"
      },
      "source": [
        "**Observations**\n",
        " - Now Loss is less, but accuracy is not increasing sufficient on the train data\n",
        " - Lets try other tuning options with the hyper parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdotCAZcEYOY",
        "colab_type": "text"
      },
      "source": [
        "## 8. Perform Hyperparameter Optimization . Record findings\t\n",
        "\n",
        "**Hyperparameter Optimization**\n",
        "\n",
        " - *Cross validation Strategy*\n",
        "   -  Do coarse -> fine cross-validation in stages\n",
        "   - First stage: only a few epochs to get rough idea of what params work\n",
        "   - Second stage: longer running time, finer search\n",
        "   - â€¦ (repeat as necessary)\n",
        "\n",
        "**Tip for detecting explosions in the solver:**\n",
        " - *If the cost is ever > 3 * original cost, break out early*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpbY8rw3fgFy",
        "colab_type": "text"
      },
      "source": [
        "### 8.1. Run a coarse search for 10 times with different lr(Learning rate) and lambda(regularization) values with 100 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5ku-5oQkMdN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "1ae60bfa-c935-4337-9db0-7b68f0181ecf"
      },
      "source": [
        "p = 1e-7\n",
        "for k in range(1,10):\n",
        "  if k ==1:\n",
        "    lr = 10*p\n",
        "  else:\n",
        "    lr = lr*10\n",
        "    print(lr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9.999999999999999e-06\n",
            "9.999999999999999e-05\n",
            "0.001\n",
            "0.01\n",
            "0.1\n",
            "1.0\n",
            "10.0\n",
            "100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UMIw5O9FRmZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bba75a7d-780b-4f09-e543-7672f26082ee"
      },
      "source": [
        "import math\n",
        "cns = 1e-7\n",
        "for k in range(1,10):\n",
        "    if k==1:\n",
        "      lr = cns*10\n",
        "      Lambda = cns*10\n",
        "    else:\n",
        "      lr = lr*10\n",
        "      Lambda = Lambda*10\n",
        "    model_temp = train_and_test_loop(X_train, y_train, hidden_nodes=256, output_nodes=10, btc_size=1000, iter_epochs=5, lr=lr, Lambda=Lambda,verb=False)\n",
        "    best_acc = model_temp.evaluate(X_train, y_train)\n",
        "    print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 100, best_acc, lr, Lambda))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_46 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/5\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 2.3160 - accuracy: 0.0949\n",
            "Epoch 2/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3159 - accuracy: 0.0950\n",
            "Epoch 3/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3159 - accuracy: 0.0950\n",
            "Epoch 4/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3158 - accuracy: 0.0950\n",
            "Epoch 5/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3158 - accuracy: 0.0949\n",
            "42000/42000 [==============================] - 2s 42us/step\n",
            "Try 1/100: Best_val_acc: [2.3157257608686175, 0.09497618675231934], lr: 1e-06, Lambda: 1e-06\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_51 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3468 - accuracy: 0.0965\n",
            "Epoch 2/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3444 - accuracy: 0.0974\n",
            "Epoch 3/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3420 - accuracy: 0.0990\n",
            "Epoch 4/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3398 - accuracy: 0.0994\n",
            "Epoch 5/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3377 - accuracy: 0.0998\n",
            "42000/42000 [==============================] - 2s 43us/step\n",
            "Try 2/100: Best_val_acc: [2.3367325810023716, 0.10019047558307648], lr: 9.999999999999999e-06, Lambda: 9.999999999999999e-06\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_56 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/5\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 2.3253 - accuracy: 0.0924\n",
            "Epoch 2/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3185 - accuracy: 0.0925\n",
            "Epoch 3/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3141 - accuracy: 0.0950\n",
            "Epoch 4/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3112 - accuracy: 0.0985\n",
            "Epoch 5/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3092 - accuracy: 0.1018\n",
            "42000/42000 [==============================] - 2s 43us/step\n",
            "Try 3/100: Best_val_acc: [2.3083507949284146, 0.10314285755157471], lr: 9.999999999999999e-05, Lambda: 9.999999999999999e-05\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_61 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3271 - accuracy: 0.1025\n",
            "Epoch 2/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3206 - accuracy: 0.1028\n",
            "Epoch 3/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3187 - accuracy: 0.1075\n",
            "Epoch 4/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3171 - accuracy: 0.1143\n",
            "Epoch 5/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3157 - accuracy: 0.1236\n",
            "42000/42000 [==============================] - 2s 43us/step\n",
            "Try 4/100: Best_val_acc: [2.3148558949970064, 0.12730953097343445], lr: 0.001, Lambda: 0.001\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_66 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_68 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_69 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/5\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 2.4848 - accuracy: 0.1145\n",
            "Epoch 2/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.4413 - accuracy: 0.1645\n",
            "Epoch 3/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.4003 - accuracy: 0.2312\n",
            "Epoch 4/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3520 - accuracy: 0.2751\n",
            "Epoch 5/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2794 - accuracy: 0.3079\n",
            "42000/42000 [==============================] - 2s 44us/step\n",
            "Try 5/100: Best_val_acc: [2.225666375023978, 0.31485715508461], lr: 0.01, Lambda: 0.01\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_71 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_73 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_74 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/5\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 2.6421 - accuracy: 0.1026\n",
            "Epoch 2/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3070 - accuracy: 0.1001\n",
            "Epoch 3/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3028 - accuracy: 0.1023\n",
            "Epoch 4/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3026 - accuracy: 0.1063\n",
            "Epoch 5/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3022 - accuracy: 0.1041\n",
            "42000/42000 [==============================] - 2s 43us/step\n",
            "Try 6/100: Best_val_acc: [2.3018756807418095, 0.09980952739715576], lr: 0.1, Lambda: 0.1\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_76 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_77 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_78 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_79 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_80 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 7.5416 - accuracy: 0.1010\n",
            "Epoch 2/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3785 - accuracy: 0.0979\n",
            "Epoch 3/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3054 - accuracy: 0.1003\n",
            "Epoch 4/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3048 - accuracy: 0.1027\n",
            "Epoch 5/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3068 - accuracy: 0.0992\n",
            "42000/42000 [==============================] - 2s 43us/step\n",
            "Try 7/100: Best_val_acc: [2.305548169363113, 0.09966666996479034], lr: 1.0, Lambda: 1.0\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_81 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_82 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_83 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_84 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_85 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/5\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: nan - accuracy: 0.0994\n",
            "Epoch 2/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 3/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 4/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 5/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: nan - accuracy: 0.0997\n",
            "42000/42000 [==============================] - 2s 47us/step\n",
            "Try 8/100: Best_val_acc: [nan, 0.09966666996479034], lr: 10.0, Lambda: 10.0\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_86 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_87 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_88 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_89 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_90 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/5\n",
            "42000/42000 [==============================] - 2s 51us/step - loss: nan - accuracy: 0.0996\n",
            "Epoch 2/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 3/5\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 4/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 5/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: nan - accuracy: 0.0997\n",
            "42000/42000 [==============================] - 2s 43us/step\n",
            "Try 9/100: Best_val_acc: [nan, 0.09966666996479034], lr: 100.0, Lambda: 100.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RPN68y2oqjy",
        "colab_type": "text"
      },
      "source": [
        "**Observations**\n",
        " - Learning rate range is 1e-3 to 1. Best at 1e-2\n",
        " - Lambda range is 1e-3 to 1. Best at 1e-2\n",
        " - epochs used is very less, so we do not know if the accuracy converges for larger value. Less epoch count is used for performance reasons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLcVzJcIo-vB",
        "colab_type": "text"
      },
      "source": [
        "**Run one more coarse search by keeping either of the parameters constant and vary the others**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsK7D1ENo9HG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ed0c186d-121f-4ca5-e841-b1fdfef252ba"
      },
      "source": [
        "cns = 1e-4\n",
        "for j in range(1,4):\n",
        "  if j==1:\n",
        "    lr = cns*10\n",
        "  else:\n",
        "    lr = lr*10\n",
        "  for k in range(1,4):\n",
        "      if k==1:\n",
        "        Lambda = cns*10\n",
        "      else:\n",
        "        Lambda = Lambda*10\n",
        "      model_temp = train_and_test_loop(X_train, y_train, hidden_nodes=256, output_nodes=10, btc_size=1000, iter_epochs=5, lr=lr, Lambda=Lambda,verb=False)\n",
        "      best_acc = model_temp.evaluate(X_train, y_train)\n",
        "      print(\"Try {0}.{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(j, k, best_acc, lr, Lambda))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_91 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_92 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_93 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_94 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_95 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/5\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 2.3281 - accuracy: 0.1035\n",
            "Epoch 2/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3184 - accuracy: 0.1199\n",
            "Epoch 3/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3153 - accuracy: 0.1304\n",
            "Epoch 4/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3129 - accuracy: 0.1372\n",
            "Epoch 5/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3109 - accuracy: 0.1490\n",
            "42000/42000 [==============================] - 2s 43us/step\n",
            "Try 1.1: Best_val_acc: [2.309697659083775, 0.1607142835855484], lr: 0.001, Lambda: 0.001\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_96 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_97 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_98 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_99 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_100 (Dense)            (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/5\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 2.4945 - accuracy: 0.1009\n",
            "Epoch 2/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.4864 - accuracy: 0.1098\n",
            "Epoch 3/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.4812 - accuracy: 0.1180\n",
            "Epoch 4/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.4767 - accuracy: 0.1235\n",
            "Epoch 5/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.4724 - accuracy: 0.1337\n",
            "42000/42000 [==============================] - 2s 44us/step\n",
            "Try 1.2: Best_val_acc: [2.470144090107509, 0.1373809576034546], lr: 0.001, Lambda: 0.01\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_101 (Dense)            (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_102 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_103 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_104 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_105 (Dense)            (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 4.1447 - accuracy: 0.0950\n",
            "Epoch 2/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 3.8635 - accuracy: 0.1002\n",
            "Epoch 3/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 3.6159 - accuracy: 0.1093\n",
            "Epoch 4/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 3.4074 - accuracy: 0.1176\n",
            "Epoch 5/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 3.2322 - accuracy: 0.1261\n",
            "42000/42000 [==============================] - 2s 43us/step\n",
            "Try 1.3: Best_val_acc: [3.15249764696757, 0.12895238399505615], lr: 0.001, Lambda: 0.1\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_106 (Dense)            (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_107 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_108 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_109 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_110 (Dense)            (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/5\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 2.3195 - accuracy: 0.1169\n",
            "Epoch 2/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3018 - accuracy: 0.1809\n",
            "Epoch 3/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.2786 - accuracy: 0.2327\n",
            "Epoch 4/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.2356 - accuracy: 0.2765\n",
            "Epoch 5/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.1457 - accuracy: 0.3199\n",
            "42000/42000 [==============================] - 2s 43us/step\n",
            "Try 2.1: Best_val_acc: [2.0721441389265514, 0.33252382278442383], lr: 0.01, Lambda: 0.001\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_111 (Dense)            (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_112 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_113 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_114 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_115 (Dense)            (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/5\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 2.4828 - accuracy: 0.1103\n",
            "Epoch 2/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.4448 - accuracy: 0.1477\n",
            "Epoch 3/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.4123 - accuracy: 0.1978\n",
            "Epoch 4/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3807 - accuracy: 0.2157\n",
            "Epoch 5/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3434 - accuracy: 0.2682\n",
            "42000/42000 [==============================] - 2s 44us/step\n",
            "Try 2.2: Best_val_acc: [2.319670258749099, 0.29114285111427307], lr: 0.01, Lambda: 0.01\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_116 (Dense)            (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_117 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_118 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_119 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_120 (Dense)            (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/5\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 3.4724 - accuracy: 0.1064\n",
            "Epoch 2/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.4771 - accuracy: 0.1214\n",
            "Epoch 3/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3209 - accuracy: 0.1333\n",
            "Epoch 4/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3040 - accuracy: 0.1161\n",
            "Epoch 5/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3022 - accuracy: 0.1183\n",
            "42000/42000 [==============================] - 2s 44us/step\n",
            "Try 2.3: Best_val_acc: [2.3018450507209414, 0.11359523981809616], lr: 0.01, Lambda: 0.1\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_121 (Dense)            (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_122 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_123 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_124 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_125 (Dense)            (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/5\n",
            "42000/42000 [==============================] - 2s 51us/step - loss: 2.3092 - accuracy: 0.1354\n",
            "Epoch 2/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.4209 - accuracy: 0.1609\n",
            "Epoch 3/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3742 - accuracy: 0.1142\n",
            "Epoch 4/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3594 - accuracy: 0.1312\n",
            "Epoch 5/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3317 - accuracy: 0.1366\n",
            "42000/42000 [==============================] - 2s 44us/step\n",
            "Try 3.1: Best_val_acc: [2.3258264302753267, 0.15276190638542175], lr: 0.1, Lambda: 0.001\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_126 (Dense)            (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_127 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_128 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_129 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_130 (Dense)            (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.4119 - accuracy: 0.1367\n",
            "Epoch 2/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.4219 - accuracy: 0.1690\n",
            "Epoch 3/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.4533 - accuracy: 0.1260\n",
            "Epoch 4/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.2273 - accuracy: 0.1633\n",
            "Epoch 5/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.1089 - accuracy: 0.2082\n",
            "42000/42000 [==============================] - 2s 44us/step\n",
            "Try 3.2: Best_val_acc: [2.288340339024862, 0.21042856574058533], lr: 0.1, Lambda: 0.01\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_131 (Dense)            (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_132 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_133 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_134 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_135 (Dense)            (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.6401 - accuracy: 0.1021\n",
            "Epoch 2/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3068 - accuracy: 0.1017\n",
            "Epoch 3/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3026 - accuracy: 0.1065\n",
            "Epoch 4/5\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3017 - accuracy: 0.1157\n",
            "Epoch 5/5\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2967 - accuracy: 0.1487\n",
            "42000/42000 [==============================] - 2s 43us/step\n",
            "Try 3.3: Best_val_acc: [2.28932791074117, 0.12871427834033966], lr: 0.1, Lambda: 0.1\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2CNP28aqpiY",
        "colab_type": "text"
      },
      "source": [
        "**Observations**\n",
        " - lr = 0.01 and Lambda = 0.001 yield the best result\n",
        "\n",
        "Now try a higher epoch count to verify if this hyper parameter combination is the best"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UO0E7-7qoc6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52904634-f949-41ed-afcf-ef3a3a5c829a"
      },
      "source": [
        "model_hyper1 = train_and_test_loop(X_train, y_train, hidden_nodes=256, output_nodes=10, btc_size=100, iter_epochs=100, lr=1e-2, Lambda=1e-3,verb=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_136 (Dense)            (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_137 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_138 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_139 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_140 (Dense)            (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 2.1305 - accuracy: 0.2324\n",
            "Epoch 2/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 1.4209 - accuracy: 0.5375\n",
            "Epoch 3/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 1.1912 - accuracy: 0.6259\n",
            "Epoch 4/100\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 1.0528 - accuracy: 0.6741\n",
            "Epoch 5/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.9796 - accuracy: 0.6982\n",
            "Epoch 6/100\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.9146 - accuracy: 0.7190\n",
            "Epoch 7/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.8538 - accuracy: 0.7378\n",
            "Epoch 8/100\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.8218 - accuracy: 0.7457\n",
            "Epoch 9/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.7745 - accuracy: 0.7634\n",
            "Epoch 10/100\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.7414 - accuracy: 0.7734\n",
            "Epoch 11/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.7029 - accuracy: 0.7863\n",
            "Epoch 12/100\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.6962 - accuracy: 0.7872\n",
            "Epoch 13/100\n",
            "42000/42000 [==============================] - 4s 85us/step - loss: 0.6635 - accuracy: 0.7969\n",
            "Epoch 14/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.6407 - accuracy: 0.8045\n",
            "Epoch 15/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.6161 - accuracy: 0.8103\n",
            "Epoch 16/100\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.5960 - accuracy: 0.8178\n",
            "Epoch 17/100\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.5803 - accuracy: 0.8234\n",
            "Epoch 18/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.5677 - accuracy: 0.8259\n",
            "Epoch 19/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.5380 - accuracy: 0.8361\n",
            "Epoch 20/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.5313 - accuracy: 0.8371\n",
            "Epoch 21/100\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.5065 - accuracy: 0.8445\n",
            "Epoch 22/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.5026 - accuracy: 0.8451\n",
            "Epoch 23/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.4872 - accuracy: 0.8481\n",
            "Epoch 24/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.4783 - accuracy: 0.8520\n",
            "Epoch 25/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.4637 - accuracy: 0.8572\n",
            "Epoch 26/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.4468 - accuracy: 0.8631\n",
            "Epoch 27/100\n",
            "42000/42000 [==============================] - 4s 85us/step - loss: 0.4350 - accuracy: 0.8674\n",
            "Epoch 28/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.4227 - accuracy: 0.8703\n",
            "Epoch 29/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.4142 - accuracy: 0.8712\n",
            "Epoch 30/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.4110 - accuracy: 0.8732\n",
            "Epoch 31/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.3972 - accuracy: 0.8775\n",
            "Epoch 32/100\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.3934 - accuracy: 0.8788\n",
            "Epoch 33/100\n",
            "42000/42000 [==============================] - 4s 105us/step - loss: 0.3751 - accuracy: 0.8833\n",
            "Epoch 34/100\n",
            "42000/42000 [==============================] - 6s 150us/step - loss: 0.3656 - accuracy: 0.8885\n",
            "Epoch 35/100\n",
            "42000/42000 [==============================] - 4s 94us/step - loss: 0.3565 - accuracy: 0.8917\n",
            "Epoch 36/100\n",
            "42000/42000 [==============================] - 4s 92us/step - loss: 0.3494 - accuracy: 0.8931\n",
            "Epoch 37/100\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.3415 - accuracy: 0.8951\n",
            "Epoch 38/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.3283 - accuracy: 0.8999\n",
            "Epoch 39/100\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.3209 - accuracy: 0.9022\n",
            "Epoch 40/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.3051 - accuracy: 0.9084\n",
            "Epoch 41/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.3060 - accuracy: 0.9072\n",
            "Epoch 42/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.3007 - accuracy: 0.9095\n",
            "Epoch 43/100\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.2940 - accuracy: 0.9110\n",
            "Epoch 44/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2808 - accuracy: 0.9157\n",
            "Epoch 45/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2757 - accuracy: 0.9176\n",
            "Epoch 46/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2657 - accuracy: 0.9217\n",
            "Epoch 47/100\n",
            "42000/42000 [==============================] - 4s 90us/step - loss: 0.2697 - accuracy: 0.9192\n",
            "Epoch 48/100\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2565 - accuracy: 0.9234\n",
            "Epoch 49/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2540 - accuracy: 0.9230\n",
            "Epoch 50/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2394 - accuracy: 0.9289\n",
            "Epoch 51/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2375 - accuracy: 0.9302\n",
            "Epoch 52/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2313 - accuracy: 0.9310\n",
            "Epoch 53/100\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.2182 - accuracy: 0.9363\n",
            "Epoch 54/100\n",
            "42000/42000 [==============================] - 4s 90us/step - loss: 0.2092 - accuracy: 0.9394\n",
            "Epoch 55/100\n",
            "42000/42000 [==============================] - 4s 90us/step - loss: 0.2201 - accuracy: 0.9345\n",
            "Epoch 56/100\n",
            "42000/42000 [==============================] - 4s 91us/step - loss: 0.2066 - accuracy: 0.9388\n",
            "Epoch 57/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2057 - accuracy: 0.9403\n",
            "Epoch 58/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2053 - accuracy: 0.9399\n",
            "Epoch 59/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2034 - accuracy: 0.9399\n",
            "Epoch 60/100\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.1961 - accuracy: 0.9428\n",
            "Epoch 61/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.1787 - accuracy: 0.9484\n",
            "Epoch 62/100\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.1638 - accuracy: 0.9556\n",
            "Epoch 63/100\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.1607 - accuracy: 0.9553\n",
            "Epoch 64/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.1687 - accuracy: 0.9532\n",
            "Epoch 65/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.1626 - accuracy: 0.9549\n",
            "Epoch 66/100\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.1556 - accuracy: 0.9570\n",
            "Epoch 67/100\n",
            "42000/42000 [==============================] - 4s 91us/step - loss: 0.1464 - accuracy: 0.9604\n",
            "Epoch 68/100\n",
            "42000/42000 [==============================] - 4s 92us/step - loss: 0.1509 - accuracy: 0.9579\n",
            "Epoch 69/100\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.1568 - accuracy: 0.9570\n",
            "Epoch 70/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.1438 - accuracy: 0.9602\n",
            "Epoch 71/100\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.1401 - accuracy: 0.9617\n",
            "Epoch 72/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.1293 - accuracy: 0.9658\n",
            "Epoch 73/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.1198 - accuracy: 0.9701\n",
            "Epoch 74/100\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.1192 - accuracy: 0.9694\n",
            "Epoch 75/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.1223 - accuracy: 0.9683\n",
            "Epoch 76/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.1276 - accuracy: 0.9665\n",
            "Epoch 77/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.1133 - accuracy: 0.9710\n",
            "Epoch 78/100\n",
            "42000/42000 [==============================] - 4s 90us/step - loss: 0.1091 - accuracy: 0.9724\n",
            "Epoch 79/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.1080 - accuracy: 0.9738\n",
            "Epoch 80/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.1079 - accuracy: 0.9726\n",
            "Epoch 81/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.0932 - accuracy: 0.9782\n",
            "Epoch 82/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.1085 - accuracy: 0.9723\n",
            "Epoch 83/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.1267 - accuracy: 0.9655\n",
            "Epoch 84/100\n",
            "42000/42000 [==============================] - 4s 90us/step - loss: 0.0967 - accuracy: 0.9773\n",
            "Epoch 85/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.1017 - accuracy: 0.9749\n",
            "Epoch 86/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.0838 - accuracy: 0.9814\n",
            "Epoch 87/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.0871 - accuracy: 0.9800\n",
            "Epoch 88/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.0885 - accuracy: 0.9788\n",
            "Epoch 89/100\n",
            "42000/42000 [==============================] - 4s 91us/step - loss: 0.0810 - accuracy: 0.9822\n",
            "Epoch 90/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.0944 - accuracy: 0.9771\n",
            "Epoch 91/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.0810 - accuracy: 0.9821\n",
            "Epoch 92/100\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.0823 - accuracy: 0.9808\n",
            "Epoch 93/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.0794 - accuracy: 0.9819\n",
            "Epoch 94/100\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.0780 - accuracy: 0.9825\n",
            "Epoch 95/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.0649 - accuracy: 0.9869\n",
            "Epoch 96/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.0793 - accuracy: 0.9814\n",
            "Epoch 97/100\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.0564 - accuracy: 0.9903\n",
            "Epoch 98/100\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.0850 - accuracy: 0.9797\n",
            "Epoch 99/100\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.0822 - accuracy: 0.9805\n",
            "Epoch 100/100\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.0672 - accuracy: 0.9864\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2BjqdBsq7xS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8de1aa40-9f60-412b-8aac-0d9171501000"
      },
      "source": [
        "score_hyper1 = model_hyper1.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18000/18000 [==============================] - 1s 45us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYAaQ2YKq7el",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9356a26e-6deb-462d-a595-7e452ac6906e"
      },
      "source": [
        "print('Accuracy for best hyperparameters: ', score_hyper1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for best hyperparameters:  [184.87181084843147, 0.8145555257797241]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6vtBzBGxQzZ",
        "colab_type": "text"
      },
      "source": [
        "**Observations**\n",
        " - Though the train set accuracy was 0.98, the test set accuracy is just 0.81\n",
        " - There is a scope for further fine tuning the hyper parameters, as well as stabilizing the model so that the train accuracy is within comparable limits of train accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jVNG-v1EYH0",
        "colab_type": "text"
      },
      "source": [
        "### 8.2. Run a finer search by using a finer range of the hyperparameter & Record findings\t\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wzr-3p7tFSQa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "db1a161e-1d0d-43d9-8b69-3dfadb7a53d1"
      },
      "source": [
        "for k in range(1,10):\n",
        "    lr = math.pow(10, np.random.uniform(-3.0, -1.0))\n",
        "    Lambda = math.pow(10, np.random.uniform(-4,-2))\n",
        "    model_fine = train_and_test_loop(X_train, y_train, hidden_nodes=256, output_nodes=10, btc_size=1000, iter_epochs=100, lr=lr, Lambda=Lambda,verb=False)\n",
        "    best_acc = model_fine.evaluate(X_train, y_train)\n",
        "    print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 100, best_acc, lr, Lambda))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_141 (Dense)            (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_142 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_143 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_144 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_145 (Dense)            (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/100\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 2.3104 - accuracy: 0.1294\n",
            "Epoch 2/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.2883 - accuracy: 0.1980\n",
            "Epoch 3/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2490 - accuracy: 0.2734\n",
            "Epoch 4/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.1362 - accuracy: 0.3325\n",
            "Epoch 5/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.8839 - accuracy: 0.4037\n",
            "Epoch 6/100\n",
            "42000/42000 [==============================] - 2s 52us/step - loss: 1.6281 - accuracy: 0.4680\n",
            "Epoch 7/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.4833 - accuracy: 0.5220\n",
            "Epoch 8/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.3628 - accuracy: 0.5662\n",
            "Epoch 9/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.2639 - accuracy: 0.6036\n",
            "Epoch 10/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.2152 - accuracy: 0.6218\n",
            "Epoch 11/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.1594 - accuracy: 0.6434\n",
            "Epoch 12/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.1226 - accuracy: 0.6556\n",
            "Epoch 13/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0767 - accuracy: 0.6687\n",
            "Epoch 14/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0214 - accuracy: 0.6893\n",
            "Epoch 15/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0011 - accuracy: 0.6945\n",
            "Epoch 16/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9778 - accuracy: 0.7028\n",
            "Epoch 17/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.9246 - accuracy: 0.7205\n",
            "Epoch 18/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9182 - accuracy: 0.7228\n",
            "Epoch 19/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9116 - accuracy: 0.7250\n",
            "Epoch 20/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8981 - accuracy: 0.7280\n",
            "Epoch 21/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8587 - accuracy: 0.7400\n",
            "Epoch 22/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.8474 - accuracy: 0.7439\n",
            "Epoch 23/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8208 - accuracy: 0.7515\n",
            "Epoch 24/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.8012 - accuracy: 0.7607\n",
            "Epoch 25/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7912 - accuracy: 0.7609\n",
            "Epoch 26/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7518 - accuracy: 0.7744\n",
            "Epoch 27/100\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 0.7358 - accuracy: 0.7799\n",
            "Epoch 28/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7386 - accuracy: 0.7785\n",
            "Epoch 29/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7344 - accuracy: 0.7792\n",
            "Epoch 30/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7112 - accuracy: 0.7876\n",
            "Epoch 31/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6861 - accuracy: 0.7953\n",
            "Epoch 32/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6857 - accuracy: 0.7967\n",
            "Epoch 33/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6671 - accuracy: 0.8019\n",
            "Epoch 34/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6711 - accuracy: 0.8001\n",
            "Epoch 35/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6647 - accuracy: 0.8022\n",
            "Epoch 36/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6458 - accuracy: 0.8066\n",
            "Epoch 37/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6399 - accuracy: 0.8100\n",
            "Epoch 38/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6343 - accuracy: 0.8120\n",
            "Epoch 39/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6313 - accuracy: 0.8117\n",
            "Epoch 40/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6190 - accuracy: 0.8141\n",
            "Epoch 41/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5927 - accuracy: 0.8251\n",
            "Epoch 42/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5877 - accuracy: 0.8255\n",
            "Epoch 43/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5775 - accuracy: 0.8295\n",
            "Epoch 44/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5638 - accuracy: 0.8340\n",
            "Epoch 45/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5595 - accuracy: 0.8342\n",
            "Epoch 46/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5509 - accuracy: 0.8395\n",
            "Epoch 47/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5541 - accuracy: 0.8367\n",
            "Epoch 48/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5467 - accuracy: 0.8388\n",
            "Epoch 49/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5471 - accuracy: 0.8386\n",
            "Epoch 50/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5421 - accuracy: 0.8400\n",
            "Epoch 51/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5372 - accuracy: 0.8412\n",
            "Epoch 52/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5333 - accuracy: 0.8428\n",
            "Epoch 53/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5127 - accuracy: 0.8486\n",
            "Epoch 54/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5060 - accuracy: 0.8517\n",
            "Epoch 55/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5266 - accuracy: 0.8429\n",
            "Epoch 56/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5097 - accuracy: 0.8501\n",
            "Epoch 57/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4995 - accuracy: 0.8537\n",
            "Epoch 58/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4949 - accuracy: 0.8540\n",
            "Epoch 59/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4919 - accuracy: 0.8554\n",
            "Epoch 60/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4860 - accuracy: 0.8584\n",
            "Epoch 61/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4722 - accuracy: 0.8614\n",
            "Epoch 62/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4734 - accuracy: 0.8610\n",
            "Epoch 63/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4757 - accuracy: 0.8615\n",
            "Epoch 64/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4681 - accuracy: 0.8635\n",
            "Epoch 65/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4726 - accuracy: 0.8617\n",
            "Epoch 66/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4520 - accuracy: 0.8683\n",
            "Epoch 67/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4494 - accuracy: 0.8680\n",
            "Epoch 68/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4368 - accuracy: 0.8729\n",
            "Epoch 69/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4351 - accuracy: 0.8747\n",
            "Epoch 70/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4446 - accuracy: 0.8699\n",
            "Epoch 71/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4232 - accuracy: 0.8778\n",
            "Epoch 72/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4265 - accuracy: 0.8755\n",
            "Epoch 73/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4155 - accuracy: 0.8796\n",
            "Epoch 74/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4212 - accuracy: 0.8772\n",
            "Epoch 75/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4073 - accuracy: 0.8825\n",
            "Epoch 76/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4122 - accuracy: 0.8801\n",
            "Epoch 77/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4230 - accuracy: 0.8752\n",
            "Epoch 78/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4229 - accuracy: 0.8742\n",
            "Epoch 79/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4193 - accuracy: 0.8770\n",
            "Epoch 80/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3970 - accuracy: 0.8850\n",
            "Epoch 81/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3858 - accuracy: 0.8884\n",
            "Epoch 82/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3908 - accuracy: 0.8863\n",
            "Epoch 83/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3908 - accuracy: 0.8856\n",
            "Epoch 84/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3880 - accuracy: 0.8863\n",
            "Epoch 85/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3989 - accuracy: 0.8841\n",
            "Epoch 86/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3828 - accuracy: 0.8892\n",
            "Epoch 87/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3734 - accuracy: 0.8903\n",
            "Epoch 88/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3673 - accuracy: 0.8940\n",
            "Epoch 89/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3557 - accuracy: 0.8968\n",
            "Epoch 90/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3566 - accuracy: 0.8966\n",
            "Epoch 91/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3743 - accuracy: 0.8898\n",
            "Epoch 92/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3651 - accuracy: 0.8937\n",
            "Epoch 93/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3531 - accuracy: 0.8962\n",
            "Epoch 94/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3378 - accuracy: 0.9032\n",
            "Epoch 95/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3356 - accuracy: 0.9041\n",
            "Epoch 96/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3319 - accuracy: 0.9041\n",
            "Epoch 97/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3337 - accuracy: 0.9038\n",
            "Epoch 98/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3368 - accuracy: 0.9026\n",
            "Epoch 99/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3354 - accuracy: 0.9045\n",
            "Epoch 100/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3184 - accuracy: 0.9100\n",
            "42000/42000 [==============================] - 2s 43us/step\n",
            "Try 1/100: Best_val_acc: [0.31773128326733907, 0.91009521484375], lr: 0.013643378328133159, Lambda: 0.0005236061467502362\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_146 (Dense)            (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_147 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_148 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_149 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_150 (Dense)            (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/100\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 2.3070 - accuracy: 0.1374\n",
            "Epoch 2/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2795 - accuracy: 0.1994\n",
            "Epoch 3/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2155 - accuracy: 0.2730\n",
            "Epoch 4/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.0365 - accuracy: 0.3389\n",
            "Epoch 5/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.7669 - accuracy: 0.4273\n",
            "Epoch 6/100\n",
            "42000/42000 [==============================] - 2s 47us/step - loss: 1.5874 - accuracy: 0.4835\n",
            "Epoch 7/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.3749 - accuracy: 0.5598\n",
            "Epoch 8/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.2628 - accuracy: 0.6020\n",
            "Epoch 9/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.1918 - accuracy: 0.6279\n",
            "Epoch 10/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0880 - accuracy: 0.6701\n",
            "Epoch 11/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0610 - accuracy: 0.6755\n",
            "Epoch 12/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0022 - accuracy: 0.6937\n",
            "Epoch 13/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9720 - accuracy: 0.7035\n",
            "Epoch 14/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.9423 - accuracy: 0.7135\n",
            "Epoch 15/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9011 - accuracy: 0.7263\n",
            "Epoch 16/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9033 - accuracy: 0.7234\n",
            "Epoch 17/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8553 - accuracy: 0.7404\n",
            "Epoch 18/100\n",
            "42000/42000 [==============================] - 2s 47us/step - loss: 0.8255 - accuracy: 0.7502\n",
            "Epoch 19/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.8070 - accuracy: 0.7567\n",
            "Epoch 20/100\n",
            "42000/42000 [==============================] - 2s 47us/step - loss: 0.7959 - accuracy: 0.7598\n",
            "Epoch 21/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7762 - accuracy: 0.7659\n",
            "Epoch 22/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7755 - accuracy: 0.7645\n",
            "Epoch 23/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7584 - accuracy: 0.7707\n",
            "Epoch 24/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7232 - accuracy: 0.7845\n",
            "Epoch 25/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7006 - accuracy: 0.7905\n",
            "Epoch 26/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7031 - accuracy: 0.7887\n",
            "Epoch 27/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6773 - accuracy: 0.7973\n",
            "Epoch 28/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6687 - accuracy: 0.7996\n",
            "Epoch 29/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6648 - accuracy: 0.8017\n",
            "Epoch 30/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6503 - accuracy: 0.8037\n",
            "Epoch 31/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6377 - accuracy: 0.8108\n",
            "Epoch 32/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6330 - accuracy: 0.8099\n",
            "Epoch 33/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6181 - accuracy: 0.8175\n",
            "Epoch 34/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6106 - accuracy: 0.8188\n",
            "Epoch 35/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6094 - accuracy: 0.8169\n",
            "Epoch 36/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5971 - accuracy: 0.8238\n",
            "Epoch 37/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5911 - accuracy: 0.8247\n",
            "Epoch 38/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5860 - accuracy: 0.8248\n",
            "Epoch 39/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5820 - accuracy: 0.8250\n",
            "Epoch 40/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5611 - accuracy: 0.8343\n",
            "Epoch 41/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5464 - accuracy: 0.8395\n",
            "Epoch 42/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5331 - accuracy: 0.8430\n",
            "Epoch 43/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5363 - accuracy: 0.8426\n",
            "Epoch 44/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5323 - accuracy: 0.8416\n",
            "Epoch 45/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5179 - accuracy: 0.8476\n",
            "Epoch 46/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5177 - accuracy: 0.8435\n",
            "Epoch 47/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5193 - accuracy: 0.8451\n",
            "Epoch 48/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5219 - accuracy: 0.8441\n",
            "Epoch 49/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4945 - accuracy: 0.8532\n",
            "Epoch 50/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4973 - accuracy: 0.8518\n",
            "Epoch 51/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4689 - accuracy: 0.8631\n",
            "Epoch 52/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4708 - accuracy: 0.8622\n",
            "Epoch 53/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4574 - accuracy: 0.8653\n",
            "Epoch 54/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4718 - accuracy: 0.8603\n",
            "Epoch 55/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4478 - accuracy: 0.8696\n",
            "Epoch 56/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4646 - accuracy: 0.8618\n",
            "Epoch 57/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4338 - accuracy: 0.8727\n",
            "Epoch 58/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4460 - accuracy: 0.8687\n",
            "Epoch 59/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4264 - accuracy: 0.8775\n",
            "Epoch 60/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4320 - accuracy: 0.8729\n",
            "Epoch 61/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4186 - accuracy: 0.8761\n",
            "Epoch 62/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4177 - accuracy: 0.8770\n",
            "Epoch 63/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4213 - accuracy: 0.8751\n",
            "Epoch 64/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4066 - accuracy: 0.8821\n",
            "Epoch 65/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3953 - accuracy: 0.8849\n",
            "Epoch 66/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3992 - accuracy: 0.8821\n",
            "Epoch 67/100\n",
            "42000/42000 [==============================] - 3s 78us/step - loss: 0.4027 - accuracy: 0.8828\n",
            "Epoch 68/100\n",
            "42000/42000 [==============================] - 4s 84us/step - loss: 0.3970 - accuracy: 0.8825\n",
            "Epoch 69/100\n",
            "42000/42000 [==============================] - 3s 64us/step - loss: 0.3792 - accuracy: 0.8889\n",
            "Epoch 70/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3731 - accuracy: 0.8923\n",
            "Epoch 71/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3831 - accuracy: 0.8871\n",
            "Epoch 72/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3746 - accuracy: 0.8922\n",
            "Epoch 73/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3726 - accuracy: 0.8917\n",
            "Epoch 74/100\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 0.3750 - accuracy: 0.8910\n",
            "Epoch 75/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3671 - accuracy: 0.8936\n",
            "Epoch 76/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3589 - accuracy: 0.8955\n",
            "Epoch 77/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3707 - accuracy: 0.8910\n",
            "Epoch 78/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3568 - accuracy: 0.8961\n",
            "Epoch 79/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3544 - accuracy: 0.8958\n",
            "Epoch 80/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3537 - accuracy: 0.8956\n",
            "Epoch 81/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3485 - accuracy: 0.8978\n",
            "Epoch 82/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3456 - accuracy: 0.8975\n",
            "Epoch 83/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3337 - accuracy: 0.9050\n",
            "Epoch 84/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3231 - accuracy: 0.9079\n",
            "Epoch 85/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3151 - accuracy: 0.9103\n",
            "Epoch 86/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3116 - accuracy: 0.9096\n",
            "Epoch 87/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3186 - accuracy: 0.9086\n",
            "Epoch 88/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3181 - accuracy: 0.9076\n",
            "Epoch 89/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3079 - accuracy: 0.9119\n",
            "Epoch 90/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3151 - accuracy: 0.9079\n",
            "Epoch 91/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2975 - accuracy: 0.9159\n",
            "Epoch 92/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3027 - accuracy: 0.9139\n",
            "Epoch 93/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2961 - accuracy: 0.9137\n",
            "Epoch 94/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2901 - accuracy: 0.9171\n",
            "Epoch 95/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.2861 - accuracy: 0.9186\n",
            "Epoch 96/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.2981 - accuracy: 0.9133\n",
            "Epoch 97/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2820 - accuracy: 0.9189\n",
            "Epoch 98/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2854 - accuracy: 0.9187\n",
            "Epoch 99/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2848 - accuracy: 0.9172\n",
            "Epoch 100/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.2749 - accuracy: 0.9214\n",
            "42000/42000 [==============================] - 2s 44us/step\n",
            "Try 2/100: Best_val_acc: [0.25755650312559947, 0.9253571629524231], lr: 0.016850966398060944, Lambda: 0.0004719806466438966\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_151 (Dense)            (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_152 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_153 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_154 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_155 (Dense)            (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3554 - accuracy: 0.1268\n",
            "Epoch 2/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3242 - accuracy: 0.2041\n",
            "Epoch 3/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2570 - accuracy: 0.2867\n",
            "Epoch 4/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.0864 - accuracy: 0.3594\n",
            "Epoch 5/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.7951 - accuracy: 0.4507\n",
            "Epoch 6/100\n",
            "42000/42000 [==============================] - 2s 47us/step - loss: 1.5970 - accuracy: 0.4958\n",
            "Epoch 7/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.4472 - accuracy: 0.5521\n",
            "Epoch 8/100\n",
            "42000/42000 [==============================] - 2s 47us/step - loss: 1.3562 - accuracy: 0.5874\n",
            "Epoch 9/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.2714 - accuracy: 0.6170\n",
            "Epoch 10/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.2089 - accuracy: 0.6402\n",
            "Epoch 11/100\n",
            "42000/42000 [==============================] - 2s 47us/step - loss: 1.1440 - accuracy: 0.6649\n",
            "Epoch 12/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.1124 - accuracy: 0.6741\n",
            "Epoch 13/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0728 - accuracy: 0.6871\n",
            "Epoch 14/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0265 - accuracy: 0.7041\n",
            "Epoch 15/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0137 - accuracy: 0.7070\n",
            "Epoch 16/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9715 - accuracy: 0.7200\n",
            "Epoch 17/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9445 - accuracy: 0.7284\n",
            "Epoch 18/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9193 - accuracy: 0.7350\n",
            "Epoch 19/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9239 - accuracy: 0.7335\n",
            "Epoch 20/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8853 - accuracy: 0.7439\n",
            "Epoch 21/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8572 - accuracy: 0.7542\n",
            "Epoch 22/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.8507 - accuracy: 0.7541\n",
            "Epoch 23/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.8321 - accuracy: 0.7585\n",
            "Epoch 24/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8231 - accuracy: 0.7623\n",
            "Epoch 25/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.8035 - accuracy: 0.7688\n",
            "Epoch 26/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7983 - accuracy: 0.7690\n",
            "Epoch 27/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7905 - accuracy: 0.7709\n",
            "Epoch 28/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7721 - accuracy: 0.7773\n",
            "Epoch 29/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7516 - accuracy: 0.7824\n",
            "Epoch 30/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7325 - accuracy: 0.7909\n",
            "Epoch 31/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7329 - accuracy: 0.7891\n",
            "Epoch 32/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7255 - accuracy: 0.7918\n",
            "Epoch 33/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7164 - accuracy: 0.7950\n",
            "Epoch 34/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7071 - accuracy: 0.7973\n",
            "Epoch 35/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6977 - accuracy: 0.7996\n",
            "Epoch 36/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6852 - accuracy: 0.8033\n",
            "Epoch 37/100\n",
            "42000/42000 [==============================] - 2s 47us/step - loss: 0.6751 - accuracy: 0.8058\n",
            "Epoch 38/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6645 - accuracy: 0.8099\n",
            "Epoch 39/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6496 - accuracy: 0.8153\n",
            "Epoch 40/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6389 - accuracy: 0.8169\n",
            "Epoch 41/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6501 - accuracy: 0.8149\n",
            "Epoch 42/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6349 - accuracy: 0.8195\n",
            "Epoch 43/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6277 - accuracy: 0.8197\n",
            "Epoch 44/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6246 - accuracy: 0.8202\n",
            "Epoch 45/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6108 - accuracy: 0.8256\n",
            "Epoch 46/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6090 - accuracy: 0.8262\n",
            "Epoch 47/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5969 - accuracy: 0.8305\n",
            "Epoch 48/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5859 - accuracy: 0.8334\n",
            "Epoch 49/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5828 - accuracy: 0.8343\n",
            "Epoch 50/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5726 - accuracy: 0.8379\n",
            "Epoch 51/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5831 - accuracy: 0.8328\n",
            "Epoch 52/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5654 - accuracy: 0.8392\n",
            "Epoch 53/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5664 - accuracy: 0.8383\n",
            "Epoch 54/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5517 - accuracy: 0.8437\n",
            "Epoch 55/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5386 - accuracy: 0.8488\n",
            "Epoch 56/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5375 - accuracy: 0.8481\n",
            "Epoch 57/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5329 - accuracy: 0.8488\n",
            "Epoch 58/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5265 - accuracy: 0.8509\n",
            "Epoch 59/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5353 - accuracy: 0.8470\n",
            "Epoch 60/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5281 - accuracy: 0.8500\n",
            "Epoch 61/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5134 - accuracy: 0.8536\n",
            "Epoch 62/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5253 - accuracy: 0.8509\n",
            "Epoch 63/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5057 - accuracy: 0.8568\n",
            "Epoch 64/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4939 - accuracy: 0.8604\n",
            "Epoch 65/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5061 - accuracy: 0.8559\n",
            "Epoch 66/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4828 - accuracy: 0.8640\n",
            "Epoch 67/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4778 - accuracy: 0.8664\n",
            "Epoch 68/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4724 - accuracy: 0.8673\n",
            "Epoch 69/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4772 - accuracy: 0.8664\n",
            "Epoch 70/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4707 - accuracy: 0.8672\n",
            "Epoch 71/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4640 - accuracy: 0.8690\n",
            "Epoch 72/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4589 - accuracy: 0.8700\n",
            "Epoch 73/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4580 - accuracy: 0.8706\n",
            "Epoch 74/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4519 - accuracy: 0.8725\n",
            "Epoch 75/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4511 - accuracy: 0.8728\n",
            "Epoch 76/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4439 - accuracy: 0.8737\n",
            "Epoch 77/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4334 - accuracy: 0.8785\n",
            "Epoch 78/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4386 - accuracy: 0.8749\n",
            "Epoch 79/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4352 - accuracy: 0.8771\n",
            "Epoch 80/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4359 - accuracy: 0.8755\n",
            "Epoch 81/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4301 - accuracy: 0.8773\n",
            "Epoch 82/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4121 - accuracy: 0.8850\n",
            "Epoch 83/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4161 - accuracy: 0.8837\n",
            "Epoch 84/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4114 - accuracy: 0.8842\n",
            "Epoch 85/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4009 - accuracy: 0.8883\n",
            "Epoch 86/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4195 - accuracy: 0.8798\n",
            "Epoch 87/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4097 - accuracy: 0.8848\n",
            "Epoch 88/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3987 - accuracy: 0.8883\n",
            "Epoch 89/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3962 - accuracy: 0.8874\n",
            "Epoch 90/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4060 - accuracy: 0.8845\n",
            "Epoch 91/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4010 - accuracy: 0.8865\n",
            "Epoch 92/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3945 - accuracy: 0.8882\n",
            "Epoch 93/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3787 - accuracy: 0.8927\n",
            "Epoch 94/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3789 - accuracy: 0.8931\n",
            "Epoch 95/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3713 - accuracy: 0.8963\n",
            "Epoch 96/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3716 - accuracy: 0.8962\n",
            "Epoch 97/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3787 - accuracy: 0.8923\n",
            "Epoch 98/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3865 - accuracy: 0.8902\n",
            "Epoch 99/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3790 - accuracy: 0.8920\n",
            "Epoch 100/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3636 - accuracy: 0.8988\n",
            "42000/42000 [==============================] - 2s 44us/step\n",
            "Try 3/100: Best_val_acc: [0.35256785418873743, 0.9012380838394165], lr: 0.015530564437333628, Lambda: 0.0031383940388992676\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_156 (Dense)            (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_157 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_158 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_159 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_160 (Dense)            (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/100\n",
            "42000/42000 [==============================] - 2s 51us/step - loss: 2.3195 - accuracy: 0.1300\n",
            "Epoch 2/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2405 - accuracy: 0.2587\n",
            "Epoch 3/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.1093 - accuracy: 0.2648\n",
            "Epoch 4/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.0042 - accuracy: 0.3034\n",
            "Epoch 5/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.6946 - accuracy: 0.4275\n",
            "Epoch 6/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.4865 - accuracy: 0.5054\n",
            "Epoch 7/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.3425 - accuracy: 0.5675\n",
            "Epoch 8/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.2463 - accuracy: 0.6056\n",
            "Epoch 9/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.1401 - accuracy: 0.6442\n",
            "Epoch 10/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.0778 - accuracy: 0.6681\n",
            "Epoch 11/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.0720 - accuracy: 0.6691\n",
            "Epoch 12/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0128 - accuracy: 0.6899\n",
            "Epoch 13/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9864 - accuracy: 0.6986\n",
            "Epoch 14/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.9808 - accuracy: 0.6992\n",
            "Epoch 15/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9067 - accuracy: 0.7254\n",
            "Epoch 16/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8787 - accuracy: 0.7335\n",
            "Epoch 17/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.8592 - accuracy: 0.7402\n",
            "Epoch 18/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8391 - accuracy: 0.7463\n",
            "Epoch 19/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8155 - accuracy: 0.7548\n",
            "Epoch 20/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7973 - accuracy: 0.7594\n",
            "Epoch 21/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7644 - accuracy: 0.7699\n",
            "Epoch 22/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7442 - accuracy: 0.7769\n",
            "Epoch 23/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7387 - accuracy: 0.7770\n",
            "Epoch 24/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7328 - accuracy: 0.7805\n",
            "Epoch 25/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6879 - accuracy: 0.7954\n",
            "Epoch 26/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6895 - accuracy: 0.7933\n",
            "Epoch 27/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6676 - accuracy: 0.8015\n",
            "Epoch 28/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6584 - accuracy: 0.8034\n",
            "Epoch 29/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6572 - accuracy: 0.8025\n",
            "Epoch 30/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6234 - accuracy: 0.8143\n",
            "Epoch 31/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6206 - accuracy: 0.8160\n",
            "Epoch 32/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6209 - accuracy: 0.8167\n",
            "Epoch 33/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5948 - accuracy: 0.8241\n",
            "Epoch 34/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5757 - accuracy: 0.8317\n",
            "Epoch 35/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5641 - accuracy: 0.8332\n",
            "Epoch 36/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5620 - accuracy: 0.8339\n",
            "Epoch 37/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5678 - accuracy: 0.8304\n",
            "Epoch 38/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5515 - accuracy: 0.8358\n",
            "Epoch 39/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5543 - accuracy: 0.8344\n",
            "Epoch 40/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5410 - accuracy: 0.8396\n",
            "Epoch 41/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5175 - accuracy: 0.8457\n",
            "Epoch 42/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4997 - accuracy: 0.8532\n",
            "Epoch 43/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4985 - accuracy: 0.8525\n",
            "Epoch 44/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5008 - accuracy: 0.8520\n",
            "Epoch 45/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4860 - accuracy: 0.8570\n",
            "Epoch 46/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4879 - accuracy: 0.8548\n",
            "Epoch 47/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4785 - accuracy: 0.8586\n",
            "Epoch 48/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4779 - accuracy: 0.8577\n",
            "Epoch 49/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4713 - accuracy: 0.8586\n",
            "Epoch 50/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4487 - accuracy: 0.8673\n",
            "Epoch 51/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4497 - accuracy: 0.8674\n",
            "Epoch 52/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4347 - accuracy: 0.8726\n",
            "Epoch 53/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4224 - accuracy: 0.8773\n",
            "Epoch 54/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4289 - accuracy: 0.8724\n",
            "Epoch 55/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4117 - accuracy: 0.8798\n",
            "Epoch 56/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4195 - accuracy: 0.8758\n",
            "Epoch 57/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4133 - accuracy: 0.8776\n",
            "Epoch 58/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3949 - accuracy: 0.8842\n",
            "Epoch 59/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3949 - accuracy: 0.8844\n",
            "Epoch 60/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3976 - accuracy: 0.8837\n",
            "Epoch 61/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3808 - accuracy: 0.8879\n",
            "Epoch 62/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4118 - accuracy: 0.8765\n",
            "Epoch 63/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3859 - accuracy: 0.8872\n",
            "Epoch 64/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3737 - accuracy: 0.8901\n",
            "Epoch 65/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3700 - accuracy: 0.8905\n",
            "Epoch 66/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3674 - accuracy: 0.8913\n",
            "Epoch 67/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3600 - accuracy: 0.8945\n",
            "Epoch 68/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3613 - accuracy: 0.8948\n",
            "Epoch 69/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3408 - accuracy: 0.9017\n",
            "Epoch 70/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3588 - accuracy: 0.8931\n",
            "Epoch 71/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3450 - accuracy: 0.8997\n",
            "Epoch 72/100\n",
            "42000/42000 [==============================] - 2s 47us/step - loss: 0.3522 - accuracy: 0.8964\n",
            "Epoch 73/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3428 - accuracy: 0.9000\n",
            "Epoch 74/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3235 - accuracy: 0.9070\n",
            "Epoch 75/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3154 - accuracy: 0.9080\n",
            "Epoch 76/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3199 - accuracy: 0.9074\n",
            "Epoch 77/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3021 - accuracy: 0.9132\n",
            "Epoch 78/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3080 - accuracy: 0.9108\n",
            "Epoch 79/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3259 - accuracy: 0.9042\n",
            "Epoch 80/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.2978 - accuracy: 0.9147\n",
            "Epoch 81/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3124 - accuracy: 0.9081\n",
            "Epoch 82/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2973 - accuracy: 0.9158\n",
            "Epoch 83/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2882 - accuracy: 0.9186\n",
            "Epoch 84/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3035 - accuracy: 0.9120\n",
            "Epoch 85/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2663 - accuracy: 0.9258\n",
            "Epoch 86/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2667 - accuracy: 0.9253\n",
            "Epoch 87/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2703 - accuracy: 0.9229\n",
            "Epoch 88/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2651 - accuracy: 0.9238\n",
            "Epoch 89/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.2836 - accuracy: 0.9165\n",
            "Epoch 90/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2698 - accuracy: 0.9222\n",
            "Epoch 91/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.2603 - accuracy: 0.9261\n",
            "Epoch 92/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2738 - accuracy: 0.9218\n",
            "Epoch 93/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.2524 - accuracy: 0.9282\n",
            "Epoch 94/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.2337 - accuracy: 0.9351\n",
            "Epoch 95/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2360 - accuracy: 0.9344\n",
            "Epoch 96/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2395 - accuracy: 0.9335\n",
            "Epoch 97/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2381 - accuracy: 0.9333\n",
            "Epoch 98/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2351 - accuracy: 0.9343\n",
            "Epoch 99/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.2267 - accuracy: 0.9376\n",
            "Epoch 100/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2230 - accuracy: 0.9385\n",
            "42000/42000 [==============================] - 2s 43us/step\n",
            "Try 4/100: Best_val_acc: [0.20601711380907467, 0.9445000290870667], lr: 0.034975337276870265, Lambda: 0.001294084269689749\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_161 (Dense)            (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_162 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_163 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_164 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_165 (Dense)            (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3316 - accuracy: 0.1025\n",
            "Epoch 2/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3247 - accuracy: 0.1160\n",
            "Epoch 3/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3222 - accuracy: 0.1211\n",
            "Epoch 4/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3199 - accuracy: 0.1330\n",
            "Epoch 5/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3177 - accuracy: 0.1406\n",
            "Epoch 6/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3154 - accuracy: 0.1635\n",
            "Epoch 7/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3132 - accuracy: 0.1712\n",
            "Epoch 8/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3111 - accuracy: 0.1752\n",
            "Epoch 9/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3087 - accuracy: 0.1927\n",
            "Epoch 10/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3062 - accuracy: 0.1975\n",
            "Epoch 11/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3036 - accuracy: 0.2071\n",
            "Epoch 12/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3008 - accuracy: 0.2238\n",
            "Epoch 13/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.2978 - accuracy: 0.2226\n",
            "Epoch 14/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.2944 - accuracy: 0.2365\n",
            "Epoch 15/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2906 - accuracy: 0.2571\n",
            "Epoch 16/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2864 - accuracy: 0.2570\n",
            "Epoch 17/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.2815 - accuracy: 0.2749\n",
            "Epoch 18/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2762 - accuracy: 0.2754\n",
            "Epoch 19/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.2698 - accuracy: 0.2870\n",
            "Epoch 20/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2625 - accuracy: 0.2983\n",
            "Epoch 21/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2546 - accuracy: 0.3019\n",
            "Epoch 22/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2456 - accuracy: 0.3074\n",
            "Epoch 23/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2352 - accuracy: 0.3129\n",
            "Epoch 24/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.2234 - accuracy: 0.3167\n",
            "Epoch 25/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2096 - accuracy: 0.3197\n",
            "Epoch 26/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.1942 - accuracy: 0.3292\n",
            "Epoch 27/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.1765 - accuracy: 0.3253\n",
            "Epoch 28/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.1557 - accuracy: 0.3407\n",
            "Epoch 29/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.1325 - accuracy: 0.3378\n",
            "Epoch 30/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.1063 - accuracy: 0.3532\n",
            "Epoch 31/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.0769 - accuracy: 0.3535\n",
            "Epoch 32/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.0449 - accuracy: 0.3644\n",
            "Epoch 33/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.0104 - accuracy: 0.3744\n",
            "Epoch 34/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.9744 - accuracy: 0.3836\n",
            "Epoch 35/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.9370 - accuracy: 0.3879\n",
            "Epoch 36/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.8997 - accuracy: 0.3990\n",
            "Epoch 37/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.8643 - accuracy: 0.4060\n",
            "Epoch 38/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.8302 - accuracy: 0.4148\n",
            "Epoch 39/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.7991 - accuracy: 0.4230\n",
            "Epoch 40/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.7681 - accuracy: 0.4312\n",
            "Epoch 41/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.7406 - accuracy: 0.4391\n",
            "Epoch 42/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.7136 - accuracy: 0.4484\n",
            "Epoch 43/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.6903 - accuracy: 0.4583\n",
            "Epoch 44/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.6681 - accuracy: 0.4653\n",
            "Epoch 45/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.6472 - accuracy: 0.4738\n",
            "Epoch 46/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.6264 - accuracy: 0.4815\n",
            "Epoch 47/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.6052 - accuracy: 0.4932\n",
            "Epoch 48/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.5879 - accuracy: 0.4964\n",
            "Epoch 49/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.5716 - accuracy: 0.5043\n",
            "Epoch 50/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.5525 - accuracy: 0.5141\n",
            "Epoch 51/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.5358 - accuracy: 0.5191\n",
            "Epoch 52/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.5184 - accuracy: 0.5261\n",
            "Epoch 53/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.5038 - accuracy: 0.5327\n",
            "Epoch 54/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.4873 - accuracy: 0.5368\n",
            "Epoch 55/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.4699 - accuracy: 0.5444\n",
            "Epoch 56/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.4543 - accuracy: 0.5525\n",
            "Epoch 57/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.4407 - accuracy: 0.5570\n",
            "Epoch 58/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.4252 - accuracy: 0.5610\n",
            "Epoch 59/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.4096 - accuracy: 0.5676\n",
            "Epoch 60/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.3979 - accuracy: 0.5700\n",
            "Epoch 61/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.3812 - accuracy: 0.5772\n",
            "Epoch 62/100\n",
            "42000/42000 [==============================] - 2s 54us/step - loss: 1.3698 - accuracy: 0.5800\n",
            "Epoch 63/100\n",
            "42000/42000 [==============================] - 4s 84us/step - loss: 1.3517 - accuracy: 0.5872\n",
            "Epoch 64/100\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 1.3411 - accuracy: 0.5896\n",
            "Epoch 65/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.3235 - accuracy: 0.5976\n",
            "Epoch 66/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.3135 - accuracy: 0.6000\n",
            "Epoch 67/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.2996 - accuracy: 0.6051\n",
            "Epoch 68/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.2918 - accuracy: 0.6062\n",
            "Epoch 69/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.2820 - accuracy: 0.6083\n",
            "Epoch 70/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.2649 - accuracy: 0.6166\n",
            "Epoch 71/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.2560 - accuracy: 0.6189\n",
            "Epoch 72/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.2434 - accuracy: 0.6229\n",
            "Epoch 73/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.2345 - accuracy: 0.6263\n",
            "Epoch 74/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.2230 - accuracy: 0.6306\n",
            "Epoch 75/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.2130 - accuracy: 0.6330\n",
            "Epoch 76/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.2047 - accuracy: 0.6369\n",
            "Epoch 77/100\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 1.1959 - accuracy: 0.6414\n",
            "Epoch 78/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.1986 - accuracy: 0.6383\n",
            "Epoch 79/100\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 1.1832 - accuracy: 0.6430\n",
            "Epoch 80/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.1756 - accuracy: 0.6463\n",
            "Epoch 81/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.1707 - accuracy: 0.6472\n",
            "Epoch 82/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.1614 - accuracy: 0.6528\n",
            "Epoch 83/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.1475 - accuracy: 0.6552\n",
            "Epoch 84/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.1397 - accuracy: 0.6596\n",
            "Epoch 85/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.1379 - accuracy: 0.6585\n",
            "Epoch 86/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.1263 - accuracy: 0.6615\n",
            "Epoch 87/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.1195 - accuracy: 0.6654\n",
            "Epoch 88/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.1134 - accuracy: 0.6676\n",
            "Epoch 89/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.1060 - accuracy: 0.6715\n",
            "Epoch 90/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.1014 - accuracy: 0.6712\n",
            "Epoch 91/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.0886 - accuracy: 0.6760\n",
            "Epoch 92/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0868 - accuracy: 0.6763\n",
            "Epoch 93/100\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 1.0802 - accuracy: 0.6799\n",
            "Epoch 94/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.0743 - accuracy: 0.6808\n",
            "Epoch 95/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0651 - accuracy: 0.6845\n",
            "Epoch 96/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0614 - accuracy: 0.6865\n",
            "Epoch 97/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0644 - accuracy: 0.6830\n",
            "Epoch 98/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.0521 - accuracy: 0.6891\n",
            "Epoch 99/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0431 - accuracy: 0.6913\n",
            "Epoch 100/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.0369 - accuracy: 0.6942\n",
            "42000/42000 [==============================] - 2s 43us/step\n",
            "Try 5/100: Best_val_acc: [1.031768485795884, 0.6964523792266846], lr: 0.0014989218452590648, Lambda: 0.0013231793335389333\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_166 (Dense)            (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_167 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_168 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_169 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_170 (Dense)            (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/100\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 2.3081 - accuracy: 0.1023\n",
            "Epoch 2/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3016 - accuracy: 0.1137\n",
            "Epoch 3/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.2992 - accuracy: 0.1177\n",
            "Epoch 4/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.2968 - accuracy: 0.1336\n",
            "Epoch 5/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2947 - accuracy: 0.1429\n",
            "Epoch 6/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2926 - accuracy: 0.1527\n",
            "Epoch 7/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2905 - accuracy: 0.1614\n",
            "Epoch 8/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2881 - accuracy: 0.1808\n",
            "Epoch 9/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.2857 - accuracy: 0.1913\n",
            "Epoch 10/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.2833 - accuracy: 0.2033\n",
            "Epoch 11/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2804 - accuracy: 0.2139\n",
            "Epoch 12/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2776 - accuracy: 0.2235\n",
            "Epoch 13/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2745 - accuracy: 0.2329\n",
            "Epoch 14/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.2708 - accuracy: 0.2407\n",
            "Epoch 15/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2668 - accuracy: 0.2519\n",
            "Epoch 16/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2624 - accuracy: 0.2565\n",
            "Epoch 17/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2574 - accuracy: 0.2672\n",
            "Epoch 18/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2516 - accuracy: 0.2771\n",
            "Epoch 19/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.2448 - accuracy: 0.2945\n",
            "Epoch 20/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2373 - accuracy: 0.2914\n",
            "Epoch 21/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2288 - accuracy: 0.3068\n",
            "Epoch 22/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.2191 - accuracy: 0.3093\n",
            "Epoch 23/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.2084 - accuracy: 0.3119\n",
            "Epoch 24/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.1951 - accuracy: 0.3140\n",
            "Epoch 25/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.1805 - accuracy: 0.3273\n",
            "Epoch 26/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.1634 - accuracy: 0.3308\n",
            "Epoch 27/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.1438 - accuracy: 0.3419\n",
            "Epoch 28/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.1221 - accuracy: 0.3447\n",
            "Epoch 29/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.0971 - accuracy: 0.3538\n",
            "Epoch 30/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.0694 - accuracy: 0.3515\n",
            "Epoch 31/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.0391 - accuracy: 0.3624\n",
            "Epoch 32/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.0060 - accuracy: 0.3740\n",
            "Epoch 33/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.9719 - accuracy: 0.3763\n",
            "Epoch 34/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.9347 - accuracy: 0.3849\n",
            "Epoch 35/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.8976 - accuracy: 0.3951\n",
            "Epoch 36/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.8620 - accuracy: 0.4003\n",
            "Epoch 37/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.8255 - accuracy: 0.4052\n",
            "Epoch 38/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.7910 - accuracy: 0.4178\n",
            "Epoch 39/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.7586 - accuracy: 0.4278\n",
            "Epoch 40/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.7301 - accuracy: 0.4337\n",
            "Epoch 41/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.7013 - accuracy: 0.4415\n",
            "Epoch 42/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.6759 - accuracy: 0.4527\n",
            "Epoch 43/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.6509 - accuracy: 0.4627\n",
            "Epoch 44/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.6272 - accuracy: 0.4719\n",
            "Epoch 45/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.6071 - accuracy: 0.4797\n",
            "Epoch 46/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.5849 - accuracy: 0.4918\n",
            "Epoch 47/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.5666 - accuracy: 0.5005\n",
            "Epoch 48/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.5466 - accuracy: 0.5069\n",
            "Epoch 49/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.5291 - accuracy: 0.5152\n",
            "Epoch 50/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.5067 - accuracy: 0.5226\n",
            "Epoch 51/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.4905 - accuracy: 0.5315\n",
            "Epoch 52/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.4707 - accuracy: 0.5376\n",
            "Epoch 53/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.4519 - accuracy: 0.5456\n",
            "Epoch 54/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.4349 - accuracy: 0.5528\n",
            "Epoch 55/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.4175 - accuracy: 0.5578\n",
            "Epoch 56/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.4003 - accuracy: 0.5658\n",
            "Epoch 57/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.3839 - accuracy: 0.5716\n",
            "Epoch 58/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.3696 - accuracy: 0.5771\n",
            "Epoch 59/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.3490 - accuracy: 0.5845\n",
            "Epoch 60/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.3383 - accuracy: 0.5878\n",
            "Epoch 61/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.3228 - accuracy: 0.5927\n",
            "Epoch 62/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.3035 - accuracy: 0.6001\n",
            "Epoch 63/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.2942 - accuracy: 0.6039\n",
            "Epoch 64/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.2793 - accuracy: 0.6087\n",
            "Epoch 65/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.2674 - accuracy: 0.6126\n",
            "Epoch 66/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.2488 - accuracy: 0.6187\n",
            "Epoch 67/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.2387 - accuracy: 0.6210\n",
            "Epoch 68/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.2171 - accuracy: 0.6291\n",
            "Epoch 69/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.2131 - accuracy: 0.6298\n",
            "Epoch 70/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.1910 - accuracy: 0.6398\n",
            "Epoch 71/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.1813 - accuracy: 0.6425\n",
            "Epoch 72/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.1699 - accuracy: 0.6445\n",
            "Epoch 73/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.1560 - accuracy: 0.6493\n",
            "Epoch 74/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.1516 - accuracy: 0.6492\n",
            "Epoch 75/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.1377 - accuracy: 0.6552\n",
            "Epoch 76/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.1236 - accuracy: 0.6602\n",
            "Epoch 77/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.1141 - accuracy: 0.6618\n",
            "Epoch 78/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.1072 - accuracy: 0.6655\n",
            "Epoch 79/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.0901 - accuracy: 0.6717\n",
            "Epoch 80/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.0823 - accuracy: 0.6745\n",
            "Epoch 81/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.0741 - accuracy: 0.6751\n",
            "Epoch 82/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.0615 - accuracy: 0.6801\n",
            "Epoch 83/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0528 - accuracy: 0.6812\n",
            "Epoch 84/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.0437 - accuracy: 0.6850\n",
            "Epoch 85/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0371 - accuracy: 0.6872\n",
            "Epoch 86/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.0426 - accuracy: 0.6845\n",
            "Epoch 87/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.0192 - accuracy: 0.6940\n",
            "Epoch 88/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.0116 - accuracy: 0.6959\n",
            "Epoch 89/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9958 - accuracy: 0.7022\n",
            "Epoch 90/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9954 - accuracy: 0.7014\n",
            "Epoch 91/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.9903 - accuracy: 0.7025\n",
            "Epoch 92/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.9809 - accuracy: 0.7058\n",
            "Epoch 93/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9830 - accuracy: 0.7049\n",
            "Epoch 94/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9632 - accuracy: 0.7114\n",
            "Epoch 95/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9607 - accuracy: 0.7121\n",
            "Epoch 96/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.9488 - accuracy: 0.7155\n",
            "Epoch 97/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9410 - accuracy: 0.7178\n",
            "Epoch 98/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9335 - accuracy: 0.7215\n",
            "Epoch 99/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9322 - accuracy: 0.7217\n",
            "Epoch 100/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9220 - accuracy: 0.7249\n",
            "42000/42000 [==============================] - 2s 45us/step\n",
            "Try 6/100: Best_val_acc: [0.9084362853595188, 0.7310237884521484], lr: 0.0015763756186507611, Lambda: 0.00010749471822500098\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_171 (Dense)            (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_172 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_173 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_174 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_175 (Dense)            (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.4359 - accuracy: 0.1238\n",
            "Epoch 2/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.3937 - accuracy: 0.1751\n",
            "Epoch 3/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.3377 - accuracy: 0.2474\n",
            "Epoch 4/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2327 - accuracy: 0.2873\n",
            "Epoch 5/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.0504 - accuracy: 0.3372\n",
            "Epoch 6/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.8427 - accuracy: 0.4031\n",
            "Epoch 7/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.6717 - accuracy: 0.4733\n",
            "Epoch 8/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.5759 - accuracy: 0.5080\n",
            "Epoch 9/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.4899 - accuracy: 0.5429\n",
            "Epoch 10/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.3963 - accuracy: 0.5770\n",
            "Epoch 11/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.3173 - accuracy: 0.6089\n",
            "Epoch 12/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.2541 - accuracy: 0.6322\n",
            "Epoch 13/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.2352 - accuracy: 0.6364\n",
            "Epoch 14/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.1774 - accuracy: 0.6566\n",
            "Epoch 15/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.1402 - accuracy: 0.6692\n",
            "Epoch 16/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0927 - accuracy: 0.6846\n",
            "Epoch 17/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0655 - accuracy: 0.6940\n",
            "Epoch 18/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0323 - accuracy: 0.7045\n",
            "Epoch 19/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0045 - accuracy: 0.7128\n",
            "Epoch 20/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.9772 - accuracy: 0.7199\n",
            "Epoch 21/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9591 - accuracy: 0.7289\n",
            "Epoch 22/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9279 - accuracy: 0.7359\n",
            "Epoch 23/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9140 - accuracy: 0.7385\n",
            "Epoch 24/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8968 - accuracy: 0.7446\n",
            "Epoch 25/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.8802 - accuracy: 0.7493\n",
            "Epoch 26/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8760 - accuracy: 0.7501\n",
            "Epoch 27/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.8543 - accuracy: 0.7557\n",
            "Epoch 28/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.8398 - accuracy: 0.7611\n",
            "Epoch 29/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.8257 - accuracy: 0.7633\n",
            "Epoch 30/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.8089 - accuracy: 0.7686\n",
            "Epoch 31/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7965 - accuracy: 0.7741\n",
            "Epoch 32/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7849 - accuracy: 0.7766\n",
            "Epoch 33/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7739 - accuracy: 0.7773\n",
            "Epoch 34/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7653 - accuracy: 0.7801\n",
            "Epoch 35/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7510 - accuracy: 0.7854\n",
            "Epoch 36/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7325 - accuracy: 0.7920\n",
            "Epoch 37/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7408 - accuracy: 0.7877\n",
            "Epoch 38/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7268 - accuracy: 0.7923\n",
            "Epoch 39/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7147 - accuracy: 0.7951\n",
            "Epoch 40/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7095 - accuracy: 0.7984\n",
            "Epoch 41/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6966 - accuracy: 0.8029\n",
            "Epoch 42/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6969 - accuracy: 0.8017\n",
            "Epoch 43/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6843 - accuracy: 0.8050\n",
            "Epoch 44/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6726 - accuracy: 0.8091\n",
            "Epoch 45/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6832 - accuracy: 0.8041\n",
            "Epoch 46/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6676 - accuracy: 0.8090\n",
            "Epoch 47/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6567 - accuracy: 0.8121\n",
            "Epoch 48/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6512 - accuracy: 0.8142\n",
            "Epoch 49/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6605 - accuracy: 0.8122\n",
            "Epoch 50/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6448 - accuracy: 0.8163\n",
            "Epoch 51/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6296 - accuracy: 0.8204\n",
            "Epoch 52/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6248 - accuracy: 0.8221\n",
            "Epoch 53/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6118 - accuracy: 0.8263\n",
            "Epoch 54/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6157 - accuracy: 0.8240\n",
            "Epoch 55/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6009 - accuracy: 0.8285\n",
            "Epoch 56/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6099 - accuracy: 0.8260\n",
            "Epoch 57/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5888 - accuracy: 0.8338\n",
            "Epoch 58/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5995 - accuracy: 0.8297\n",
            "Epoch 59/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5864 - accuracy: 0.8328\n",
            "Epoch 60/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5803 - accuracy: 0.8361\n",
            "Epoch 61/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5821 - accuracy: 0.8357\n",
            "Epoch 62/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5713 - accuracy: 0.8376\n",
            "Epoch 63/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5713 - accuracy: 0.8371\n",
            "Epoch 64/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5686 - accuracy: 0.8387\n",
            "Epoch 65/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5537 - accuracy: 0.8423\n",
            "Epoch 66/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5521 - accuracy: 0.8438\n",
            "Epoch 67/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5479 - accuracy: 0.8438\n",
            "Epoch 68/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5322 - accuracy: 0.8505\n",
            "Epoch 69/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5358 - accuracy: 0.8475\n",
            "Epoch 70/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5391 - accuracy: 0.8474\n",
            "Epoch 71/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5284 - accuracy: 0.8505\n",
            "Epoch 72/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5251 - accuracy: 0.8521\n",
            "Epoch 73/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5279 - accuracy: 0.8511\n",
            "Epoch 74/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5216 - accuracy: 0.8524\n",
            "Epoch 75/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5157 - accuracy: 0.8529\n",
            "Epoch 76/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5148 - accuracy: 0.8543\n",
            "Epoch 77/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5088 - accuracy: 0.8560\n",
            "Epoch 78/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4927 - accuracy: 0.8601\n",
            "Epoch 79/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4882 - accuracy: 0.8621\n",
            "Epoch 80/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5031 - accuracy: 0.8567\n",
            "Epoch 81/100\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 0.4907 - accuracy: 0.8604\n",
            "Epoch 82/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4855 - accuracy: 0.8626\n",
            "Epoch 83/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4872 - accuracy: 0.8630\n",
            "Epoch 84/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4802 - accuracy: 0.8638\n",
            "Epoch 85/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4853 - accuracy: 0.8608\n",
            "Epoch 86/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4697 - accuracy: 0.8678\n",
            "Epoch 87/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4649 - accuracy: 0.8690\n",
            "Epoch 88/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4539 - accuracy: 0.8724\n",
            "Epoch 89/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4616 - accuracy: 0.8693\n",
            "Epoch 90/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4550 - accuracy: 0.8709\n",
            "Epoch 91/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4585 - accuracy: 0.8709\n",
            "Epoch 92/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4690 - accuracy: 0.8648\n",
            "Epoch 93/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4497 - accuracy: 0.8729\n",
            "Epoch 94/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4464 - accuracy: 0.8728\n",
            "Epoch 95/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4502 - accuracy: 0.8722\n",
            "Epoch 96/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4368 - accuracy: 0.8775\n",
            "Epoch 97/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4348 - accuracy: 0.8777\n",
            "Epoch 98/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4299 - accuracy: 0.8784\n",
            "Epoch 99/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4543 - accuracy: 0.8700\n",
            "Epoch 100/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4351 - accuracy: 0.8769\n",
            "42000/42000 [==============================] - 2s 43us/step\n",
            "Try 7/100: Best_val_acc: [0.41324541620981126, 0.8871904611587524], lr: 0.014511994990848672, Lambda: 0.0075559290766274\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_176 (Dense)            (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_177 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_178 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_179 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_180 (Dense)            (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/100\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 2.3174 - accuracy: 0.1129\n",
            "Epoch 2/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.2991 - accuracy: 0.1656\n",
            "Epoch 3/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2783 - accuracy: 0.2308\n",
            "Epoch 4/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.2399 - accuracy: 0.2751\n",
            "Epoch 5/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.1624 - accuracy: 0.3198\n",
            "Epoch 6/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.0225 - accuracy: 0.3632\n",
            "Epoch 7/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.8343 - accuracy: 0.4253\n",
            "Epoch 8/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.6391 - accuracy: 0.4913\n",
            "Epoch 9/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.5058 - accuracy: 0.5263\n",
            "Epoch 10/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.4017 - accuracy: 0.5635\n",
            "Epoch 11/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.3288 - accuracy: 0.5840\n",
            "Epoch 12/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.2617 - accuracy: 0.6106\n",
            "Epoch 13/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.2193 - accuracy: 0.6272\n",
            "Epoch 14/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.1811 - accuracy: 0.6357\n",
            "Epoch 15/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.1464 - accuracy: 0.6485\n",
            "Epoch 16/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0885 - accuracy: 0.6706\n",
            "Epoch 17/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0695 - accuracy: 0.6769\n",
            "Epoch 18/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0516 - accuracy: 0.6811\n",
            "Epoch 19/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0002 - accuracy: 0.6990\n",
            "Epoch 20/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.9768 - accuracy: 0.7079\n",
            "Epoch 21/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9585 - accuracy: 0.7133\n",
            "Epoch 22/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.9270 - accuracy: 0.7244\n",
            "Epoch 23/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.9161 - accuracy: 0.7255\n",
            "Epoch 24/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.8855 - accuracy: 0.7364\n",
            "Epoch 25/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8787 - accuracy: 0.7385\n",
            "Epoch 26/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8565 - accuracy: 0.7453\n",
            "Epoch 27/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.8612 - accuracy: 0.7432\n",
            "Epoch 28/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.8319 - accuracy: 0.7529\n",
            "Epoch 29/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8228 - accuracy: 0.7562\n",
            "Epoch 30/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8032 - accuracy: 0.7625\n",
            "Epoch 31/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7959 - accuracy: 0.7632\n",
            "Epoch 32/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7722 - accuracy: 0.7714\n",
            "Epoch 33/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7569 - accuracy: 0.7761\n",
            "Epoch 34/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7472 - accuracy: 0.7819\n",
            "Epoch 35/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7403 - accuracy: 0.7816\n",
            "Epoch 36/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7394 - accuracy: 0.7822\n",
            "Epoch 37/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7282 - accuracy: 0.7860\n",
            "Epoch 38/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7117 - accuracy: 0.7901\n",
            "Epoch 39/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7086 - accuracy: 0.7922\n",
            "Epoch 40/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6975 - accuracy: 0.7967\n",
            "Epoch 41/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6967 - accuracy: 0.7956\n",
            "Epoch 42/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6825 - accuracy: 0.7997\n",
            "Epoch 43/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6743 - accuracy: 0.8021\n",
            "Epoch 44/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6632 - accuracy: 0.8066\n",
            "Epoch 45/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6522 - accuracy: 0.8093\n",
            "Epoch 46/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6595 - accuracy: 0.8072\n",
            "Epoch 47/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6523 - accuracy: 0.8087\n",
            "Epoch 48/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6412 - accuracy: 0.8157\n",
            "Epoch 49/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6333 - accuracy: 0.8166\n",
            "Epoch 50/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6220 - accuracy: 0.8188\n",
            "Epoch 51/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6154 - accuracy: 0.8220\n",
            "Epoch 52/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6197 - accuracy: 0.8187\n",
            "Epoch 53/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6119 - accuracy: 0.8230\n",
            "Epoch 54/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6051 - accuracy: 0.8253\n",
            "Epoch 55/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6014 - accuracy: 0.8262\n",
            "Epoch 56/100\n",
            "42000/42000 [==============================] - 2s 52us/step - loss: 0.5868 - accuracy: 0.8301\n",
            "Epoch 57/100\n",
            "42000/42000 [==============================] - 4s 85us/step - loss: 0.5751 - accuracy: 0.8340\n",
            "Epoch 58/100\n",
            "42000/42000 [==============================] - 4s 84us/step - loss: 0.5747 - accuracy: 0.8346\n",
            "Epoch 59/100\n",
            "42000/42000 [==============================] - 2s 54us/step - loss: 0.5548 - accuracy: 0.8400\n",
            "Epoch 60/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5443 - accuracy: 0.8438\n",
            "Epoch 61/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5503 - accuracy: 0.8417\n",
            "Epoch 62/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5640 - accuracy: 0.8363\n",
            "Epoch 63/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5531 - accuracy: 0.8414\n",
            "Epoch 64/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5442 - accuracy: 0.8432\n",
            "Epoch 65/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5359 - accuracy: 0.8435\n",
            "Epoch 66/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5376 - accuracy: 0.8455\n",
            "Epoch 67/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5308 - accuracy: 0.8476\n",
            "Epoch 68/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5322 - accuracy: 0.8468\n",
            "Epoch 69/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5343 - accuracy: 0.8440\n",
            "Epoch 70/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5214 - accuracy: 0.8503\n",
            "Epoch 71/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5155 - accuracy: 0.8499\n",
            "Epoch 72/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5177 - accuracy: 0.8505\n",
            "Epoch 73/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5123 - accuracy: 0.8542\n",
            "Epoch 74/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5022 - accuracy: 0.8554\n",
            "Epoch 75/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4834 - accuracy: 0.8615\n",
            "Epoch 76/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4966 - accuracy: 0.8577\n",
            "Epoch 77/100\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 0.4792 - accuracy: 0.8629\n",
            "Epoch 78/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4804 - accuracy: 0.8628\n",
            "Epoch 79/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4804 - accuracy: 0.8630\n",
            "Epoch 80/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4784 - accuracy: 0.8624\n",
            "Epoch 81/100\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 0.4797 - accuracy: 0.8630\n",
            "Epoch 82/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4744 - accuracy: 0.8648\n",
            "Epoch 83/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4784 - accuracy: 0.8628\n",
            "Epoch 84/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4605 - accuracy: 0.8696\n",
            "Epoch 85/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4469 - accuracy: 0.8755\n",
            "Epoch 86/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4547 - accuracy: 0.8698\n",
            "Epoch 87/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4446 - accuracy: 0.8736\n",
            "Epoch 88/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4410 - accuracy: 0.8742\n",
            "Epoch 89/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4617 - accuracy: 0.8676\n",
            "Epoch 90/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4517 - accuracy: 0.8711\n",
            "Epoch 91/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4313 - accuracy: 0.8773\n",
            "Epoch 92/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4335 - accuracy: 0.8770\n",
            "Epoch 93/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4299 - accuracy: 0.8785\n",
            "Epoch 94/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4268 - accuracy: 0.8780\n",
            "Epoch 95/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4342 - accuracy: 0.8770\n",
            "Epoch 96/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4211 - accuracy: 0.8809\n",
            "Epoch 97/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4347 - accuracy: 0.8748\n",
            "Epoch 98/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4214 - accuracy: 0.8800\n",
            "Epoch 99/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4156 - accuracy: 0.8815\n",
            "Epoch 100/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4149 - accuracy: 0.8820\n",
            "42000/42000 [==============================] - 2s 44us/step\n",
            "Try 8/100: Best_val_acc: [0.4055318783294587, 0.8840952515602112], lr: 0.0089762377665122, Lambda: 0.0007930026412645376\n",
            "\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_181 (Dense)            (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_182 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_183 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_184 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_185 (Dense)            (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/100\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 2.3079 - accuracy: 0.1175\n",
            "Epoch 2/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2961 - accuracy: 0.1574\n",
            "Epoch 3/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2859 - accuracy: 0.1981\n",
            "Epoch 4/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2719 - accuracy: 0.2501\n",
            "Epoch 5/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2524 - accuracy: 0.2741\n",
            "Epoch 6/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2200 - accuracy: 0.3206\n",
            "Epoch 7/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 2.1674 - accuracy: 0.3429\n",
            "Epoch 8/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.0866 - accuracy: 0.3586\n",
            "Epoch 9/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.9719 - accuracy: 0.3828\n",
            "Epoch 10/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.8393 - accuracy: 0.4183\n",
            "Epoch 11/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.7126 - accuracy: 0.4578\n",
            "Epoch 12/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.6035 - accuracy: 0.4945\n",
            "Epoch 13/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.5136 - accuracy: 0.5270\n",
            "Epoch 14/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.4337 - accuracy: 0.5570\n",
            "Epoch 15/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.3677 - accuracy: 0.5793\n",
            "Epoch 16/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.3199 - accuracy: 0.5905\n",
            "Epoch 17/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.2735 - accuracy: 0.6059\n",
            "Epoch 18/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.2356 - accuracy: 0.6147\n",
            "Epoch 19/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.2053 - accuracy: 0.6249\n",
            "Epoch 20/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.1661 - accuracy: 0.6416\n",
            "Epoch 21/100\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 1.1246 - accuracy: 0.6547\n",
            "Epoch 22/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.0971 - accuracy: 0.6655\n",
            "Epoch 23/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0821 - accuracy: 0.6700\n",
            "Epoch 24/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0575 - accuracy: 0.6797\n",
            "Epoch 25/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.0393 - accuracy: 0.6835\n",
            "Epoch 26/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.0146 - accuracy: 0.6937\n",
            "Epoch 27/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.9959 - accuracy: 0.6991\n",
            "Epoch 28/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9885 - accuracy: 0.7018\n",
            "Epoch 29/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9574 - accuracy: 0.7138\n",
            "Epoch 30/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9459 - accuracy: 0.7161\n",
            "Epoch 31/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9377 - accuracy: 0.7183\n",
            "Epoch 32/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9154 - accuracy: 0.7251\n",
            "Epoch 33/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9188 - accuracy: 0.7225\n",
            "Epoch 34/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8907 - accuracy: 0.7329\n",
            "Epoch 35/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8827 - accuracy: 0.7365\n",
            "Epoch 36/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8689 - accuracy: 0.7399\n",
            "Epoch 37/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.8470 - accuracy: 0.7484\n",
            "Epoch 38/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8421 - accuracy: 0.7462\n",
            "Epoch 39/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8383 - accuracy: 0.7489\n",
            "Epoch 40/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8257 - accuracy: 0.7521\n",
            "Epoch 41/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8230 - accuracy: 0.7530\n",
            "Epoch 42/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.8100 - accuracy: 0.7563\n",
            "Epoch 43/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7995 - accuracy: 0.7612\n",
            "Epoch 44/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7856 - accuracy: 0.7645\n",
            "Epoch 45/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7791 - accuracy: 0.7658\n",
            "Epoch 46/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7672 - accuracy: 0.7699\n",
            "Epoch 47/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7664 - accuracy: 0.7707\n",
            "Epoch 48/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7529 - accuracy: 0.7743\n",
            "Epoch 49/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7352 - accuracy: 0.7804\n",
            "Epoch 50/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7330 - accuracy: 0.7817\n",
            "Epoch 51/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7203 - accuracy: 0.7841\n",
            "Epoch 52/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7160 - accuracy: 0.7866\n",
            "Epoch 53/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7187 - accuracy: 0.7839\n",
            "Epoch 54/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7211 - accuracy: 0.7835\n",
            "Epoch 55/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6973 - accuracy: 0.7924\n",
            "Epoch 56/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6941 - accuracy: 0.7939\n",
            "Epoch 57/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6870 - accuracy: 0.7951\n",
            "Epoch 58/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6760 - accuracy: 0.7980\n",
            "Epoch 59/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6721 - accuracy: 0.7984\n",
            "Epoch 60/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6650 - accuracy: 0.8029\n",
            "Epoch 61/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6615 - accuracy: 0.8029\n",
            "Epoch 62/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6647 - accuracy: 0.8021\n",
            "Epoch 63/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6397 - accuracy: 0.8093\n",
            "Epoch 64/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6395 - accuracy: 0.8097\n",
            "Epoch 65/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6309 - accuracy: 0.8125\n",
            "Epoch 66/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6295 - accuracy: 0.8118\n",
            "Epoch 67/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6237 - accuracy: 0.8149\n",
            "Epoch 68/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6165 - accuracy: 0.8172\n",
            "Epoch 69/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6088 - accuracy: 0.8184\n",
            "Epoch 70/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6027 - accuracy: 0.8207\n",
            "Epoch 71/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5982 - accuracy: 0.8231\n",
            "Epoch 72/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5949 - accuracy: 0.8238\n",
            "Epoch 73/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5881 - accuracy: 0.8260\n",
            "Epoch 74/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5848 - accuracy: 0.8272\n",
            "Epoch 75/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5916 - accuracy: 0.8241\n",
            "Epoch 76/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5700 - accuracy: 0.8313\n",
            "Epoch 77/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5671 - accuracy: 0.8310\n",
            "Epoch 78/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5652 - accuracy: 0.8322\n",
            "Epoch 79/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5665 - accuracy: 0.8326\n",
            "Epoch 80/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5582 - accuracy: 0.8362\n",
            "Epoch 81/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5520 - accuracy: 0.8378\n",
            "Epoch 82/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5501 - accuracy: 0.8384\n",
            "Epoch 83/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5449 - accuracy: 0.8386\n",
            "Epoch 84/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5419 - accuracy: 0.8413\n",
            "Epoch 85/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5312 - accuracy: 0.8434\n",
            "Epoch 86/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5457 - accuracy: 0.8379\n",
            "Epoch 87/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5376 - accuracy: 0.8391\n",
            "Epoch 88/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5280 - accuracy: 0.8444\n",
            "Epoch 89/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5287 - accuracy: 0.8450\n",
            "Epoch 90/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5129 - accuracy: 0.8503\n",
            "Epoch 91/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5133 - accuracy: 0.8472\n",
            "Epoch 92/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5101 - accuracy: 0.8499\n",
            "Epoch 93/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5061 - accuracy: 0.8525\n",
            "Epoch 94/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5039 - accuracy: 0.8505\n",
            "Epoch 95/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4963 - accuracy: 0.8541\n",
            "Epoch 96/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4933 - accuracy: 0.8542\n",
            "Epoch 97/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4921 - accuracy: 0.8561\n",
            "Epoch 98/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4836 - accuracy: 0.8583\n",
            "Epoch 99/100\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5019 - accuracy: 0.8530\n",
            "Epoch 100/100\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4829 - accuracy: 0.8577\n",
            "42000/42000 [==============================] - 2s 44us/step\n",
            "Try 9/100: Best_val_acc: [0.46389453585942586, 0.8638095259666443], lr: 0.00552799836688967, Lambda: 0.0003018681358617448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfedvSrNBOVs",
        "colab_type": "text"
      },
      "source": [
        "**Observations:**\n",
        " - Best accuracy was for learning rate of 0.027 and lambda of 0.00066 (from a previous run)\n",
        " - \"Try 4/100: Best_val_acc: [0.20601711380907467, 0.9445000290870667], lr: 0.034975337276870265, Lambda: 0.001294084269689749\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEKGTX-QExXV",
        "colab_type": "text"
      },
      "source": [
        "## 9. Set the best hyperparameters found in the previous step. Check the Networkâ€™s accuracy.\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJuSYoDWFS7u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b58e3453-1404-46c8-e282-f1a1bfd7d874"
      },
      "source": [
        "Final_model = train_and_test_loop(X_train, y_train, hidden_nodes=256, output_nodes=10, btc_size=1000, iter_epochs=200, lr=0.027, Lambda=0.00066,verb=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_186 (Dense)            (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_187 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_188 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_189 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_190 (Dense)            (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/200\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 2.3076 - accuracy: 0.1316\n",
            "Epoch 2/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.2521 - accuracy: 0.2404\n",
            "Epoch 3/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 2.0264 - accuracy: 0.3190\n",
            "Epoch 4/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.6888 - accuracy: 0.4343\n",
            "Epoch 5/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.5215 - accuracy: 0.4977\n",
            "Epoch 6/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.3630 - accuracy: 0.5629\n",
            "Epoch 7/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.2194 - accuracy: 0.6157\n",
            "Epoch 8/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.1352 - accuracy: 0.6490\n",
            "Epoch 9/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 1.0920 - accuracy: 0.6602\n",
            "Epoch 10/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 1.0207 - accuracy: 0.6861\n",
            "Epoch 11/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9604 - accuracy: 0.7078\n",
            "Epoch 12/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.9458 - accuracy: 0.7096\n",
            "Epoch 13/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.8937 - accuracy: 0.7281\n",
            "Epoch 14/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.8817 - accuracy: 0.7323\n",
            "Epoch 15/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.8563 - accuracy: 0.7387\n",
            "Epoch 16/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.8385 - accuracy: 0.7448\n",
            "Epoch 17/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.7860 - accuracy: 0.7630\n",
            "Epoch 18/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7906 - accuracy: 0.7598\n",
            "Epoch 19/200\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 0.7531 - accuracy: 0.7727\n",
            "Epoch 20/200\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 0.7488 - accuracy: 0.7710\n",
            "Epoch 21/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.7311 - accuracy: 0.7787\n",
            "Epoch 22/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6858 - accuracy: 0.7942\n",
            "Epoch 23/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6685 - accuracy: 0.8016\n",
            "Epoch 24/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6616 - accuracy: 0.8042\n",
            "Epoch 25/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6603 - accuracy: 0.8017\n",
            "Epoch 26/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6474 - accuracy: 0.8060\n",
            "Epoch 27/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.6288 - accuracy: 0.8128\n",
            "Epoch 28/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6252 - accuracy: 0.8117\n",
            "Epoch 29/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6306 - accuracy: 0.8097\n",
            "Epoch 30/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.6002 - accuracy: 0.8213\n",
            "Epoch 31/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5880 - accuracy: 0.8248\n",
            "Epoch 32/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5739 - accuracy: 0.8289\n",
            "Epoch 33/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5607 - accuracy: 0.8330\n",
            "Epoch 34/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5696 - accuracy: 0.8295\n",
            "Epoch 35/200\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 0.5523 - accuracy: 0.8355\n",
            "Epoch 36/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5261 - accuracy: 0.8436\n",
            "Epoch 37/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5296 - accuracy: 0.8414\n",
            "Epoch 38/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.5318 - accuracy: 0.8410\n",
            "Epoch 39/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.5169 - accuracy: 0.8474\n",
            "Epoch 40/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4949 - accuracy: 0.8549\n",
            "Epoch 41/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4932 - accuracy: 0.8544\n",
            "Epoch 42/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4788 - accuracy: 0.8591\n",
            "Epoch 43/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4763 - accuracy: 0.8577\n",
            "Epoch 44/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4687 - accuracy: 0.8621\n",
            "Epoch 45/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4701 - accuracy: 0.8605\n",
            "Epoch 46/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4600 - accuracy: 0.8630\n",
            "Epoch 47/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4466 - accuracy: 0.8694\n",
            "Epoch 48/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4349 - accuracy: 0.8715\n",
            "Epoch 49/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4329 - accuracy: 0.8727\n",
            "Epoch 50/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4307 - accuracy: 0.8732\n",
            "Epoch 51/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.4439 - accuracy: 0.8668\n",
            "Epoch 52/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4438 - accuracy: 0.8683\n",
            "Epoch 53/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4172 - accuracy: 0.8753\n",
            "Epoch 54/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4050 - accuracy: 0.8802\n",
            "Epoch 55/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3991 - accuracy: 0.8819\n",
            "Epoch 56/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.4009 - accuracy: 0.8814\n",
            "Epoch 57/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3901 - accuracy: 0.8841\n",
            "Epoch 58/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3806 - accuracy: 0.8876\n",
            "Epoch 59/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3858 - accuracy: 0.8852\n",
            "Epoch 60/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3706 - accuracy: 0.8911\n",
            "Epoch 61/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3621 - accuracy: 0.8950\n",
            "Epoch 62/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3640 - accuracy: 0.8933\n",
            "Epoch 63/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3610 - accuracy: 0.8948\n",
            "Epoch 64/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3611 - accuracy: 0.8943\n",
            "Epoch 65/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3557 - accuracy: 0.8943\n",
            "Epoch 66/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3696 - accuracy: 0.8902\n",
            "Epoch 67/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3435 - accuracy: 0.8989\n",
            "Epoch 68/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3441 - accuracy: 0.8986\n",
            "Epoch 69/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3303 - accuracy: 0.9050\n",
            "Epoch 70/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3267 - accuracy: 0.9047\n",
            "Epoch 71/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3160 - accuracy: 0.9085\n",
            "Epoch 72/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3051 - accuracy: 0.9116\n",
            "Epoch 73/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3129 - accuracy: 0.9091\n",
            "Epoch 74/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3156 - accuracy: 0.9080\n",
            "Epoch 75/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3049 - accuracy: 0.9124\n",
            "Epoch 76/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.2878 - accuracy: 0.9165\n",
            "Epoch 77/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.3046 - accuracy: 0.9110\n",
            "Epoch 78/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.2966 - accuracy: 0.9143\n",
            "Epoch 79/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2981 - accuracy: 0.9126\n",
            "Epoch 80/200\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 0.2877 - accuracy: 0.9157\n",
            "Epoch 81/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.3033 - accuracy: 0.9101\n",
            "Epoch 82/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.2800 - accuracy: 0.9188\n",
            "Epoch 83/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2808 - accuracy: 0.9190\n",
            "Epoch 84/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2774 - accuracy: 0.9196\n",
            "Epoch 85/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2574 - accuracy: 0.9262\n",
            "Epoch 86/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.2651 - accuracy: 0.9238\n",
            "Epoch 87/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2519 - accuracy: 0.9295\n",
            "Epoch 88/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2518 - accuracy: 0.9281\n",
            "Epoch 89/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2448 - accuracy: 0.9315\n",
            "Epoch 90/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.2410 - accuracy: 0.9314\n",
            "Epoch 91/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.2540 - accuracy: 0.9270\n",
            "Epoch 92/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.2416 - accuracy: 0.9306\n",
            "Epoch 93/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.2559 - accuracy: 0.9253\n",
            "Epoch 94/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.2241 - accuracy: 0.9381\n",
            "Epoch 95/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.2309 - accuracy: 0.9336\n",
            "Epoch 96/200\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 0.2305 - accuracy: 0.9335\n",
            "Epoch 97/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2247 - accuracy: 0.9362\n",
            "Epoch 98/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2173 - accuracy: 0.9391\n",
            "Epoch 99/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2140 - accuracy: 0.9404\n",
            "Epoch 100/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2088 - accuracy: 0.9433\n",
            "Epoch 101/200\n",
            "42000/42000 [==============================] - 2s 58us/step - loss: 0.2023 - accuracy: 0.9447\n",
            "Epoch 102/200\n",
            "42000/42000 [==============================] - 4s 85us/step - loss: 0.1973 - accuracy: 0.9472\n",
            "Epoch 103/200\n",
            "42000/42000 [==============================] - 4s 85us/step - loss: 0.1947 - accuracy: 0.9463\n",
            "Epoch 104/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.2064 - accuracy: 0.9416\n",
            "Epoch 105/200\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 0.1995 - accuracy: 0.9449\n",
            "Epoch 106/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1862 - accuracy: 0.9495\n",
            "Epoch 107/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1765 - accuracy: 0.9542\n",
            "Epoch 108/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.1887 - accuracy: 0.9491\n",
            "Epoch 109/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.2065 - accuracy: 0.9410\n",
            "Epoch 110/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1980 - accuracy: 0.9440\n",
            "Epoch 111/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1931 - accuracy: 0.9460\n",
            "Epoch 112/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1826 - accuracy: 0.9495\n",
            "Epoch 113/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1619 - accuracy: 0.9590\n",
            "Epoch 114/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1658 - accuracy: 0.9568\n",
            "Epoch 115/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1598 - accuracy: 0.9590\n",
            "Epoch 116/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.1734 - accuracy: 0.9534\n",
            "Epoch 117/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.1520 - accuracy: 0.9617\n",
            "Epoch 118/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.1565 - accuracy: 0.9602\n",
            "Epoch 119/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1677 - accuracy: 0.9539\n",
            "Epoch 120/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1495 - accuracy: 0.9620\n",
            "Epoch 121/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.1583 - accuracy: 0.9579\n",
            "Epoch 122/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1577 - accuracy: 0.9585\n",
            "Epoch 123/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.1515 - accuracy: 0.9611\n",
            "Epoch 124/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.1334 - accuracy: 0.9686\n",
            "Epoch 125/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.1510 - accuracy: 0.9601\n",
            "Epoch 126/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1395 - accuracy: 0.9657\n",
            "Epoch 127/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1396 - accuracy: 0.9648\n",
            "Epoch 128/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1337 - accuracy: 0.9675\n",
            "Epoch 129/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1613 - accuracy: 0.9558\n",
            "Epoch 130/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1698 - accuracy: 0.9532\n",
            "Epoch 131/200\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 0.1327 - accuracy: 0.9675\n",
            "Epoch 132/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1308 - accuracy: 0.9682\n",
            "Epoch 133/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1343 - accuracy: 0.9654\n",
            "Epoch 134/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.1250 - accuracy: 0.9695\n",
            "Epoch 135/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.1113 - accuracy: 0.9753\n",
            "Epoch 136/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1101 - accuracy: 0.9758\n",
            "Epoch 137/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1036 - accuracy: 0.9784\n",
            "Epoch 138/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0984 - accuracy: 0.9803\n",
            "Epoch 139/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.1082 - accuracy: 0.9763\n",
            "Epoch 140/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.1134 - accuracy: 0.9738\n",
            "Epoch 141/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1094 - accuracy: 0.9748\n",
            "Epoch 142/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0936 - accuracy: 0.9814\n",
            "Epoch 143/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1220 - accuracy: 0.9699\n",
            "Epoch 144/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1194 - accuracy: 0.9704\n",
            "Epoch 145/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.1020 - accuracy: 0.9775\n",
            "Epoch 146/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.0964 - accuracy: 0.9795\n",
            "Epoch 147/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0998 - accuracy: 0.9778\n",
            "Epoch 148/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0980 - accuracy: 0.9779\n",
            "Epoch 149/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.1063 - accuracy: 0.9742\n",
            "Epoch 150/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0877 - accuracy: 0.9824\n",
            "Epoch 151/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.0785 - accuracy: 0.9866\n",
            "Epoch 152/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0781 - accuracy: 0.9868\n",
            "Epoch 153/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.1019 - accuracy: 0.9755\n",
            "Epoch 154/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0871 - accuracy: 0.9831\n",
            "Epoch 155/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0757 - accuracy: 0.9875\n",
            "Epoch 156/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.0817 - accuracy: 0.9847\n",
            "Epoch 157/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0847 - accuracy: 0.9825\n",
            "Epoch 158/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.1028 - accuracy: 0.9747\n",
            "Epoch 159/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.0966 - accuracy: 0.9777\n",
            "Epoch 160/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.0774 - accuracy: 0.9853\n",
            "Epoch 161/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.0885 - accuracy: 0.9810\n",
            "Epoch 162/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.0759 - accuracy: 0.9865\n",
            "Epoch 163/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0774 - accuracy: 0.9859\n",
            "Epoch 164/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.0751 - accuracy: 0.9859\n",
            "Epoch 165/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0750 - accuracy: 0.9864\n",
            "Epoch 166/200\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 0.0687 - accuracy: 0.9885\n",
            "Epoch 167/200\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 0.0628 - accuracy: 0.9910\n",
            "Epoch 168/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.0595 - accuracy: 0.9921\n",
            "Epoch 169/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0576 - accuracy: 0.9926\n",
            "Epoch 170/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.0572 - accuracy: 0.9927\n",
            "Epoch 171/200\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 0.0566 - accuracy: 0.9928\n",
            "Epoch 172/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0545 - accuracy: 0.9943\n",
            "Epoch 173/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0570 - accuracy: 0.9927\n",
            "Epoch 174/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0508 - accuracy: 0.9952\n",
            "Epoch 175/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.0496 - accuracy: 0.9953\n",
            "Epoch 176/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0547 - accuracy: 0.9934\n",
            "Epoch 177/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.0638 - accuracy: 0.9891\n",
            "Epoch 178/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0572 - accuracy: 0.9919\n",
            "Epoch 179/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0568 - accuracy: 0.9921\n",
            "Epoch 180/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0535 - accuracy: 0.9937\n",
            "Epoch 181/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.0492 - accuracy: 0.9949\n",
            "Epoch 182/200\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 0.0458 - accuracy: 0.9964\n",
            "Epoch 183/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0415 - accuracy: 0.9976\n",
            "Epoch 184/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.0397 - accuracy: 0.9979\n",
            "Epoch 185/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.0396 - accuracy: 0.9980\n",
            "Epoch 186/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0379 - accuracy: 0.9983\n",
            "Epoch 187/200\n",
            "42000/42000 [==============================] - 2s 50us/step - loss: 0.0370 - accuracy: 0.9985\n",
            "Epoch 188/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0387 - accuracy: 0.9979\n",
            "Epoch 189/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0403 - accuracy: 0.9976\n",
            "Epoch 190/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0403 - accuracy: 0.9973\n",
            "Epoch 191/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0379 - accuracy: 0.9982\n",
            "Epoch 192/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.0357 - accuracy: 0.9987\n",
            "Epoch 193/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.0339 - accuracy: 0.9991\n",
            "Epoch 194/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0360 - accuracy: 0.9986\n",
            "Epoch 195/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0365 - accuracy: 0.9983\n",
            "Epoch 196/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.0370 - accuracy: 0.9983\n",
            "Epoch 197/200\n",
            "42000/42000 [==============================] - 2s 49us/step - loss: 0.0332 - accuracy: 0.9992\n",
            "Epoch 198/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0338 - accuracy: 0.9989\n",
            "Epoch 199/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0324 - accuracy: 0.9992\n",
            "Epoch 200/200\n",
            "42000/42000 [==============================] - 2s 48us/step - loss: 0.0337 - accuracy: 0.9989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQmgR_1xB5_8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "75a8a2e7-17c8-4fca-ce90-24ef076f46cc"
      },
      "source": [
        "Final_score = Final_model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18000/18000 [==============================] - 1s 52us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIJoImxcB52r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "edd77db1-d678-409e-ff20-c21922cfae11"
      },
      "source": [
        "print('Accuracy of the final neural network model on Test set: ', Final_score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the final neural network model on Test set:  0.8180555701255798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b92bcVaavwqt",
        "colab_type": "text"
      },
      "source": [
        "**Observations:**\n",
        " - Even with very high accuracy of 0.99 on train data, the model performance on test data is 0.81\n",
        " - There is room for considering other tuning options to stabilize the model across training and testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85DefjF6D-7j",
        "colab_type": "text"
      },
      "source": [
        "## 10. Add Batch Normalization technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dykav4SHHEtv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b9fe636a-b327-4e1d-e622-ec9df13db825"
      },
      "source": [
        "Final_model_Normalized = train_and_test_loop(X_train, y_train, hidden_nodes=256, output_nodes=10, btc_size=100, iter_epochs=200, lr=0.027, Lambda=0.00066,verb=False, addbatchnormalization=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Added Batch Normalization after input layer\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_191 (Dense)            (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_192 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_193 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_194 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_195 (Dense)            (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 466,442\n",
            "Trainable params: 464,394\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/200\n",
            "42000/42000 [==============================] - 5s 126us/step - loss: 1.2938 - accuracy: 0.5787\n",
            "Epoch 2/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.8555 - accuracy: 0.7321\n",
            "Epoch 3/200\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 0.7212 - accuracy: 0.7743\n",
            "Epoch 4/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.6320 - accuracy: 0.8059\n",
            "Epoch 5/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.5792 - accuracy: 0.8213\n",
            "Epoch 6/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.5350 - accuracy: 0.8364\n",
            "Epoch 7/200\n",
            "42000/42000 [==============================] - 5s 111us/step - loss: 0.4955 - accuracy: 0.8470\n",
            "Epoch 8/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.4655 - accuracy: 0.8572\n",
            "Epoch 9/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.4369 - accuracy: 0.8655\n",
            "Epoch 10/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.4078 - accuracy: 0.8765\n",
            "Epoch 11/200\n",
            "42000/42000 [==============================] - 5s 110us/step - loss: 0.3837 - accuracy: 0.8830\n",
            "Epoch 12/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.3640 - accuracy: 0.8915\n",
            "Epoch 13/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.3433 - accuracy: 0.8977\n",
            "Epoch 14/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.3250 - accuracy: 0.9013\n",
            "Epoch 15/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.3130 - accuracy: 0.9052\n",
            "Epoch 16/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.2932 - accuracy: 0.9128\n",
            "Epoch 17/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.2805 - accuracy: 0.9160\n",
            "Epoch 18/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.2632 - accuracy: 0.9216\n",
            "Epoch 19/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.2524 - accuracy: 0.9251\n",
            "Epoch 20/200\n",
            "42000/42000 [==============================] - 5s 111us/step - loss: 0.2354 - accuracy: 0.9315\n",
            "Epoch 21/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.2353 - accuracy: 0.9314\n",
            "Epoch 22/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.2249 - accuracy: 0.9353\n",
            "Epoch 23/200\n",
            "42000/42000 [==============================] - 5s 111us/step - loss: 0.2145 - accuracy: 0.9378\n",
            "Epoch 24/200\n",
            "42000/42000 [==============================] - 5s 111us/step - loss: 0.1986 - accuracy: 0.9431\n",
            "Epoch 25/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.1955 - accuracy: 0.9453\n",
            "Epoch 26/200\n",
            "42000/42000 [==============================] - 7s 168us/step - loss: 0.1917 - accuracy: 0.9458\n",
            "Epoch 27/200\n",
            "42000/42000 [==============================] - 6s 139us/step - loss: 0.1815 - accuracy: 0.9483\n",
            "Epoch 28/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.1687 - accuracy: 0.9540\n",
            "Epoch 29/200\n",
            "42000/42000 [==============================] - 5s 119us/step - loss: 0.1611 - accuracy: 0.9564\n",
            "Epoch 30/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.1593 - accuracy: 0.9559\n",
            "Epoch 31/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.1532 - accuracy: 0.9583\n",
            "Epoch 32/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.1435 - accuracy: 0.9615\n",
            "Epoch 33/200\n",
            "42000/42000 [==============================] - 5s 117us/step - loss: 0.1432 - accuracy: 0.9620\n",
            "Epoch 34/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.1376 - accuracy: 0.9629\n",
            "Epoch 35/200\n",
            "42000/42000 [==============================] - 5s 111us/step - loss: 0.1302 - accuracy: 0.9664\n",
            "Epoch 36/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.1254 - accuracy: 0.9676\n",
            "Epoch 37/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.1241 - accuracy: 0.9671\n",
            "Epoch 38/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.1138 - accuracy: 0.9718\n",
            "Epoch 39/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.1159 - accuracy: 0.9703\n",
            "Epoch 40/200\n",
            "42000/42000 [==============================] - 5s 121us/step - loss: 0.0994 - accuracy: 0.9764\n",
            "Epoch 41/200\n",
            "42000/42000 [==============================] - 5s 119us/step - loss: 0.1062 - accuracy: 0.9734\n",
            "Epoch 42/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.1082 - accuracy: 0.9717\n",
            "Epoch 43/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.1026 - accuracy: 0.9743\n",
            "Epoch 44/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0982 - accuracy: 0.9762\n",
            "Epoch 45/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0981 - accuracy: 0.9755\n",
            "Epoch 46/200\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 0.0888 - accuracy: 0.9791\n",
            "Epoch 47/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0820 - accuracy: 0.9807\n",
            "Epoch 48/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0844 - accuracy: 0.9799\n",
            "Epoch 49/200\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 0.0817 - accuracy: 0.9806\n",
            "Epoch 50/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0859 - accuracy: 0.9795\n",
            "Epoch 51/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0810 - accuracy: 0.9812\n",
            "Epoch 52/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0834 - accuracy: 0.9798\n",
            "Epoch 53/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0817 - accuracy: 0.9797\n",
            "Epoch 54/200\n",
            "42000/42000 [==============================] - 5s 118us/step - loss: 0.0757 - accuracy: 0.9819\n",
            "Epoch 55/200\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 0.0727 - accuracy: 0.9834\n",
            "Epoch 56/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0750 - accuracy: 0.9824\n",
            "Epoch 57/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0711 - accuracy: 0.9838\n",
            "Epoch 58/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0684 - accuracy: 0.9846\n",
            "Epoch 59/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0644 - accuracy: 0.9866\n",
            "Epoch 60/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0652 - accuracy: 0.9853\n",
            "Epoch 61/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0649 - accuracy: 0.9856\n",
            "Epoch 62/200\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 0.0663 - accuracy: 0.9847\n",
            "Epoch 63/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0633 - accuracy: 0.9859\n",
            "Epoch 64/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0590 - accuracy: 0.9874\n",
            "Epoch 65/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0640 - accuracy: 0.9859\n",
            "Epoch 66/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0576 - accuracy: 0.9874\n",
            "Epoch 67/200\n",
            "42000/42000 [==============================] - 5s 111us/step - loss: 0.0499 - accuracy: 0.9913\n",
            "Epoch 68/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0535 - accuracy: 0.9895\n",
            "Epoch 69/200\n",
            "42000/42000 [==============================] - 5s 111us/step - loss: 0.0520 - accuracy: 0.9900\n",
            "Epoch 70/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0495 - accuracy: 0.9901\n",
            "Epoch 71/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0511 - accuracy: 0.9901\n",
            "Epoch 72/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0528 - accuracy: 0.9890\n",
            "Epoch 73/200\n",
            "42000/42000 [==============================] - 5s 111us/step - loss: 0.0497 - accuracy: 0.9900\n",
            "Epoch 74/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0530 - accuracy: 0.9888\n",
            "Epoch 75/200\n",
            "42000/42000 [==============================] - 5s 118us/step - loss: 0.0498 - accuracy: 0.9901\n",
            "Epoch 76/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0451 - accuracy: 0.9920\n",
            "Epoch 77/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0486 - accuracy: 0.9906\n",
            "Epoch 78/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0432 - accuracy: 0.9919\n",
            "Epoch 79/200\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 0.0456 - accuracy: 0.9912\n",
            "Epoch 80/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0450 - accuracy: 0.9914\n",
            "Epoch 81/200\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 0.0482 - accuracy: 0.9899\n",
            "Epoch 82/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0418 - accuracy: 0.9923\n",
            "Epoch 83/200\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 0.0431 - accuracy: 0.9919\n",
            "Epoch 84/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0386 - accuracy: 0.9934\n",
            "Epoch 85/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0374 - accuracy: 0.9939\n",
            "Epoch 86/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0370 - accuracy: 0.9938\n",
            "Epoch 87/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0398 - accuracy: 0.9928\n",
            "Epoch 88/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0381 - accuracy: 0.9933\n",
            "Epoch 89/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0377 - accuracy: 0.9933\n",
            "Epoch 90/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0388 - accuracy: 0.9931\n",
            "Epoch 91/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0401 - accuracy: 0.9926\n",
            "Epoch 92/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0365 - accuracy: 0.9935\n",
            "Epoch 93/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0363 - accuracy: 0.9934\n",
            "Epoch 94/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0377 - accuracy: 0.9930\n",
            "Epoch 95/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0361 - accuracy: 0.9938\n",
            "Epoch 96/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0354 - accuracy: 0.9935\n",
            "Epoch 97/200\n",
            "42000/42000 [==============================] - 5s 111us/step - loss: 0.0373 - accuracy: 0.9931\n",
            "Epoch 98/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0364 - accuracy: 0.9934\n",
            "Epoch 99/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0356 - accuracy: 0.9935\n",
            "Epoch 100/200\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 0.0349 - accuracy: 0.9938\n",
            "Epoch 101/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0351 - accuracy: 0.9936\n",
            "Epoch 102/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0354 - accuracy: 0.9933\n",
            "Epoch 103/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0354 - accuracy: 0.9934\n",
            "Epoch 104/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0323 - accuracy: 0.9947\n",
            "Epoch 105/200\n",
            "42000/42000 [==============================] - 5s 121us/step - loss: 0.0317 - accuracy: 0.9949\n",
            "Epoch 106/200\n",
            "42000/42000 [==============================] - 5s 120us/step - loss: 0.0301 - accuracy: 0.9954\n",
            "Epoch 107/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0332 - accuracy: 0.9943\n",
            "Epoch 108/200\n",
            "42000/42000 [==============================] - 5s 117us/step - loss: 0.0302 - accuracy: 0.9952\n",
            "Epoch 109/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0346 - accuracy: 0.9932\n",
            "Epoch 110/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0317 - accuracy: 0.9944\n",
            "Epoch 111/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0312 - accuracy: 0.9946\n",
            "Epoch 112/200\n",
            "42000/42000 [==============================] - 5s 117us/step - loss: 0.0308 - accuracy: 0.9950\n",
            "Epoch 113/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0300 - accuracy: 0.9948\n",
            "Epoch 114/200\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 0.0283 - accuracy: 0.9954\n",
            "Epoch 115/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0310 - accuracy: 0.9948\n",
            "Epoch 116/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0315 - accuracy: 0.9949\n",
            "Epoch 117/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0317 - accuracy: 0.9940\n",
            "Epoch 118/200\n",
            "42000/42000 [==============================] - 5s 120us/step - loss: 0.0313 - accuracy: 0.9943\n",
            "Epoch 119/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0293 - accuracy: 0.9949\n",
            "Epoch 120/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0270 - accuracy: 0.9961\n",
            "Epoch 121/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0281 - accuracy: 0.9952\n",
            "Epoch 122/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0290 - accuracy: 0.9952\n",
            "Epoch 123/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0280 - accuracy: 0.9956\n",
            "Epoch 124/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0255 - accuracy: 0.9965\n",
            "Epoch 125/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0257 - accuracy: 0.9955\n",
            "Epoch 126/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0235 - accuracy: 0.9968\n",
            "Epoch 127/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0256 - accuracy: 0.9960\n",
            "Epoch 128/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0253 - accuracy: 0.9963\n",
            "Epoch 129/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0268 - accuracy: 0.9955\n",
            "Epoch 130/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0212 - accuracy: 0.9978\n",
            "Epoch 131/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0234 - accuracy: 0.9966\n",
            "Epoch 132/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0261 - accuracy: 0.9957\n",
            "Epoch 133/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0219 - accuracy: 0.9971\n",
            "Epoch 134/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0231 - accuracy: 0.9964\n",
            "Epoch 135/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0268 - accuracy: 0.9949\n",
            "Epoch 136/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0244 - accuracy: 0.9962\n",
            "Epoch 137/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0262 - accuracy: 0.9956\n",
            "Epoch 138/200\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 0.0232 - accuracy: 0.9965\n",
            "Epoch 139/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0269 - accuracy: 0.9949\n",
            "Epoch 140/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0218 - accuracy: 0.9972\n",
            "Epoch 141/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0226 - accuracy: 0.9964\n",
            "Epoch 142/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0225 - accuracy: 0.9968\n",
            "Epoch 143/200\n",
            "42000/42000 [==============================] - 5s 111us/step - loss: 0.0210 - accuracy: 0.9973\n",
            "Epoch 144/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0228 - accuracy: 0.9963\n",
            "Epoch 145/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0227 - accuracy: 0.9968\n",
            "Epoch 146/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0188 - accuracy: 0.9979\n",
            "Epoch 147/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0203 - accuracy: 0.9973\n",
            "Epoch 148/200\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 0.0226 - accuracy: 0.9963\n",
            "Epoch 149/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0212 - accuracy: 0.9972\n",
            "Epoch 150/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0198 - accuracy: 0.9976\n",
            "Epoch 151/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0230 - accuracy: 0.9964\n",
            "Epoch 152/200\n",
            "42000/42000 [==============================] - 5s 121us/step - loss: 0.0227 - accuracy: 0.9961\n",
            "Epoch 153/200\n",
            "42000/42000 [==============================] - 8s 184us/step - loss: 0.0295 - accuracy: 0.9939\n",
            "Epoch 154/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0252 - accuracy: 0.9957\n",
            "Epoch 155/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0233 - accuracy: 0.9963\n",
            "Epoch 156/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0231 - accuracy: 0.9965\n",
            "Epoch 157/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0237 - accuracy: 0.9962\n",
            "Epoch 158/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0226 - accuracy: 0.9965\n",
            "Epoch 159/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0240 - accuracy: 0.9960\n",
            "Epoch 160/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0229 - accuracy: 0.9961\n",
            "Epoch 161/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0240 - accuracy: 0.9956\n",
            "Epoch 162/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0234 - accuracy: 0.9964\n",
            "Epoch 163/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0199 - accuracy: 0.9975\n",
            "Epoch 164/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0210 - accuracy: 0.9967\n",
            "Epoch 165/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0213 - accuracy: 0.9964\n",
            "Epoch 166/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0213 - accuracy: 0.9969\n",
            "Epoch 167/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0195 - accuracy: 0.9973\n",
            "Epoch 168/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0199 - accuracy: 0.9969\n",
            "Epoch 169/200\n",
            "42000/42000 [==============================] - 5s 118us/step - loss: 0.0197 - accuracy: 0.9972\n",
            "Epoch 170/200\n",
            "42000/42000 [==============================] - 5s 121us/step - loss: 0.0203 - accuracy: 0.9968\n",
            "Epoch 171/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0191 - accuracy: 0.9975\n",
            "Epoch 172/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0209 - accuracy: 0.9965\n",
            "Epoch 173/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0210 - accuracy: 0.9967\n",
            "Epoch 174/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0198 - accuracy: 0.9971\n",
            "Epoch 175/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0175 - accuracy: 0.9977\n",
            "Epoch 176/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0200 - accuracy: 0.9970\n",
            "Epoch 177/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0195 - accuracy: 0.9973\n",
            "Epoch 178/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0174 - accuracy: 0.9978\n",
            "Epoch 179/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0170 - accuracy: 0.9978\n",
            "Epoch 180/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0173 - accuracy: 0.9979\n",
            "Epoch 181/200\n",
            "42000/42000 [==============================] - 5s 118us/step - loss: 0.0175 - accuracy: 0.9974\n",
            "Epoch 182/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0160 - accuracy: 0.9982\n",
            "Epoch 183/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0158 - accuracy: 0.9985\n",
            "Epoch 184/200\n",
            "42000/42000 [==============================] - 5s 112us/step - loss: 0.0160 - accuracy: 0.9980\n",
            "Epoch 185/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0146 - accuracy: 0.9985\n",
            "Epoch 186/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0167 - accuracy: 0.9978\n",
            "Epoch 187/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0203 - accuracy: 0.9967\n",
            "Epoch 188/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0210 - accuracy: 0.9963\n",
            "Epoch 189/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0170 - accuracy: 0.9979\n",
            "Epoch 190/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0169 - accuracy: 0.9977\n",
            "Epoch 191/200\n",
            "42000/42000 [==============================] - 5s 111us/step - loss: 0.0177 - accuracy: 0.9975\n",
            "Epoch 192/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0185 - accuracy: 0.9972\n",
            "Epoch 193/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0174 - accuracy: 0.9978\n",
            "Epoch 194/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0206 - accuracy: 0.9963\n",
            "Epoch 195/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0189 - accuracy: 0.9971\n",
            "Epoch 196/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0192 - accuracy: 0.9970\n",
            "Epoch 197/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0173 - accuracy: 0.9977\n",
            "Epoch 198/200\n",
            "42000/42000 [==============================] - 5s 113us/step - loss: 0.0174 - accuracy: 0.9974\n",
            "Epoch 199/200\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.0159 - accuracy: 0.9982\n",
            "Epoch 200/200\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.0167 - accuracy: 0.9976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRi1unsVFC2O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4fc153cd-e66c-4441-96e1-83452db0cd0b"
      },
      "source": [
        "Score_normalized = Final_model_Normalized.evaluate(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42000/42000 [==============================] - 2s 58us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5u3euBqFCtk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "57ce08c0-4abd-4121-de6d-4d2003ad3495"
      },
      "source": [
        "print('Accuracy with batch normalization: ', Score_normalized[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy with batch normalization:  0.998452365398407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvpZauk3wijc",
        "colab_type": "text"
      },
      "source": [
        "**Observation**\n",
        " - Within the first 20 epochs, the training accuracy went up steep. By 50 epochs, the accuracy went up to 0.98. \n",
        " - By 100 epochs, the accuracy is 0.99. yet planned 200 epochs to see if the accuracy of model on test data improves significantly over the iteration without batch normalization\n",
        " - Final train accuracy is very good 0.998"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUI6zF7reTGE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b88b58d9-47c8-4441-d4d9-7aa8ddb5f8e7"
      },
      "source": [
        "score_normalized_test = Final_model_Normalized.evaluate(X_test, y_test)\n",
        "print('Accuracy with batch normalization: ', score_normalized_test[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18000/18000 [==============================] - 1s 56us/step\n",
            "Accuracy with batch normalization:  0.4534444510936737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHQ-oK8sJmGQ",
        "colab_type": "text"
      },
      "source": [
        "**Observation:**\n",
        " - With Batch Normalization, the training quickly converged and a better accuracy is obtained\n",
        " - The model performance on test data is poor compared to non-normalized model\n",
        " - This could mean, the hyperparameters could have been further tuned to build the model more stable with batch normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG8hzg-XWib_",
        "colab_type": "text"
      },
      "source": [
        "## 11. Add Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWnakBKrWmXA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "75262309-98aa-4352-f57d-211ad06cab38"
      },
      "source": [
        "Final_model_dropout = train_and_test_loop(X_train, y_train, hidden_nodes=256, output_nodes=10, btc_size=100, iter_epochs=100, lr=0.027, Lambda=0.00066, setdropout=True, verb=False, addbatchnormalization=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Added Batch Normalization after input layer\n",
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_196 (Dense)            (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_197 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_198 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_199 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_200 (Dense)            (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 466,442\n",
            "Trainable params: 464,394\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/100\n",
            "42000/42000 [==============================] - 6s 151us/step - loss: 1.7279 - accuracy: 0.4020\n",
            "Epoch 2/100\n",
            "42000/42000 [==============================] - 6s 133us/step - loss: 1.1843 - accuracy: 0.6194\n",
            "Epoch 3/100\n",
            "42000/42000 [==============================] - 5s 129us/step - loss: 1.0267 - accuracy: 0.6748\n",
            "Epoch 4/100\n",
            "42000/42000 [==============================] - 5s 131us/step - loss: 0.9393 - accuracy: 0.7046\n",
            "Epoch 5/100\n",
            "42000/42000 [==============================] - 5s 130us/step - loss: 0.8769 - accuracy: 0.7248\n",
            "Epoch 6/100\n",
            "42000/42000 [==============================] - 6s 133us/step - loss: 0.8201 - accuracy: 0.7446\n",
            "Epoch 7/100\n",
            "42000/42000 [==============================] - 6s 132us/step - loss: 0.7878 - accuracy: 0.7541\n",
            "Epoch 8/100\n",
            "42000/42000 [==============================] - 6s 134us/step - loss: 0.7575 - accuracy: 0.7661\n",
            "Epoch 9/100\n",
            "42000/42000 [==============================] - 6s 132us/step - loss: 0.7310 - accuracy: 0.7721\n",
            "Epoch 10/100\n",
            "42000/42000 [==============================] - 6s 132us/step - loss: 0.7108 - accuracy: 0.7787\n",
            "Epoch 11/100\n",
            "42000/42000 [==============================] - 6s 134us/step - loss: 0.6847 - accuracy: 0.7877\n",
            "Epoch 12/100\n",
            "42000/42000 [==============================] - 6s 131us/step - loss: 0.6694 - accuracy: 0.7918\n",
            "Epoch 13/100\n",
            "42000/42000 [==============================] - 5s 130us/step - loss: 0.6553 - accuracy: 0.7966\n",
            "Epoch 14/100\n",
            "42000/42000 [==============================] - 5s 130us/step - loss: 0.6423 - accuracy: 0.8019\n",
            "Epoch 15/100\n",
            "42000/42000 [==============================] - 6s 134us/step - loss: 0.6210 - accuracy: 0.8070\n",
            "Epoch 16/100\n",
            "42000/42000 [==============================] - 6s 131us/step - loss: 0.6162 - accuracy: 0.8061\n",
            "Epoch 17/100\n",
            "42000/42000 [==============================] - 5s 128us/step - loss: 0.6026 - accuracy: 0.8118\n",
            "Epoch 18/100\n",
            "42000/42000 [==============================] - 5s 129us/step - loss: 0.5959 - accuracy: 0.8148\n",
            "Epoch 19/100\n",
            "42000/42000 [==============================] - 6s 133us/step - loss: 0.5889 - accuracy: 0.8187\n",
            "Epoch 20/100\n",
            "42000/42000 [==============================] - 5s 129us/step - loss: 0.5752 - accuracy: 0.8209\n",
            "Epoch 21/100\n",
            "42000/42000 [==============================] - 5s 130us/step - loss: 0.5700 - accuracy: 0.8204\n",
            "Epoch 22/100\n",
            "42000/42000 [==============================] - 5s 128us/step - loss: 0.5558 - accuracy: 0.8293\n",
            "Epoch 23/100\n",
            "42000/42000 [==============================] - 5s 130us/step - loss: 0.5527 - accuracy: 0.8306\n",
            "Epoch 24/100\n",
            "42000/42000 [==============================] - 5s 127us/step - loss: 0.5435 - accuracy: 0.8311\n",
            "Epoch 25/100\n",
            "42000/42000 [==============================] - 5s 127us/step - loss: 0.5340 - accuracy: 0.8353\n",
            "Epoch 26/100\n",
            "42000/42000 [==============================] - 5s 128us/step - loss: 0.5334 - accuracy: 0.8333\n",
            "Epoch 27/100\n",
            "42000/42000 [==============================] - 5s 129us/step - loss: 0.5217 - accuracy: 0.8388\n",
            "Epoch 28/100\n",
            "42000/42000 [==============================] - 5s 129us/step - loss: 0.5153 - accuracy: 0.8407\n",
            "Epoch 29/100\n",
            "42000/42000 [==============================] - 6s 132us/step - loss: 0.5116 - accuracy: 0.8418\n",
            "Epoch 30/100\n",
            "42000/42000 [==============================] - 6s 135us/step - loss: 0.5141 - accuracy: 0.8397\n",
            "Epoch 31/100\n",
            "42000/42000 [==============================] - 5s 130us/step - loss: 0.4940 - accuracy: 0.8469\n",
            "Epoch 32/100\n",
            "42000/42000 [==============================] - 6s 132us/step - loss: 0.4965 - accuracy: 0.8463\n",
            "Epoch 33/100\n",
            "42000/42000 [==============================] - 5s 128us/step - loss: 0.4913 - accuracy: 0.8490\n",
            "Epoch 34/100\n",
            "42000/42000 [==============================] - 5s 128us/step - loss: 0.4828 - accuracy: 0.8506\n",
            "Epoch 35/100\n",
            "42000/42000 [==============================] - 5s 130us/step - loss: 0.4798 - accuracy: 0.8501\n",
            "Epoch 36/100\n",
            "42000/42000 [==============================] - 6s 133us/step - loss: 0.4716 - accuracy: 0.8541\n",
            "Epoch 37/100\n",
            "42000/42000 [==============================] - 6s 150us/step - loss: 0.4620 - accuracy: 0.8561\n",
            "Epoch 38/100\n",
            "42000/42000 [==============================] - 8s 183us/step - loss: 0.4638 - accuracy: 0.8556\n",
            "Epoch 39/100\n",
            "42000/42000 [==============================] - 5s 128us/step - loss: 0.4698 - accuracy: 0.8544\n",
            "Epoch 40/100\n",
            "42000/42000 [==============================] - 6s 131us/step - loss: 0.4581 - accuracy: 0.8599\n",
            "Epoch 41/100\n",
            "42000/42000 [==============================] - 5s 130us/step - loss: 0.4576 - accuracy: 0.8573\n",
            "Epoch 42/100\n",
            "42000/42000 [==============================] - 5s 130us/step - loss: 0.4484 - accuracy: 0.8610\n",
            "Epoch 43/100\n",
            "42000/42000 [==============================] - 6s 132us/step - loss: 0.4491 - accuracy: 0.8593\n",
            "Epoch 44/100\n",
            "42000/42000 [==============================] - 6s 133us/step - loss: 0.4458 - accuracy: 0.8606\n",
            "Epoch 45/100\n",
            "42000/42000 [==============================] - 5s 130us/step - loss: 0.4399 - accuracy: 0.8641\n",
            "Epoch 46/100\n",
            "42000/42000 [==============================] - 6s 133us/step - loss: 0.4364 - accuracy: 0.8626\n",
            "Epoch 47/100\n",
            "42000/42000 [==============================] - 5s 129us/step - loss: 0.4382 - accuracy: 0.8639\n",
            "Epoch 48/100\n",
            "42000/42000 [==============================] - 5s 128us/step - loss: 0.4386 - accuracy: 0.8636\n",
            "Epoch 49/100\n",
            "42000/42000 [==============================] - 5s 131us/step - loss: 0.4317 - accuracy: 0.8658\n",
            "Epoch 50/100\n",
            "42000/42000 [==============================] - 5s 130us/step - loss: 0.4250 - accuracy: 0.8684\n",
            "Epoch 51/100\n",
            "42000/42000 [==============================] - 6s 133us/step - loss: 0.4236 - accuracy: 0.8701\n",
            "Epoch 52/100\n",
            "42000/42000 [==============================] - 6s 133us/step - loss: 0.4243 - accuracy: 0.8660\n",
            "Epoch 53/100\n",
            "42000/42000 [==============================] - 5s 130us/step - loss: 0.4134 - accuracy: 0.8715\n",
            "Epoch 54/100\n",
            "42000/42000 [==============================] - 5s 130us/step - loss: 0.4218 - accuracy: 0.8687\n",
            "Epoch 55/100\n",
            "42000/42000 [==============================] - 5s 128us/step - loss: 0.4141 - accuracy: 0.8725\n",
            "Epoch 56/100\n",
            "42000/42000 [==============================] - 6s 134us/step - loss: 0.4118 - accuracy: 0.8727\n",
            "Epoch 57/100\n",
            "42000/42000 [==============================] - 6s 141us/step - loss: 0.4092 - accuracy: 0.8720\n",
            "Epoch 58/100\n",
            "42000/42000 [==============================] - 6s 132us/step - loss: 0.4104 - accuracy: 0.8737\n",
            "Epoch 59/100\n",
            "42000/42000 [==============================] - 5s 129us/step - loss: 0.4048 - accuracy: 0.8735\n",
            "Epoch 60/100\n",
            "42000/42000 [==============================] - 6s 135us/step - loss: 0.4039 - accuracy: 0.8740\n",
            "Epoch 61/100\n",
            "42000/42000 [==============================] - 6s 131us/step - loss: 0.3988 - accuracy: 0.8750\n",
            "Epoch 62/100\n",
            "42000/42000 [==============================] - 6s 132us/step - loss: 0.3940 - accuracy: 0.8775\n",
            "Epoch 63/100\n",
            "42000/42000 [==============================] - 6s 136us/step - loss: 0.3948 - accuracy: 0.8761\n",
            "Epoch 64/100\n",
            "42000/42000 [==============================] - 6s 132us/step - loss: 0.3892 - accuracy: 0.8777\n",
            "Epoch 65/100\n",
            "42000/42000 [==============================] - 6s 134us/step - loss: 0.3839 - accuracy: 0.8796\n",
            "Epoch 66/100\n",
            "42000/42000 [==============================] - 5s 130us/step - loss: 0.3913 - accuracy: 0.8775\n",
            "Epoch 67/100\n",
            "42000/42000 [==============================] - 6s 131us/step - loss: 0.3816 - accuracy: 0.8800\n",
            "Epoch 68/100\n",
            "42000/42000 [==============================] - 5s 130us/step - loss: 0.3845 - accuracy: 0.8804\n",
            "Epoch 69/100\n",
            "42000/42000 [==============================] - 6s 131us/step - loss: 0.3869 - accuracy: 0.8785\n",
            "Epoch 70/100\n",
            "42000/42000 [==============================] - 5s 128us/step - loss: 0.3768 - accuracy: 0.8822\n",
            "Epoch 71/100\n",
            "42000/42000 [==============================] - 5s 129us/step - loss: 0.3826 - accuracy: 0.8800\n",
            "Epoch 72/100\n",
            "42000/42000 [==============================] - 6s 132us/step - loss: 0.3805 - accuracy: 0.8794\n",
            "Epoch 73/100\n",
            "42000/42000 [==============================] - 6s 133us/step - loss: 0.3715 - accuracy: 0.8842\n",
            "Epoch 74/100\n",
            "42000/42000 [==============================] - 6s 134us/step - loss: 0.3717 - accuracy: 0.8842\n",
            "Epoch 75/100\n",
            "42000/42000 [==============================] - 6s 133us/step - loss: 0.3728 - accuracy: 0.8827\n",
            "Epoch 76/100\n",
            "42000/42000 [==============================] - 5s 130us/step - loss: 0.3711 - accuracy: 0.8847\n",
            "Epoch 77/100\n",
            "42000/42000 [==============================] - 6s 133us/step - loss: 0.3702 - accuracy: 0.8841\n",
            "Epoch 78/100\n",
            "42000/42000 [==============================] - 6s 135us/step - loss: 0.3648 - accuracy: 0.8863\n",
            "Epoch 79/100\n",
            "42000/42000 [==============================] - 5s 130us/step - loss: 0.3619 - accuracy: 0.8873\n",
            "Epoch 80/100\n",
            "42000/42000 [==============================] - 6s 131us/step - loss: 0.3636 - accuracy: 0.8881\n",
            "Epoch 81/100\n",
            "42000/42000 [==============================] - 5s 129us/step - loss: 0.3629 - accuracy: 0.8867\n",
            "Epoch 82/100\n",
            "42000/42000 [==============================] - 6s 131us/step - loss: 0.3584 - accuracy: 0.8880\n",
            "Epoch 83/100\n",
            "42000/42000 [==============================] - 5s 130us/step - loss: 0.3633 - accuracy: 0.8869\n",
            "Epoch 84/100\n",
            "42000/42000 [==============================] - 6s 131us/step - loss: 0.3567 - accuracy: 0.8885\n",
            "Epoch 85/100\n",
            "42000/42000 [==============================] - 6s 133us/step - loss: 0.3518 - accuracy: 0.8905\n",
            "Epoch 86/100\n",
            "42000/42000 [==============================] - 6s 131us/step - loss: 0.3527 - accuracy: 0.8893\n",
            "Epoch 87/100\n",
            "42000/42000 [==============================] - 5s 129us/step - loss: 0.3506 - accuracy: 0.8915\n",
            "Epoch 88/100\n",
            "42000/42000 [==============================] - 5s 131us/step - loss: 0.3476 - accuracy: 0.8905\n",
            "Epoch 89/100\n",
            "42000/42000 [==============================] - 6s 133us/step - loss: 0.3463 - accuracy: 0.8916\n",
            "Epoch 90/100\n",
            "42000/42000 [==============================] - 5s 129us/step - loss: 0.3500 - accuracy: 0.8890\n",
            "Epoch 91/100\n",
            "42000/42000 [==============================] - 5s 128us/step - loss: 0.3478 - accuracy: 0.8897\n",
            "Epoch 92/100\n",
            "42000/42000 [==============================] - 6s 131us/step - loss: 0.3483 - accuracy: 0.8919\n",
            "Epoch 93/100\n",
            "42000/42000 [==============================] - 5s 131us/step - loss: 0.3441 - accuracy: 0.8933\n",
            "Epoch 94/100\n",
            "42000/42000 [==============================] - 6s 133us/step - loss: 0.3456 - accuracy: 0.8919\n",
            "Epoch 95/100\n",
            "42000/42000 [==============================] - 5s 130us/step - loss: 0.3471 - accuracy: 0.8912\n",
            "Epoch 96/100\n",
            "42000/42000 [==============================] - 6s 133us/step - loss: 0.3443 - accuracy: 0.8920\n",
            "Epoch 97/100\n",
            "42000/42000 [==============================] - 6s 132us/step - loss: 0.3418 - accuracy: 0.8937\n",
            "Epoch 98/100\n",
            "42000/42000 [==============================] - 6s 135us/step - loss: 0.3389 - accuracy: 0.8940\n",
            "Epoch 99/100\n",
            "42000/42000 [==============================] - 5s 129us/step - loss: 0.3369 - accuracy: 0.8942\n",
            "Epoch 100/100\n",
            "42000/42000 [==============================] - 5s 131us/step - loss: 0.3391 - accuracy: 0.8949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogs-LDerWmi3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "306c1b27-6f53-454f-cc1e-46bf17f17ace"
      },
      "source": [
        "Score_dropout = Final_model_dropout.evaluate(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42000/42000 [==============================] - 2s 59us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KicxX0y6W3qk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c0c2ecd9-5088-4636-fde9-0848ae757252"
      },
      "source": [
        "print('Accuracy with batch normalization & dropout: ', Score_dropout[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy with batch normalization & dropout:  0.918666660785675\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQWN5YKfW3ho",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3a65d735-f40a-4640-8ea1-7a12bde3bafc"
      },
      "source": [
        "score_dropout_test = Final_model_dropout.evaluate(X_test, y_test)\n",
        "print('Accuracy with batch normalization & dropout on test data: ', score_dropout_test[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18000/18000 [==============================] - 1s 60us/step\n",
            "Accuracy with batch normalization & dropout on test data:  0.7223333120346069\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2QA_ESs27YZ",
        "colab_type": "text"
      },
      "source": [
        "**Observations:**\n",
        " - Considering batch normalization + dropout of 0.2 to see the performance of the model\n",
        " - within 25 epochs, the accuracy on train data is steep to 0.83, by the end of 100 epochs, the train accuracy was 0.91\n",
        " - But train accuracy was just 0.72, which is lesser than without dropout and batch normailzation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5ywEcau5bCE",
        "colab_type": "text"
      },
      "source": [
        "Lets try now with just dropout and without batch normalization and see the model performance with test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYU2iRvb26qZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9674eb34-a0aa-474e-9564-aac8db8862d4"
      },
      "source": [
        "Final_mdl_dropout = train_and_test_loop(X_train, y_train, hidden_nodes=256, output_nodes=10, btc_size=100, iter_epochs=200, lr=0.027, Lambda=0.00066, setdropout=True, verb=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimizer SGD is used\n",
            "Compiling the model\n",
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_201 (Dense)            (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_202 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_203 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_204 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_205 (Dense)            (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 462,346\n",
            "Trainable params: 462,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fit the model\n",
            "Epoch 1/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 2.0279 - accuracy: 0.2580\n",
            "Epoch 2/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 1.4585 - accuracy: 0.5086\n",
            "Epoch 3/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 1.1904 - accuracy: 0.6208\n",
            "Epoch 4/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 1.0853 - accuracy: 0.6535\n",
            "Epoch 5/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 1.0077 - accuracy: 0.6809\n",
            "Epoch 6/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.9438 - accuracy: 0.7036\n",
            "Epoch 7/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.8986 - accuracy: 0.7171\n",
            "Epoch 8/200\n",
            "42000/42000 [==============================] - 5s 125us/step - loss: 0.8252 - accuracy: 0.7413\n",
            "Epoch 9/200\n",
            "42000/42000 [==============================] - 5s 125us/step - loss: 0.8056 - accuracy: 0.7479\n",
            "Epoch 10/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.7798 - accuracy: 0.7554\n",
            "Epoch 11/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.7525 - accuracy: 0.7634\n",
            "Epoch 12/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.7225 - accuracy: 0.7745\n",
            "Epoch 13/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.6879 - accuracy: 0.7833\n",
            "Epoch 14/200\n",
            "42000/42000 [==============================] - 4s 90us/step - loss: 0.6721 - accuracy: 0.7872\n",
            "Epoch 15/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.6470 - accuracy: 0.7963\n",
            "Epoch 16/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.6275 - accuracy: 0.8020\n",
            "Epoch 17/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.6061 - accuracy: 0.8086\n",
            "Epoch 18/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.6028 - accuracy: 0.8099\n",
            "Epoch 19/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.5652 - accuracy: 0.8230\n",
            "Epoch 20/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.5573 - accuracy: 0.8235\n",
            "Epoch 21/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.5351 - accuracy: 0.8300\n",
            "Epoch 22/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.5248 - accuracy: 0.8339\n",
            "Epoch 23/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.5178 - accuracy: 0.8359\n",
            "Epoch 24/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.4891 - accuracy: 0.8457\n",
            "Epoch 25/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.4799 - accuracy: 0.8480\n",
            "Epoch 26/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.4816 - accuracy: 0.8482\n",
            "Epoch 27/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.4693 - accuracy: 0.8513\n",
            "Epoch 28/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.4638 - accuracy: 0.8529\n",
            "Epoch 29/200\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.4370 - accuracy: 0.8619\n",
            "Epoch 30/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.4231 - accuracy: 0.8667\n",
            "Epoch 31/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.4172 - accuracy: 0.8695\n",
            "Epoch 32/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.3946 - accuracy: 0.8753\n",
            "Epoch 33/200\n",
            "42000/42000 [==============================] - 4s 85us/step - loss: 0.3959 - accuracy: 0.8751\n",
            "Epoch 34/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.3752 - accuracy: 0.8808\n",
            "Epoch 35/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.3863 - accuracy: 0.8775\n",
            "Epoch 36/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.3641 - accuracy: 0.8852\n",
            "Epoch 37/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.3623 - accuracy: 0.8858\n",
            "Epoch 38/200\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.3629 - accuracy: 0.8850\n",
            "Epoch 39/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.3673 - accuracy: 0.8847\n",
            "Epoch 40/200\n",
            "42000/42000 [==============================] - 4s 91us/step - loss: 0.3359 - accuracy: 0.8952\n",
            "Epoch 41/200\n",
            "42000/42000 [==============================] - 4s 92us/step - loss: 0.3436 - accuracy: 0.8909\n",
            "Epoch 42/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.3210 - accuracy: 0.9003\n",
            "Epoch 43/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.3264 - accuracy: 0.8955\n",
            "Epoch 44/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.3078 - accuracy: 0.9035\n",
            "Epoch 45/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.3193 - accuracy: 0.9004\n",
            "Epoch 46/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2843 - accuracy: 0.9118\n",
            "Epoch 47/200\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.3066 - accuracy: 0.9051\n",
            "Epoch 48/200\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.3139 - accuracy: 0.9019\n",
            "Epoch 49/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.3150 - accuracy: 0.9012\n",
            "Epoch 50/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2936 - accuracy: 0.9085\n",
            "Epoch 51/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2843 - accuracy: 0.9120\n",
            "Epoch 52/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2710 - accuracy: 0.9166\n",
            "Epoch 53/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2691 - accuracy: 0.9164\n",
            "Epoch 54/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2894 - accuracy: 0.9111\n",
            "Epoch 55/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2776 - accuracy: 0.9147\n",
            "Epoch 56/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2529 - accuracy: 0.9226\n",
            "Epoch 57/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2777 - accuracy: 0.9140\n",
            "Epoch 58/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2685 - accuracy: 0.9176\n",
            "Epoch 59/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2654 - accuracy: 0.9190\n",
            "Epoch 60/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2442 - accuracy: 0.9255\n",
            "Epoch 61/200\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.2879 - accuracy: 0.9125\n",
            "Epoch 62/200\n",
            "42000/42000 [==============================] - 4s 90us/step - loss: 0.2494 - accuracy: 0.9260\n",
            "Epoch 63/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2595 - accuracy: 0.9218\n",
            "Epoch 64/200\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.2561 - accuracy: 0.9232\n",
            "Epoch 65/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2479 - accuracy: 0.9266\n",
            "Epoch 66/200\n",
            "42000/42000 [==============================] - 4s 85us/step - loss: 0.2672 - accuracy: 0.9188\n",
            "Epoch 67/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2382 - accuracy: 0.9290\n",
            "Epoch 68/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2548 - accuracy: 0.9228\n",
            "Epoch 69/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2384 - accuracy: 0.9298\n",
            "Epoch 70/200\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.2259 - accuracy: 0.9322\n",
            "Epoch 71/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2476 - accuracy: 0.9260\n",
            "Epoch 72/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2271 - accuracy: 0.9317\n",
            "Epoch 73/200\n",
            "42000/42000 [==============================] - 4s 91us/step - loss: 0.2296 - accuracy: 0.9328\n",
            "Epoch 74/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2506 - accuracy: 0.9254\n",
            "Epoch 75/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2500 - accuracy: 0.9255\n",
            "Epoch 76/200\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.2429 - accuracy: 0.9281\n",
            "Epoch 77/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2225 - accuracy: 0.9339\n",
            "Epoch 78/200\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.2524 - accuracy: 0.9260\n",
            "Epoch 79/200\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.2332 - accuracy: 0.9314\n",
            "Epoch 80/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2171 - accuracy: 0.9372\n",
            "Epoch 81/200\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.2225 - accuracy: 0.9356\n",
            "Epoch 82/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2369 - accuracy: 0.9308\n",
            "Epoch 83/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2463 - accuracy: 0.9295\n",
            "Epoch 84/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2438 - accuracy: 0.9294\n",
            "Epoch 85/200\n",
            "42000/42000 [==============================] - 4s 85us/step - loss: 0.2077 - accuracy: 0.9394\n",
            "Epoch 86/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2261 - accuracy: 0.9344\n",
            "Epoch 87/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2066 - accuracy: 0.9402\n",
            "Epoch 88/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2289 - accuracy: 0.9332\n",
            "Epoch 89/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2111 - accuracy: 0.9392\n",
            "Epoch 90/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2446 - accuracy: 0.9294\n",
            "Epoch 91/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2262 - accuracy: 0.9357\n",
            "Epoch 92/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.1945 - accuracy: 0.9442\n",
            "Epoch 93/200\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.2143 - accuracy: 0.9402\n",
            "Epoch 94/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2153 - accuracy: 0.9378\n",
            "Epoch 95/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2596 - accuracy: 0.9254\n",
            "Epoch 96/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2209 - accuracy: 0.9365\n",
            "Epoch 97/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2392 - accuracy: 0.9331\n",
            "Epoch 98/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2081 - accuracy: 0.9415\n",
            "Epoch 99/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.1989 - accuracy: 0.9432\n",
            "Epoch 100/200\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.2299 - accuracy: 0.9354\n",
            "Epoch 101/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2539 - accuracy: 0.9284\n",
            "Epoch 102/200\n",
            "42000/42000 [==============================] - 4s 85us/step - loss: 0.2092 - accuracy: 0.9400\n",
            "Epoch 103/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2688 - accuracy: 0.9263\n",
            "Epoch 104/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2102 - accuracy: 0.9408\n",
            "Epoch 105/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2088 - accuracy: 0.9417\n",
            "Epoch 106/200\n",
            "42000/42000 [==============================] - 4s 85us/step - loss: 0.2281 - accuracy: 0.9360\n",
            "Epoch 107/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2620 - accuracy: 0.9263\n",
            "Epoch 108/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2108 - accuracy: 0.9414\n",
            "Epoch 109/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2017 - accuracy: 0.9448\n",
            "Epoch 110/200\n",
            "42000/42000 [==============================] - 4s 90us/step - loss: 0.2156 - accuracy: 0.9399\n",
            "Epoch 111/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2288 - accuracy: 0.9357\n",
            "Epoch 112/200\n",
            "42000/42000 [==============================] - 4s 85us/step - loss: 0.2297 - accuracy: 0.9366\n",
            "Epoch 113/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2392 - accuracy: 0.9335\n",
            "Epoch 114/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2398 - accuracy: 0.9337\n",
            "Epoch 115/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2921 - accuracy: 0.9203\n",
            "Epoch 116/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2412 - accuracy: 0.9345\n",
            "Epoch 117/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2083 - accuracy: 0.9427\n",
            "Epoch 118/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2263 - accuracy: 0.9388\n",
            "Epoch 119/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2655 - accuracy: 0.9280\n",
            "Epoch 120/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2205 - accuracy: 0.9392\n",
            "Epoch 121/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2201 - accuracy: 0.9403\n",
            "Epoch 122/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2642 - accuracy: 0.9275\n",
            "Epoch 123/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2242 - accuracy: 0.9386\n",
            "Epoch 124/200\n",
            "42000/42000 [==============================] - 4s 90us/step - loss: 0.2251 - accuracy: 0.9405\n",
            "Epoch 125/200\n",
            "42000/42000 [==============================] - 4s 91us/step - loss: 0.2274 - accuracy: 0.9381\n",
            "Epoch 126/200\n",
            "42000/42000 [==============================] - 4s 91us/step - loss: 0.2300 - accuracy: 0.9373\n",
            "Epoch 127/200\n",
            "42000/42000 [==============================] - 4s 90us/step - loss: 0.2353 - accuracy: 0.9351\n",
            "Epoch 128/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2609 - accuracy: 0.9286\n",
            "Epoch 129/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.1999 - accuracy: 0.9469\n",
            "Epoch 130/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2250 - accuracy: 0.9397\n",
            "Epoch 131/200\n",
            "42000/42000 [==============================] - 4s 92us/step - loss: 0.2402 - accuracy: 0.9347\n",
            "Epoch 132/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2297 - accuracy: 0.9387\n",
            "Epoch 133/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2112 - accuracy: 0.9430\n",
            "Epoch 134/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2278 - accuracy: 0.9410\n",
            "Epoch 135/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2489 - accuracy: 0.9336\n",
            "Epoch 136/200\n",
            "42000/42000 [==============================] - 4s 85us/step - loss: 0.2166 - accuracy: 0.9420\n",
            "Epoch 137/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2304 - accuracy: 0.9387\n",
            "Epoch 138/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2115 - accuracy: 0.9429\n",
            "Epoch 139/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2131 - accuracy: 0.9429\n",
            "Epoch 140/200\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.2339 - accuracy: 0.9400\n",
            "Epoch 141/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2294 - accuracy: 0.9393\n",
            "Epoch 142/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2598 - accuracy: 0.9313\n",
            "Epoch 143/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2207 - accuracy: 0.9402\n",
            "Epoch 144/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2762 - accuracy: 0.9282\n",
            "Epoch 145/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2424 - accuracy: 0.9362\n",
            "Epoch 146/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2054 - accuracy: 0.9452\n",
            "Epoch 147/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2611 - accuracy: 0.9325\n",
            "Epoch 148/200\n",
            "42000/42000 [==============================] - 4s 85us/step - loss: 0.2581 - accuracy: 0.9347\n",
            "Epoch 149/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2372 - accuracy: 0.9381\n",
            "Epoch 150/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2940 - accuracy: 0.9243\n",
            "Epoch 151/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2401 - accuracy: 0.9377\n",
            "Epoch 152/200\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.2590 - accuracy: 0.9340\n",
            "Epoch 153/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2709 - accuracy: 0.9314\n",
            "Epoch 154/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2384 - accuracy: 0.9357\n",
            "Epoch 155/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2228 - accuracy: 0.9418\n",
            "Epoch 156/200\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.1980 - accuracy: 0.9485\n",
            "Epoch 157/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.1883 - accuracy: 0.9499\n",
            "Epoch 158/200\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.2176 - accuracy: 0.9452\n",
            "Epoch 159/200\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.2722 - accuracy: 0.9315\n",
            "Epoch 160/200\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.2439 - accuracy: 0.9367\n",
            "Epoch 161/200\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.2566 - accuracy: 0.9336\n",
            "Epoch 162/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2340 - accuracy: 0.9392\n",
            "Epoch 163/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2094 - accuracy: 0.9457\n",
            "Epoch 164/200\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.3077 - accuracy: 0.9213\n",
            "Epoch 165/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2641 - accuracy: 0.9313\n",
            "Epoch 166/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2068 - accuracy: 0.9460\n",
            "Epoch 167/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2626 - accuracy: 0.9331\n",
            "Epoch 168/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2363 - accuracy: 0.9393\n",
            "Epoch 169/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2446 - accuracy: 0.9382\n",
            "Epoch 170/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.1903 - accuracy: 0.9515\n",
            "Epoch 171/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2338 - accuracy: 0.9427\n",
            "Epoch 172/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2462 - accuracy: 0.9375\n",
            "Epoch 173/200\n",
            "42000/42000 [==============================] - 5s 107us/step - loss: 0.2313 - accuracy: 0.9403\n",
            "Epoch 174/200\n",
            "42000/42000 [==============================] - 6s 142us/step - loss: 0.3270 - accuracy: 0.9205\n",
            "Epoch 175/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2553 - accuracy: 0.9362\n",
            "Epoch 176/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2168 - accuracy: 0.9438\n",
            "Epoch 177/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2382 - accuracy: 0.9391\n",
            "Epoch 178/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2123 - accuracy: 0.9459\n",
            "Epoch 179/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2067 - accuracy: 0.9472\n",
            "Epoch 180/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2221 - accuracy: 0.9444\n",
            "Epoch 181/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2876 - accuracy: 0.9282\n",
            "Epoch 182/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2215 - accuracy: 0.9435\n",
            "Epoch 183/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2432 - accuracy: 0.9386\n",
            "Epoch 184/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2506 - accuracy: 0.9372\n",
            "Epoch 185/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2220 - accuracy: 0.9445\n",
            "Epoch 186/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2643 - accuracy: 0.9344\n",
            "Epoch 187/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2994 - accuracy: 0.9257\n",
            "Epoch 188/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2243 - accuracy: 0.9438\n",
            "Epoch 189/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2260 - accuracy: 0.9428\n",
            "Epoch 190/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2668 - accuracy: 0.9339\n",
            "Epoch 191/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2134 - accuracy: 0.9449\n",
            "Epoch 192/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2549 - accuracy: 0.9368\n",
            "Epoch 193/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2353 - accuracy: 0.9419\n",
            "Epoch 194/200\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.2629 - accuracy: 0.9349\n",
            "Epoch 195/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2797 - accuracy: 0.9313\n",
            "Epoch 196/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2344 - accuracy: 0.9418\n",
            "Epoch 197/200\n",
            "42000/42000 [==============================] - 4s 87us/step - loss: 0.2812 - accuracy: 0.9323\n",
            "Epoch 198/200\n",
            "42000/42000 [==============================] - 4s 88us/step - loss: 0.2544 - accuracy: 0.9359\n",
            "Epoch 199/200\n",
            "42000/42000 [==============================] - 4s 86us/step - loss: 0.2198 - accuracy: 0.9466\n",
            "Epoch 200/200\n",
            "42000/42000 [==============================] - 4s 89us/step - loss: 0.2482 - accuracy: 0.9410\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFN1Oc4V5xMc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f764ffda-b15e-414e-d690-7e21558c9e6a"
      },
      "source": [
        "score_mdl_dropout = Final_mdl_dropout.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18000/18000 [==============================] - 1s 51us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P_Muj7253x4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8dd979ad-e2b5-45e7-926b-89a462a222f3"
      },
      "source": [
        "print('Accuracy without batch normalization & with dropout on test data: ', score_mdl_dropout[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy without batch normalization & with dropout on test data:  0.7911111116409302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwA4Kd415wkp",
        "colab_type": "text"
      },
      "source": [
        "**Observations:**\n",
        " - Within first 25 epochs, the model without batch normalization and dropout of 0.2 yielded 0.85 accuracy on train data\n",
        " - The train accuracy at end of 200 epochs was 0.94. And test accuracy is 0.79 which is almost the same as without dropout and batch normailzation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmMSpfUhE1Wx",
        "colab_type": "text"
      },
      "source": [
        "## 12. Print Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu1vuCb_KF22",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "4d04074e-cb9a-4a19-b8fd-9edec5b562e4"
      },
      "source": [
        "# Get predicted values for non-normalized model and its performance on test data\n",
        "pred_val_cls_nn = Final_model.predict_classes(X_test, batch_size = 200, verbose=0)\n",
        "\n",
        "# Revert the one-hot encoded y_test to labels\n",
        "rounded_labels=np.argmax(y_test, axis=1)\n",
        "\n",
        "# Now output the confusion matrix\n",
        "cm = confusion_matrix(rounded_labels, pred_val_cls_nn)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1507,   17,   17,   23,   41,   17,   48,   18,   41,   85],\n",
              "       [  27, 1384,   34,   59,  103,   26,   41,   61,   49,   44],\n",
              "       [  20,   14, 1475,   53,   38,   18,   10,   60,   42,   73],\n",
              "       [   8,   14,   39, 1344,   23,  132,   30,   25,   44,   60],\n",
              "       [  10,   28,   23,   36, 1579,   20,   32,    8,   33,   43],\n",
              "       [  15,   13,   12,   97,   21, 1416,   84,   16,   48,   46],\n",
              "       [  30,   12,    9,   32,   39,   67, 1512,   11,   91,   29],\n",
              "       [  18,   41,   41,   31,   20,   10,    8, 1593,   13,   33],\n",
              "       [  25,   20,   29,   52,   27,   44,   92,   16, 1428,   79],\n",
              "       [  34,   12,   20,   54,   35,   58,   20,   20,   64, 1487]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD_eRxWjJ6_t",
        "colab_type": "text"
      },
      "source": [
        "**Observation**\n",
        " - With Batch normailzation, the accuracy of the model on test data seems to be low for the given training parameters used\n",
        " - For the given trained model, the non-normalized model is giving better performance. But stability could be off due to overfitting on training data"
      ]
    }
  ]
}