{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SJ_NLP_Project1_Sentiment_Class_Classification_V2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOgXpd0sYie54+dGKFaWcq+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SandeepJosyula/NeuralNetworks/blob/master/SJ_NLP_Project1_Sentiment_Class_Classification_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRx6OTfN5eCD"
      },
      "source": [
        "# Project 1 - NLP - Sequential Models\n",
        "\n",
        "## Sentiment Classification\n",
        "**Objective**\n",
        "The objective of this project is to build a text classification model that analyses the customer's sentiments\n",
        "based on their reviews in the IMDB database. The model uses a complex deep learning model to build an\n",
        "embedding layer followed by a classification algorithm to analyze the sentiment of the customers.\n",
        "\n",
        "**Dataset**\n",
        "\n",
        "The Dataset of 50,000 movie reviews from IMDB, labelled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers). For convenience, the words are indexed by their frequency in the dataset, meaning the for that has index 1 is the most frequent word. Use the first 20 words from each review to speed up training, using a max vocab size of 10,000. As a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word\n",
        "\n",
        "**Overview**\n",
        "- Dataset of 50,000 movie reviews from IMDB, labeled by sentiment positive (1) or negative (0)\n",
        "- Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers).\n",
        "- For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: \"only consider the top 10,000 most common words, but eliminate the top 20 most common words\".\n",
        "- As a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word.\n",
        "\n",
        "Command to import data\n",
        "- `from tensorflow.keras.datasets import imdb`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScspWyLd8I2-"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgDYwEXR8M1s",
        "outputId": "77a09f72-43f1-4bd7-a4f6-c4bbd406f023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h89s6AZ38jha"
      },
      "source": [
        "# Initialize the random number generator\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "# Ignore the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import textwrap\n",
        "\n",
        "from keras        import models, regularizers, layers, optimizers, losses, metrics\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, TimeDistributed\n",
        "from keras.utils  import np_utils, to_categorical"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE3Xc5Co6lGO"
      },
      "source": [
        "### Import the data (2 Marks)\n",
        "- Use `imdb.load_data()` method\n",
        "- Get train and test set\n",
        "- Take 10000 most frequent words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI0tNK-5_b_v"
      },
      "source": [
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZH4sa8BAJlg",
        "outputId": "1558ae0c-ccde-4c20-a5c6-846f8a3c0067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "print(\"train_data \", train_data.shape)\n",
        "print(\"train_labels \", train_labels.shape)\n",
        "print(\"~\"*100)\n",
        "print(\"test_data \", test_data.shape)\n",
        "print(\"test_labels \", test_labels.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data  (25000,)\n",
            "train_labels  (25000,)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "test_data  (25000,)\n",
            "test_labels  (25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuetZGRylXGg"
      },
      "source": [
        "**Observations:**\n",
        " - Though we import train and test data sets, we will combine them both and reorder prior to using with our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2Hz6mBJPOEK"
      },
      "source": [
        "### Print shape of features & labels (2 Marks)\n",
        " - Number of reviews\n",
        " - Number of words in each review\n",
        " - Number of labels\n",
        " - Maximum review length\n",
        " - Number of categories\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjNuytx2Opbs"
      },
      "source": [
        "**Combine train and test data in to single np array to do the pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYCvJbVzNk1O",
        "outputId": "e659da93-4341-4e01-88bc-bd4089f6e584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "data = np.concatenate((train_data, test_data), axis=0)\n",
        "targets = np.concatenate((train_labels, test_labels), axis=0)\n",
        "\n",
        "print(\"Number of reviews:\", data.shape[0])\n",
        "print(\"Label categories:\", np.unique(targets))\n",
        "print(\"Number of unique words across all reviews:\", len(np.unique(np.hstack(data))))\n",
        "print(\"Maximum count of words in one review: \", max([len(sequence) for sequence in data]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of reviews: 50000\n",
            "Label categories: [0 1]\n",
            "Number of unique words across all reviews: 9998\n",
            "Maximum count of words in one review:  2494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9fb6_FmN5kz",
        "outputId": "66861649-09e0-48de-b073-3113b0d1acdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "length = [len(i) for i in data]\n",
        "print(\"Maximum review length:\", np.max(length))\n",
        "print(\"Average Review length:\", np.mean(length))\n",
        "print(\"Standard Deviation:\", round(np.std(length)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum review length: 2494\n",
            "Average Review length: 234.75892\n",
            "Standard Deviation: 173.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUoiEt-ON_mK",
        "outputId": "07d04205-050e-41d1-e80f-9dd11a0eccfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#print the label\n",
        "print(\"Label:\", targets[100])\n",
        "# print the data \n",
        "print(data[100])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 0\n",
            "[1, 13, 244, 6, 87, 337, 7, 628, 2219, 5, 28, 285, 15, 240, 93, 23, 288, 549, 18, 1455, 673, 4, 241, 534, 3635, 8448, 20, 38, 54, 13, 258, 46, 44, 14, 13, 1241, 7258, 12, 5, 5, 51, 9, 14, 45, 6, 762, 7, 2, 1309, 328, 5, 428, 2473, 15, 26, 1292, 5, 3939, 6728, 5, 1960, 279, 13, 92, 124, 803, 52, 21, 279, 14, 9, 43, 6, 762, 7, 595, 15, 16, 2, 23, 4, 1071, 467, 4, 403, 7, 628, 2219, 8, 97, 6, 171, 3596, 99, 387, 72, 97, 12, 788, 15, 13, 161, 459, 44, 4, 3939, 1101, 173, 21, 69, 8, 401, 2, 4, 481, 88, 61, 4731, 238, 28, 32, 11, 32, 14, 9, 6, 545, 1332, 766, 5, 203, 73, 28, 43, 77, 317, 11, 4, 2, 953, 270, 17, 6, 3616, 13, 545, 386, 25, 92, 1142, 129, 278, 23, 14, 241, 46, 7, 158]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M39zwSBFK9K"
      },
      "source": [
        "### Decode the feature value to get original sentence (2 Marks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkrDyJqsFaIt"
      },
      "source": [
        "First, retrieve a dictionary that contains mapping of words to their index in the IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9co9F7HAJdn"
      },
      "source": [
        "# See an actual review in words\n",
        "# Reverse from integers to words using the DICTIONARY (given by keras...need to do nothing to create it)\n",
        "\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHUUrebamsJ1"
      },
      "source": [
        "Build a reverse word index to decode the imported database values in to specific review comments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9CM7UDFFdlh"
      },
      "source": [
        "Now use the dictionary to get the original words from the encodings, for a particular sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRAll1kUC4T3",
        "outputId": "eb6a7270-f21c-49e7-a55c-7de52fd90240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "pick_idx = 123  # Pick 123rd sentence\n",
        "\n",
        "print(\"Label:\", train_labels[pick_idx])\n",
        "\n",
        "# build the sentence by decoding each word and concatenate it\n",
        "decoded_review = ' '.join([reverse_word_index.get(i - 3, '$') for i in train_data[pick_idx]])\n",
        "\n",
        "print(textwrap.fill(decoded_review,100))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 1\n",
            "$ beautiful and touching movie rich colors great settings good acting and one of the most charming\n",
            "movies i have seen in a while i never saw such an interesting setting when i was in china my wife\n",
            "liked it so much she asked me to $ on and rate it so other would enjoy too\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXQy_10nTjTr"
      },
      "source": [
        "### Print value of any one feature and it's label (2 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqzRUmqKTlKj",
        "outputId": "f06c30d9-729b-4444-9728-32e9a8fb3e0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "pick_idx = 1500 # Pick 1500th review\n",
        "print(\"Label:\", train_labels[pick_idx])\n",
        "# build the sentence by decoding each word and concatenate it\n",
        "decoded_review = ' '.join([reverse_word_index.get(i - 3, '$') for i in train_data[pick_idx]])\n",
        "\n",
        "print(textwrap.fill(decoded_review,100))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 1\n",
            "$ one of the things about the film that $ my heart strings was that dry fly fishing was a major part\n",
            "of the scene i have occasionally carried out my times of dry fly fishing having tied my own flies\n",
            "and being accompanied by my brother and my father we spend a day on one river or another seeking to\n",
            "$ the ever $ brown $ to rise and take the fly that has been offered to them br br when we had\n",
            "occasions like this any differences between us disappeared and any of the $ of the world $ away to\n",
            "be replaced by the glory of being absorbed in the activity and the surroundings of the place we were\n",
            "in br br this was one of the amazing things that was portrayed to me in the film as the minister and\n",
            "his two sons norman and $ carried out the ritual for there is something $ about fly fishing as there\n",
            "is something $ about so many $ you can't just start casting your fishing line and hope for the best\n",
            "you have to $ yourself to the place you are in you have to $ the surface of the water considering\n",
            "how it is flowing and where the best point might be to place your fly and depending on your skill\n",
            "level you might even get your fly to land there long enough for a fish to take note of it and strike\n",
            "the $ of fly $ was directed and represented so well that they themselves can be classified as\n",
            "artists br br the title for the film could not be more $ chosen for the river did in fact run\n",
            "through the life of father and two sons this film however $ itself $ than the family and community\n",
            "in montana by the the $ river where the film is played out it has the capacity to draw you in to $\n",
            "you to capture you as the history of the family community and period is $ the story told is not just\n",
            "a family history but a history of life what may be classified as a $ of $\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5VqjSwUS4S4"
      },
      "source": [
        "### Pad each sentence to be of same length (2 Marks)\n",
        "- Take maximum sequence length as 300"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh7YsmdQYkwp",
        "outputId": "ca60fc09-f539-44fb-d0e8-9202093f5ad5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X = pad_sequences(data,maxlen=300)\n",
        "print(\"Maximum count of words in a review in original review dataset: \", max([len(sequence) for sequence in data]))\n",
        "print(\"Maximum count of words in a review in padded dataset: \", max([len(sequence) for sequence in X]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum count of words in a review in original review dataset:  2494\n",
            "Maximum count of words in a review in padded dataset:  300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liktIdFZcC0y"
      },
      "source": [
        "### Split in to train and test sets\n",
        " - Train set containing 40000 reviews\n",
        " - Test set containing 10000 reviews\n",
        " - Within the Train set, 10000 reviews are moved in to validation set, and rest 30000 for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou1_GLcKcB1o"
      },
      "source": [
        "x_train = X[10000:]\n",
        "x_test = X[:10000]\n",
        "y_train = targets[10000:]\n",
        "y_test = targets[:10000]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LkUVcFgBkft",
        "outputId": "c03ec5bf-9b9c-4c53-9ccd-aed7a9433fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Set a VALIDATION set\n",
        "\n",
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]\n",
        "\n",
        "print(\"x_val \", x_val.shape)\n",
        "print(\"partial_x_train \", partial_x_train.shape)\n",
        "print(\"y_val \", y_val.shape)\n",
        "print(\"partial_y_train \", partial_y_train.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_val  (10000, 300)\n",
            "partial_x_train  (30000, 300)\n",
            "y_val  (10000,)\n",
            "partial_y_train  (30000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC6HtTzzXFn3"
      },
      "source": [
        "### Define model (10 Marks)\n",
        "- Define a Sequential Model\n",
        "- Add Embedding layer\n",
        "  - Embedding layer turns positive integers into dense vectors of fixed size\n",
        "  - `tensorflow.keras` embedding layer doesn't require us to onehot encode our words, instead we have to give each word a unique integer number as an id. For the imdb dataset we've loaded this has already been done, but if this wasn't the case we could use sklearn LabelEncoder.\n",
        "  - Size of the vocabulary will be 10000\n",
        "  - Give dimension of the dense embedding as 100\n",
        "  - Length of input sequences should be 300\n",
        "- Add LSTM layer\n",
        "  - Pass value in `return_sequences` as True\n",
        "- Add a `TimeDistributed` layer with 100 Dense neurons\n",
        "- Add Flatten layer\n",
        "- Add Dense layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73mjykywBkc5",
        "outputId": "709784a8-9191-4b32-975a-39914cae02ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# NN MODEL\n",
        "\n",
        "vocabsize = 10000\n",
        "embed_dim = 100\n",
        "lstm_out = 100\n",
        "\n",
        "# Use of DROPOUT\n",
        "model = models.Sequential()\n",
        "model.add(Embedding(vocabsize, embed_dim,input_length = X.shape[1],name=\"EmbeddingLayer\"))\n",
        "model.add(SpatialDropout1D(0.4,name=\"SpatialDropoutLayer\"))\n",
        "model.add(LSTM(lstm_out,dropout=0.2,recurrent_dropout=0.2,return_sequences=True,name=\"LSTMLayer\"))\n",
        "model.add(TimeDistributed(Dense(100),name=\"TimeDistributedLayer\"))\n",
        "model.add(Flatten(name=\"FlattenLayer\"))\n",
        "model.add(Dense(1,activation='sigmoid',name=\"FinalDenseLayer\"))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer LSTMLayer will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lHQwizhow7P"
      },
      "source": [
        "### Compile the model (2 Marks)\n",
        "- Use Optimizer as Adam\n",
        "- Use Binary Crossentropy as loss\n",
        "- Use Accuracy as metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EctVvETko3q8"
      },
      "source": [
        "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKy05jUwpENK"
      },
      "source": [
        "### Print model summary (2 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1dKnT75pB8f",
        "outputId": "4999a076-feb7-4031-ea72-9db4384a8def",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "EmbeddingLayer (Embedding)   (None, 300, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "SpatialDropoutLayer (Spatial (None, 300, 100)          0         \n",
            "_________________________________________________________________\n",
            "LSTMLayer (LSTM)             (None, 300, 100)          80400     \n",
            "_________________________________________________________________\n",
            "TimeDistributedLayer (TimeDi (None, 300, 100)          10100     \n",
            "_________________________________________________________________\n",
            "FlattenLayer (Flatten)       (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "FinalDenseLayer (Dense)      (None, 1)                 30001     \n",
            "=================================================================\n",
            "Total params: 1,120,501\n",
            "Trainable params: 1,120,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r78VaSgjpaM1"
      },
      "source": [
        "### Fit the model (2 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Jz9438gBkaA",
        "outputId": "15f54de5-80bc-42f2-d9f9-3ed4c0bf3f79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "# FIT / TRAIN model\n",
        "\n",
        "NumEpochs = 10\n",
        "BatchSize = 500\n",
        "\n",
        "history = model.fit(partial_x_train, partial_y_train, epochs=NumEpochs, batch_size=BatchSize, validation_data=(x_val, y_val))\n",
        "\n",
        "results = model.evaluate(x_test, y_test)\n",
        "print(\"_\"*100)\n",
        "print(\"Test Loss and Accuracy\")\n",
        "print(\"results \", results)\n",
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60/60 [==============================] - 31s 520ms/step - loss: 0.5136 - accuracy: 0.7208 - val_loss: 0.3165 - val_accuracy: 0.8633\n",
            "Epoch 2/10\n",
            "60/60 [==============================] - 31s 509ms/step - loss: 0.2587 - accuracy: 0.8927 - val_loss: 0.2801 - val_accuracy: 0.8839\n",
            "Epoch 3/10\n",
            "60/60 [==============================] - 30s 508ms/step - loss: 0.1969 - accuracy: 0.9226 - val_loss: 0.2964 - val_accuracy: 0.8796\n",
            "Epoch 4/10\n",
            "60/60 [==============================] - 31s 511ms/step - loss: 0.1629 - accuracy: 0.9357 - val_loss: 0.3379 - val_accuracy: 0.8820\n",
            "Epoch 5/10\n",
            "60/60 [==============================] - 31s 509ms/step - loss: 0.1423 - accuracy: 0.9446 - val_loss: 0.3410 - val_accuracy: 0.8776\n",
            "Epoch 6/10\n",
            "60/60 [==============================] - 31s 510ms/step - loss: 0.1148 - accuracy: 0.9568 - val_loss: 0.3893 - val_accuracy: 0.8725\n",
            "Epoch 7/10\n",
            "60/60 [==============================] - 31s 510ms/step - loss: 0.0852 - accuracy: 0.9682 - val_loss: 0.4332 - val_accuracy: 0.8696\n",
            "Epoch 8/10\n",
            "60/60 [==============================] - 31s 512ms/step - loss: 0.0693 - accuracy: 0.9741 - val_loss: 0.4804 - val_accuracy: 0.8725\n",
            "Epoch 9/10\n",
            "60/60 [==============================] - 31s 513ms/step - loss: 0.0540 - accuracy: 0.9790 - val_loss: 0.5240 - val_accuracy: 0.8713\n",
            "Epoch 10/10\n",
            "60/60 [==============================] - 31s 516ms/step - loss: 0.0467 - accuracy: 0.9824 - val_loss: 0.5673 - val_accuracy: 0.8645\n",
            "313/313 [==============================] - 24s 78ms/step - loss: 0.5739 - accuracy: 0.8631\n",
            "____________________________________________________________________________________________________\n",
            "Test Loss and Accuracy\n",
            "results  [0.5739215612411499, 0.863099992275238]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw6LxqROo0P_"
      },
      "source": [
        "**Observations:**\n",
        " - The training accuracy is pretty decent as is the validation and test accuracy\n",
        " - Since we considered only 300 padded reviews, which means the first 300 words of all the 50,000 reviews there is a possibility of information loss. This is done for obvious performance reasons\n",
        " - So the model will cater to majority of the data but not necessarily be accurate\n",
        " - We are also not using new NLP processes like bi-directional/BERT...etc.,. So there is a high chance that the model is only for basic evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zmFlbDrB5ZZ",
        "outputId": "f7648ef8-55ab-46dd-f40f-052921f43655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# VALIDATION LOSS curves\n",
        "\n",
        "plt.clf()\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "epochs = range(1, (len(history_dict['loss']) + 1))\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-dTRNVmqZ9f"
      },
      "source": [
        "**Observations:**\n",
        " - Though the training loss is constantly reduced, the validation loss is exploding. This means the validation data may not be a representation of training data. There is scope for further tuning to find the global minima"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giOMX3hmB5WI",
        "outputId": "a80e7b15-d00e-4f15-a154-0ee7c299b6ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# VALIDATION ACCURACY curves\n",
        "\n",
        "plt.clf()\n",
        "acc_values = history_dict['accuracy']\n",
        "val_acc_values = history_dict['val_accuracy']\n",
        "epochs = range(1, (len(history_dict['accuracy']) + 1))\n",
        "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCYNFsy4qs3K"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djdj2upDqtFC"
      },
      "source": [
        "**Observations:**\n",
        " - Same observations as the validation loss is not reduced for subsequent training iterations, the accuracy of validation data also didnt improve proportioanl to the accuracy of training data\n",
        " - Seems to be a case of overfitting on training data, but didnt achieve its purpuse on validation data. So probably the model is a bit skewed and requires further tuning or use advanced NLP methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkwyR16XqsjS"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-e3cj5V7Xrl"
      },
      "source": [
        "### Evaluate model (2 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO7mKG7j7ozi",
        "outputId": "04164ff4-60e0-439b-9d25-fe3e82326541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 24s 77ms/step - loss: 0.5739 - accuracy: 0.8631\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5739215612411499, 0.863099992275238]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmX-3V3N7XiY"
      },
      "source": [
        "### Predict on one sample (2 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euMv5gznBP36"
      },
      "source": [
        "def preprocess(sample_text):\n",
        "  sample_input = sample_text.split(' ')\n",
        "  sample_predict = np.zeros(300)\n",
        "  sample_predict = sample_predict.astype('int')\n",
        "  idx = 299\n",
        "  for txt in sample_input:\n",
        "    tmp = word_index.get(txt,0)\n",
        "    sample_predict[idx] = tmp\n",
        "    print(txt,\" - \", tmp)\n",
        "    idx = idx - 1\n",
        "  print(\"Sample Text encoded: \", sample_predict)\n",
        "  sample_predict = sample_predict.astype('int')\n",
        "\n",
        "  # build the final array for predicting using the model\n",
        "  final_pred[0]=sample_predict    #copy the new values to first row\n",
        "  print(\"Final input to model to predict, shape:\", final_pred.shape)\n",
        "  return final_pred"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkjNnTT79tCv",
        "outputId": "b4d8689a-75ca-43a4-8644-e50f2bcb8241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        }
      },
      "source": [
        "sample_text = \"bad movie and a total waste of time \"\n",
        "final_pred = x_test[:1]         #copy the same structure as test dataset\n",
        "final_pred = preprocess(sample_text)\n",
        "sentiment = model.predict(final_pred,batch_size=1)[0]\n",
        "print(\"Sentiment Assessment value (0-Negative <--> 1.Positive): \", sentiment)\n",
        "if(sentiment < 0.5):\n",
        "    print(\"negative\")\n",
        "else:\n",
        "    print(\"positive\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bad  -  75\n",
            "movie  -  17\n",
            "and  -  2\n",
            "a  -  3\n",
            "total  -  961\n",
            "waste  -  434\n",
            "of  -  4\n",
            "time  -  55\n",
            "  -  0\n",
            "Sample Text encoded:  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0  55   4 434 961   3   2  17  75]\n",
            "Final input to model to predict, shape: (1, 300)\n",
            "Sentiment Assessment value (0-Negative <--> 1.Positive):  [0.41072938]\n",
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSpjANXVn1Z5"
      },
      "source": [
        "**Observations:**\n",
        " - For a sample random review, the accuracy is pretty low but decent enough\n",
        " - For IMDB list of review comments, the accuracy is pretty high. So we can try a couple of options"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4K0GtsurpTZ"
      },
      "source": [
        "#### A negative sentiment case from IMDB database itself"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyOGVR-onrOS",
        "outputId": "f75e3d90-3ae2-43dc-cd15-b664b2dc2fc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "final_pred = x_test[:1]         #copy the same structure as test dataset\n",
        "final_pred[0] = x_test[1000]    #transfer the encoded review comment of 1002 item from test set\n",
        "print(\"Label from IMDB for a sample test set:\", y_test[1000])\n",
        "sentiment = model.predict(final_pred,batch_size=1)[0]\n",
        "print(\"Sentiment Assessment value (0-Negative <--> 1.Positive): \", sentiment)\n",
        "if(sentiment < 0.5):\n",
        "    print(\"negative\")\n",
        "else:\n",
        "    print(\"positive\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label from IMDB for a sample test set: 0\n",
            "Sentiment Assessment value (0-Negative <--> 1.Positive):  [0.04528756]\n",
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooDc0ZHsrt5b"
      },
      "source": [
        "#### A positive sentiment case from IMDB database itself"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt064SClrgZQ",
        "outputId": "bf1c3c1d-f3cb-45d6-e80c-db6b5dde6495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "final_pred = x_test[:1]         #copy the same structure as test dataset\n",
        "final_pred[0] = x_test[900]    #transfer the encoded review comment of 1002 item from test set\n",
        "print(\"Label from IMDB for a sample test set:\", y_test[900])\n",
        "sentiment = model.predict(final_pred,batch_size=1)[0]\n",
        "print(\"Sentiment Assessment value (0-Negative <--> 1.Positive): \", sentiment)\n",
        "if(sentiment < 0.5):\n",
        "    print(\"negative\")\n",
        "else:\n",
        "    print(\"positive\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label from IMDB for a sample test set: 1\n",
            "Sentiment Assessment value (0-Negative <--> 1.Positive):  [0.9891494]\n",
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}